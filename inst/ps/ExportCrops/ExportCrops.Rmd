
```{r 'check_ps', include=FALSE}

user.name = ''
```

---
title: "Export Crops and Civil Conflicts"
author: "Adrian Sihler"
date: "2024-05-09"
output:
  word_document: default
  html_document: default
editor_options:
  chunk_output_type: console
---

# The Role of Export Crops in the Conflict Dynamics of the Philippines

Author: Adrian Sihler

## Greetings! 

I express my satisfaction that you have arrived at this interactive Problem Set, which is my master thesis at Ulm University. Over the course of this Problem Set, we will examine the results of the economic article **"Export Crops and Civil Conflict"** written by Benjamin Crost and Joseph H. Felter. This Problem Set aims to provide a comprehensive understanding of the statistical methods applied in the article by replicating and interpreting the authors empirical analyses. In facilitating the implementations, we will demonstrate the power of the R programming language. 

After processing this Problem Set, you will be equipped with the economic knowledge of the paper, the analysis methods used, and the essential skills of R, which will enable you to conduct your own analyses. 

The study was published in June 2020, in the 18th Volume, Issue 3 of the Journal of the European Economic Association. The source is accessible in the following [link](https://academic.oup.com/jeea/article/18/3/1484/5505371?login=true) with the corresponding data set provided in the section *"Supplementary data"*. 

The Problem Set corresponding to the study is published on GitHub and ShinyApp. It is available at the following two links:

* `GitHub`: <https://github.com/AdrianSihler/RTutorExportCrops>

* `ShinyApp`: <https://adriansihler.shinyapps.io/RTutorExportCrops/>

<br/>

## Exercise Content

**1 – Motivation and Background**

1.1 – High-value Export Crops and the Philippine Economy

1.2 – Armed Rebel Groups and Potential for Conflict

**2 – Data Overview**

2.1 – Introducing the Data Set and getting started with R

2.2 – Descriptive Statistics of the Data

**3 – Empirical Analysis**

3.1 – Introduction to the DiD Approach

3.2 – DiD Adjustment, Parallel Trend Assumption and Control Variables

3.3 – Last Modifications and Key Analysis Results

**4 – Robustness Check**

4.1 – The Problem of Reverse Causality

4.2 – Spatial Regression

**5 – Further Analyses**

**6 – Possible Mechanisms**

**7 – Conclusion**

**Bibliography**

**List of illustrations**

**Appendix**

<br/>

## Abstract

In the political and economic literature, the prevalent belief that conflict can be mitigated by the cultivation of high-value export crops, which generates jobs, opportunities for legal income sources, and increase the opportunity costs of participating in violent organizations, is common. Therefore, many national governments of developing countries depend on the cultivation and export of high-value commodities such as bananas or sugar, as a means of restoring national stability and gain economic growth. This dominant ideology entails adverse implications. Few researchers and policy makers examine the effect of this export-driven mentality on the likelihood of violence in unstable low-income nations. Potential risks and challenges could arise from empowering insurgent groups, who intensify their activities in extorting agricultural producers. For this reason, the aim of this Problem Set is to evaluate the methods and findings of Crost and Felter’s study "Export crops and Civil Conflict". We investigate throughout this Problem Set, how changing global crop prices affect the occurrence of provincial violent conflicts in the Philippines during the observation period of 2001 to 2009. We incorporate several variations of crop values, geographic modifications, territorial rebel dominance, and plantation characteristics to examine the actual determinants of violence. The empirical results support the claim that there is a positive correlation between provincial violence and crop price fluctuations. In addition to that, we try to explain these results with respective mechanisms and their central implications for future governmental policies. 

<br/>

## Settings of the Problem Set and how it can be solved!

Before starting the exercises, here are some guidelines to follow. First of all, it is not mandatory to strictly follow the structure of the Problem Set step by step. However, this Problem Set is structured as a guided tour through the study, and **it is strongly recommended to follow this format**. Within one exercise, you must comply with the sequence of the tasks. The core of this Problem Set consists of three types of code chunks, which are:

* Code blocks that do not contain any predefined code and allow you to implement your own solution.

* Code blocks that contain partially completed code and require you to fill in the missing parts by replacing the `___` placeholders.

* Code blocks that contain fully functional code where you only need to click on the `check` button to verify the output. 

In the `ShinyApp version` of this Problem Set, each code chunk has several buttons above it that allows interaction with the code. The `edit` button enables you to modify the code if it is not editable by default. The `check` button allows you to verify your answer and receive feedback on its correctness. The `hint` button provides you with a clue if you are stuck or confused. The `solution` button reveals the sample solution for the edited chunk. To proceed to the next exercise, you can either use the `Go to next exercise` button on the bottom left of the respective exercise or simply click on the corresponding tabs at the top. 

Moreover, this Problem Set is also designed to be solved within the `RStudio environment using the RMarkdown` format. You can use the addin `Check Problem Set` to navigate through the Set. **Please note** that the chunks, which have `eval = FALSE` in the **Info blocks** are **non-executable**. **Attempting to run them will result in errors!** Moreover, there are several useful functions that you need to run in the console for completing the tasks. If you encounter difficulties, the `hint()` function will give you a clue about the current task. The `stats()` function displays your progress in the Problem Set, with a summary of the completed and remaining tasks.

Additionally, there are also quizzes in this Problem Set. Those are all single-choice quizzes, which are based on previous information or general knowledge. After you locked in your answer in the `ShinyApp version`, press on the `check` button. During the `RStudio environment`, execute the quiz chunk and indicate the correct answer by entering it in the console.

A final remark is warranted. The **links provided for additional information should be opened in a separate browser tab to avoid losing progress on the Problem Set!**

Furthermore, you can score **amazing awards** for tackling the exercises in this Problem Set. The `awards()` function enables the presentation of the achievements. Each award has a **hidden letter!** Remember them well and arrange them in the right order at the conclusion to *win the ultimate prize of the game*. Hopefully, this boosts your passion to net them all, collect every single one and build your own trophy cabinet. Now let's kick off this Problem Set and have a blast!

<br/>


## Exercise 1 -- Motivation and Background

The first chapter presents an overview of the global banana production and examines the characteristics and challenges of the Philippine banana industry, with focus on the conflict dynamics that affect its performance and stability.

First, we will discuss the rapidly grown move toward high-value export crops and its implications for the Philippine banana sector, which is one of the major producers of bananas in the world. Then, you will be given a detailed description of the geographic and economic situation of the Philippines and how the country is affected by the volatility of the global banana price.

Second, we are going to examine the potential for conflict that is attributable to the export of high-value banana crops. We look at different armed rebel groups and a special extortion mechanism that helps us to explain, how the insurgent strength, in several regions of the Philippines, affects the conflict violence. 

### Framework

1.1 High-value Export Crops and the Philippine Economy

1.2 Armed Rebel Groups and Potential for Conflict

<br/>

## Exercise 1.1 -- High-value Export Crops and the Philippine Economy

In recent years, the western way of thinking as well as our consumer habits have unfortunately adapted to the fact that all kinds of fruits and vegetables are available at any time of the year. Weinberger and Lumpkin (2005, p. 1) mentioned **two major factors leading to more horticultural crops that have high quality and value**. First, the year-round accessibility of all sorts of fruits all over the world. Second, the raising consciousness among people in developed countries about the impact of food on their well-being. They also quoted that growing fruits and vegetables is a lucrative and work-intensive activity, which enables the farms to generate more revenue and it fosters the effective use of labor.

The subsequent section provides updated statistics on bananas and the Philippines in general, supplementing the outdated statistical data reported by the authors.

As determined by the FAOSTAT Analytical Brief 44 from the Food and Agriculture Organization of the United Nations (2022, p. 5), fruit and vegetables topped 2020 export values with USD283 billion, a 318% rise from the year 2000. Tomato products (5.3% of the total fruit and vegetables export value), **bananas (4.7%)**, potatoes (4%) and grapes (3.9%) led the table. These commodities faced an increase of 6 to 6.5% annually from 2000 to 2020. Moreover, the four core foods have low shares due to the fruit and vegetables sector size (>100 products labelled as *"Other"*), as shown in the following Figure 1: 

![](Image_1_export_values.png) 

According to Bayer Global (2023), bananas are the world’s fourth largest and vital crop. Bananas feed over 400 million people who depend on it for 15 to 27% of their daily calories. Especially the **Cavendish variety** is widely known. Crost and Felter (2020, p. 1489f.) mentioned that Cavendish is the dominant variety of bananas that are exported worldwide, as it has the capability to endure transportation over long distances without deterioration.


Quiz: Since the focus of the study **"Export Crops and Civil Conflict"** relies on the horticultural banana crop, where do you think most bananas come from?

(1) Central and Southern Europe
(2) North, Middle and Southern America
(3) Latin America, East India, and Southeast Asia
(4) Middle East and Western Asia

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("Banana Crop Origin")
```

```{r eval=FALSE}
# Run for additional info in the Viewer pane
info("Banana production worldwide")
```

High-value crops like fruits and vegetables can boost the economy and reduce poverty in developing countries, where billions live in extreme poverty. Therefore, high-value export crops attract heavy investments from developing countries seeking this huge opportunity [Weinberger and Lumpkin (2005, p. 2), Crost and Felter (2020, p. 1484)]. 

To underpin this effect, if we look at especially the **banana crop**, the FAOSTAT Analytical Brief 44 from the Food and Agriculture Organization of the United Nations (2022, p. 5) has released that the **top three exporter of bananas contributes to 47% of the total export value**. The developing country Ecuador accounts for 27%, the **Philippines** for 12%, and Costa Rica for about 8%, which can be seen in Figure 4:

![](Image_4_banana_trades.png) 

A comparison of the global top ten banana producers from the Info block above and the top three banana exporters from Figure 4 reveals that the leading exporters are ranked lower among the producers. **This suggests that the highest-producing countries primarily cater to their domestic demand rather than exporting their surplus to enhance their economic growth.** The Philippines are an exception, as the nation exploits its potential to augment their economy by being the second largest banana exporter in the world.

Therefore, a brief overview of the Philippines is essential, considering its unique geographic features, historical events, and economic performance. Furthermore, it helps you to understand the economic analysis of the Problem Set later.

<br/>

The World Factbook (2024) quoted that the Philippines are an island country in Southeast Asia, located south of China and east of Vietnam in the Pacific Ocean. The Philippines were colonized by Spain in the 16th century and transferred to the US in 1898 after the Spanish-American War. With the US, the Filipinos fought against the Japanese during World War II, after the Japanese occupied the territory. The Philippines gained their independence in 1946 and experienced several political and economic challenges under different presidents, such as Marcos, Aquino, Estrada, Arroyo, and Duterte. Marcos Jr. became the head of the presidential republic in 2022 after his father was ejected in 1986.

According to The World Factbook (2024), the Philippine land territory covers an area of approximately 298,000 square kilometers. Most of the landscape consists of mountainous regions, which is due to the Philippines location on the Ring of Fire. 


Quiz: Given that the Philippines consists of several island groups, what do you think is the number of regions and provinces in the country?

(1) 17 regions with 81 provinces
(2) 18 regions with 92 provinces
(3) 20 regions with 86 provinces
(4) 15 regions with 105 provinces

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("Location of the Philippines")
```

<br/>

![](Image_5_location.png)

<br/>

As stated in The World Factbook (2024), Philippine is the 13th most populous country in the world with over 116 million inhabitants. The population growth rate is 1.58%, which is higher than the global average of 1.05%. Manila, the capital city, is home to nearly 15 million people, accounting for almost 13% of the total population. The predominant religion is Roman Catholicism, followed by Islam and Iglesia ni Cristo, with 79%, 6.5% and 2.6% of the population, respectively. Overall, the Philippines has a young demographic profile, with a median age of 24 years and an age distribution of 30.5% (0-14 years) and 64% (15-64 years). Associating with the demographic picture, the total fertility rate is also high, with 2.77 children born per woman. As the country consists of many island and regions, the population density varies, depending on the availability of arable farmland, like in the regions of Luzon, Mindanao, and Visayas. Agricultural terrain constitutes 41% of the total land area in the Philippines, of which 18% is used for permanent crops. The environment and therefore the economy of the Philippines is vulnerable to natural disasters, especially typhoons, as it is the most exposed country in the world to tropical storms.

<br/>

The World Bank (2024) provides statistical evidence for the complexity of the Philippine economy in the **data for the fiscal year 2022** in current USD. The gross domestic product (GDP) of the country reached USD404 billion, recovering from a slight decline during the COVID-19 pandemic. GDP per capita was around USD3,500, indicating a low income distribution. The annual GDP growth rate rebounded to 7.6% after the crisis, showing a strong resilience of the economy. The inflation rate was 5.8%, lower than that of Germany. Moreover, the unemployment rate was also low, at 2.2% of the total labor force. 

With about 48 million workers, the Philippines had a comparable size of labor force as Germany, according to the World Factbook (2024). As the main source of employment, followed by the agriculture and industry sectors, the service sector dominates, as illustrated by the following Figure 6:

![](Image_6_sector_employment.png)

<br/>

To show the dependence of the Philippine economy on its exports and imports, the OEC Philippines (2022) provides data. The country has natural resources such as petroleum, nickel, cobalt, copper, gold, silver, and domestic banana plantations. On the one hand, in 2022, the Philippines exported goods worth USD110 billion (top 20% of the world), with an increasing trend. Main export products were integrated circuits (USD32 billion), machine parts (USD10 billion), insulted wires (USD3 billion), semiconductor devices (USD3 billion), bananas (USD1.4 billion), and others. These products were mainly exported to China, US, Hong Kong, and Japan. On the other hand, the Philippines imported goods worth USD167 billion. Main import products were integrated circuits (USD16 billion), refined petroleum (USD14 billion), coal briquettes (USD5 billion), and cars (USD4 billion), primarily imported from China, Indonesia, South Korea, and Japan. This resulted in a negative trade balance of -USD57 billion.

<br/>

According to the Poverty & Equity Brief in April 2023 for East Asia & Pacific, particularly the Philippines, by the World Bank Group (2023, p. 1), the COVID-19 pandemic has reversed the ongoing trend of poverty decrease in the Philippines that lasted over 30 years. The incidence of poverty increased up to 18.1% in 2021, which means that more than 19 million people lived below the national poverty line. Despite the economic recovery of the Philippines, the high inflation rate undermined these gains. The poor households spent about 70% of their expenditures on food and energy, which experienced sharp price increases. This reduced their purchasing power and increased their vulnerability to poverty. The poorest region in the country is the Bangsamoro Autonomous Region of Muslim Mindanao (BARMM).

![](Image_7_poverty_region.png)

<br/>


Quiz: Given the previous Figure 7 about the regional poverty differences, which regions are the poorest among the Philippines?

(1) BARMM, Visayas, National Capital Region
(2) BARMM, Caraga, Visayas
(3) National Capital Region, Cordillera Administrative Region, Calabarzon
(4) Bicol Region, Soccsksargen, Mindanao

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("Poverty Regions of the Philippines")
```

This realization is confirmed by the following graphic from Crost and Felter (2020, p. 1503), which presents the average banana production by province, differentiated by the *Cavendish variety* and *Other Bananas*. Based on Crost and Felter (2020, p. 1491f.), *Other Bananas* refer to the varieties of bananas that are cultivated for domestic consumption. These include *Lacatan*, a dessert banana and *Saba*, a variety of banana utilized as a cooking ingredient in numerous traditional dishes. These bananas are distributed by small farmers directly to the consumers in local markets.
The average provincial banana cultivation in kg is shown in Figure 8 below. It illustrates that the production of *Other Bananas* is geographically more dispersed throughout the nation, in contrast to the centralized cultivation of the Cavendish variety for the export market.

![](Image_8_mean_production.png)

<br/>

The OEC Bananas in Philippines (2022) reported that the country exported Cavendish bananas worth USD1.4 billion in 2022, ranking as the second largest exporter in the world after Ecuador and ahead of Costa Rica in this highly concentrated market. Bananas constituted the tenth largest export product of the Philippines, with Japan (USD650 million), China (USD400 million) and South Korea (USD200 million) as the main markets. 

According to Crost and Felter (2020, p. 1490.), the Philippine banana export industry exhibits a high degree of market concentration. A small number of multinational export firms, such as Dole, Chiquita, and Sumitomo, control the processing and distribution of the bananas, even though the land is owned by the farmers. These firms have established a highly vertically integrated supply chain, which enables them to exert major influence over the production and marketing of the bananas.

Given that the banana export sector is a vital source of income and livelihood for the rural and agricultural regions of the Philippines, fluctuations in the global price of bananas in US Dollar per Metric Tons has a considerable impact on their economic well-being.

The Federal Reserve Bank of St. Louis (2024) provided monthly data to illustrate the fluctuations of the global price of bananas from 1990 to the present.

**Task 1:** To show the development of the banana price, just `check` the following chunk. Do not worry, you will be able to compute such a code at the end of the Problem Set without any issues.  

```{r "3_1",fig.width=10, fig.height=6}
#Load the necessary package
library("ggplot2")

#Read in the data set from the Federal Reserve Bank of St. Louis
df_banana_prices <- read.csv("Banana_prices.csv", header = TRUE, sep = ",")

#Change the column names
colnames(df_banana_prices) <- c("Date", "Prices")

#Change the "Date" column to an actual date variable
df_banana_prices$Date <- as.Date(df_banana_prices$Date)

#Generate the plot
ggplot(data = df_banana_prices, mapping = aes(x = Date, y = Prices)) +
  geom_line(color = "blue", linewidth = 1) +
  scale_y_continuous(breaks = seq(from = 200, to = 1800, by = 200)) +
  labs(x = "Years", y = "US Dollar per Metric Ton", title = "Global Price of Bananas") + 
  theme_bw()
```

As we can see in the created graph, the global banana price exhibited high volatility prior to the Global Financial Crisis (2007-2009). Subsequently, the price stabilized and followed an upward trend, driven by the rising demand for bananas as a source of health and caloric benefits. Moreover, we can see a sharp increase in the global banana price especially through the end of 2022. What are the global influences behind the price increase in 2022?

<br/>

Banana production is influenced by global factors, which are reflected in the fluctuations of the global market price. The Banana Market Review 2022, a publication of the Food and Agriculture Organization of the United Nations (2023, p. 1), reports that several supply-side factors harmed the global banana trade in 2022, which led to alterations in the world market price. The banana import market faced a constant demand, while the supply side encountered rising production costs and shortages, which influenced the global price. 

Furthermore, according to the Banana Market Review 2022 (2023, p. 1), the unaffordable prices for fertilizers resulted in a reduced application by farmers, hampering the productivity and quality of domestic banana cultivation. In addition, the general availability of bananas for export in 2022 was also affected by challenging weather conditions e.g. tropical storms, which occurred in the main producing countries, such as Ecuador or the Philippines. Moreover, the occurrence of plant diseases, particularly the rapid propagation of the Banana Fusarium Wilt Tropical Race 4 (TR4) disease in the Philippines, resulted in additional costs related to disease prevention and production shortages. 

Another influence mentioned by the Banana Market Review 2022 from the Food and Agriculture Organization of the United Nations (2023, p. 1), is that the prices and export growth were influenced by the shortage of refrigerated containers and the elevated global transportation costs. To make matters worse, the escalation of the war in Ukraine, which began in 2022, aggravated the existing challenges on the global supply chain. Moreover, the conflict led to the termination of vital trade relations due to the economic sanctions charged on the Russian Federation. On top of the mountain, operating conditions in 2022 have become more complex due to the substantial devaluation of currencies against the US dollar, which impacted the activities throughout the value chain as the common transaction currency in the banana industry is the US dollar.


Quiz: Given the previously created graph about the global banana price, what was the peak banana price level that was ever recorded?

(1) USD1.357 per kg
(2) USD1.833 per kg
(3) USD1.685 per kg
(4) USD1.464 per kg

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("Banana Global Market Price")
```


<br/>

## Exercise 1.2 -- Armed Rebel Groups and Potential for Conflict

Before starting with the data and the empirical analyses, **it is essential to examine the characteristics of the rebel groups in the Philippines and the general concept of conflict.** The mentioned increase in banana prices and the high concentration of the export market creates an opportunity for armed rebel groups to finance their operations by **extorting and predating** the processing plants.

According to The World Factbook (2024), the Philippine has been plagued by various forms of armed violence for decades, stemming from the appeals and aspirations of separate groups that challenge the legitimacy and authority of the central government. These groups include separatists, terrorists, and criminal groups, who often operate in the remote and impoverished banana production regions of the country. To combat these internal threats, the government has various armed military and security forces at its disposal. These forces are the *Armed Forces of the Philippines (AFP)*, which includes the Army, Air Force, and Navy with the Marine Corps, the *Philippine Coast Guard (PCG)*, and the *Philippine National Police Force (PNP)*. **The primary objective of the government is to conduct operations against terrorists, insurgents, and criminals that pose a threat to national security and economic stability.** To assist them in their efforts, the Philippine Government also provides arms and support to civilian militias, who participate in conflicts with rebel groups.

The AFP is primarily engaged in internal security operations, especially in the southern regions of the country, where it faces several challenges from Islamic terrorist groups. These groups operate in the rural and conflict-prone banana production areas of Mindanao, where the AFP has deployed more than half of its personnel, as stated in the World Factbook (2024). 

<br/>

Crost and Felter (2020, p. 1491.) mentioned that one opposing combat party of the AFP is the **New People’s Army (NPA)**, which is an armed wing group of the Communist Party of the Philippines. The rebel group operates in a highly decentralized manner, with activities spanning almost every province in the country, through numerous autonomous guerrilla fronts in various territories. They conduct attacks on military and police stations, aiming to destabilize the political system to bring down the government and establish a communist regime. *They sustain themselves by extracting extortion fees from exporters under the menace of damaging the infrastructure of banana processing plants or even setting fires in the plantations.* 

<br/>

As reported by The World Factbook (2024), the second mentionable combat party until 2014, was the **Moro Islamic Liberation Front (MILF)**. Until then, the AFP engaged in a protracted conflict with the MILF, a separatist group that operates mainly in Mindanao and Bangsamoro. According to Crost and Felter (2020, p. 1492.), the MILF had the ambition to establish their own autonomous region under the control of Muslim Moro people, independent from governmental control. They are causing a stir among the population for various horrific acts in the conflict with the AFP. These acts include beheading of government combatants and extortion involving attacks on banana plantations, the same as previously mentioned by the NPA. It is reported that Muslim countries, such as Saudi Arabia and Iran, supported the rebel group financially. 

Since the study period of our article, *Export Crops and Civil Conflict*, spans from 2001 to 2009, preceding the peace agreement *(”Comprehensive Agreement on Bangsamoro”)* between the government and the MILF in 2014, *the MILF is a noteworthy conflict party for our study*, see University of Edinburgh - Peace Agreements Database (2024) for more details. 

<br/>

The last mentionable conflict party for our study is the **Abu Sayyaf Group (ASG)**. According to The World Factbook with its references to Terrorist Organizations (2024), the ASG is an Islamist terrorist group that has sworn loyalty to the Islamic State. Their primary objective is to establish their own Islamic State in the southern Philippines and strive for a bigger State in Southeast Asia. The terrorist group has been associated with al-Qaida in the early 2000s and has participated in the activities of ISIS-East Asia, such as suicide attacks and bombings. Crost and Felter (2020, p. 1492) describe the ASG as operating mainly in the Sulu archipelago and continuing to extend it into neighboring Malaysia. They reach financial liquidity through kidnappings for ransom, extortion attacks on banana plantations, and drug smuggling in the South Chinese region.


Quiz: Considering these armed rebel groups, what do you intuitively expect, how the Philippines compare with other countries, in terms of the impact of terrorism on its security, as of the year 2020 when our research article was published? The lower the rank, the greater the impact of terrorism.

(1) Rank 10 of the 195 countries in the world
(2) Rank 115 of the 195 countries in the world

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("Terrorism in the Philippines")
```

As mentioned by the Global Terrorism Index 2020, published by the Institute for Economics & Peace (2020, p. 28), the Philippines ranked 10th with a GTI score of 7.099, behind the leader Afghanistan, which had the highest score of 9.592. The report recorded 348 terrorist incidents in 2020, resulting in 393 injuries and 284 fatalities. The main targets of these attacks were government officials and institutions, followed by private citizens and property, which included banana farmers and plantations. The terrorist group with the highest level of activity and fatality was the NPA, which accounted for almost one-third of the deaths in 2020. The ASG was the third deadliest group in the country, as shown in the statistic of Figure 9. It is infamous for its violent assaults on both soldiers and civilians, causing many deaths.

![](Image_9_terrorism.png)

<br/>

The ASG admitted designing the most devastating terrorist attack in the Philippines and simultaneously the world’s most fatal maritime attack. The operation involved the bombing of a passenger ferry *(“Superferry 14”)* in 2004, which resulted in the death of 116 people, see Stanford University (2022) for more details.

A notable trend that can be observed from the Global Terrorism Index reports from 2020 to 2024 is the decline of the Philippines in the ranking of the most affected countries by terrorism. The country has improved its situation and reduced the impact from terrorism, moving from the 10th place in 2020 to the 19th place in 2024. The reports can be accessed [here](https://www.economicsandpeace.org/reports/?sa=Global+terrorism+index#). 


The data presented in the Global Terrorism Index 2020 indicate that the various insurgent groups **pose a significant potential for civil conflict in the Philippines**, particularly in the regions where bananas are cultivated, due to the **extortion effect.**


Quiz: What is your guess of the total extortion revenues that the NPA obtains, just from the banana plantation region of Mindanao alone?

(1) USD17 million
(2) USD32 million
(3) USD28 million
(4) USD41 million

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("Extortion in the Philippines")
```

**Therefore, due to these massive transactions, we will examine the theoretical framework of conflict that will guide our analysis throughout the Problem Set.**

<br/>

## Theoretical Framework of Conflict

We begin by exploring the *extortion mechanism*. Crost and Felter (2020, p. 1493) explain how a rise in global banana prices intensifies conflict through a model of the direct and indirect extortion channel. **As an initial factor, the global market price of bananas is used.** Banana exporters obtain higher returns from their banana facilities when the price is high, such as in January 2023. The rebels are aware of this situation and taking advantage of it. In the extortion process, the rebels expect banana plantation owners to pay a higher fee because they are more willing to pay, to prevent an attack that would jeopardize the profitable export of bananas. The exporter or landowner faces a dilemma. They can either comply with the rebel's demand for fees or resist payment and seek governmental assistance in defending their property. **Both channels of this extortion mechanism lead to an intensification of the conflict**.

<br/>

On the one hand, in the *direct extortion channel*, so-called *“direct predation”*, as described by Berman et al. (2012, p. 1f.) and Crost and Felter (2020, p. 1493), increasing product values enhances the value of disputed resources and thus raises the motivation for the opposing parties to gain (remain in) control of them. **Consequently, this leads to a higher allocation of resources towards conflict-related operations.**

This behavior reflects a common human tendency. **The higher the value of the good, the greater the satisfaction for it and the more intense the conflict.** Therefore, Crost and Felter (2020, p. 1493) posit that the competition for the high-value banana crop results in violent rebel attacks to enforce their extortion demand or in preventive government strikes focused on weakening insurgent groups.

On the other hand, in the *indirect extortion channel*, the rebel groups can use the increased proceeds to purchase weapons or hire warriors thereby reinforcing their rebel power, according to Crost and Felter (2020, p. 1494). 

<br/>

In economic theory, this contest can be conceptualized as a strategic interaction, in which the agents allocate effort to increase their likelihood of winning. **The Contest-Success-Function (CSF)** represents the probability of winning as a function of the effort level, as stated by Skaperdas (1996). Crost and Felter (2020, p. 1494) explain that our CSF anticipates a **concave relationship between the relative power of two opposing groups and the intensity of violence, for our theoretical framework of conflict.** To illustrate this model more easily, *consider a contest between the Philippine government and the NPA insurgent group over the supremacy of a lucrative banana plantation.*


Quiz: How do you expect the level of violence to vary, if, in the author's model, the banana plantation is situated in a region where the government has a dominant position?

(1) Low level of violence
(2) High level of violence

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("Framework of Conflict 1")
```


Quiz: And now the other way around, how do you expect the level of violence to vary, if, in the author's model, the banana plantation is situated in a region where the NPA insurgent group has a dominant position?

(1) Low level of violence
(2) High level of violence

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("Framework of Conflict 2")
```


Quiz: In addition, there exists another potential scenario. How would the degree of violence fluctuate, if, in the author's model, the banana plantation is in a region where the governmental forces and the NPA insurgent group have comparable power?

(1) Low level of violence
(2) High level of violence

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("Framework of Conflict 3")
```

The following Figure 10 demonstrates this model mechanism.

![](Image_10_CSF.png)

<br/>

Crost and Felter (2020, p. 1494f.) revealed that the CSF posits a concave link between **rebel strength (relative to the government) and violence**. The level of violence in a region will be influenced by the relative strength of the rebels and the government. A *reduction in violence* may indicate either a weakening of the insurgent force in a region where they had a low baseline influence *(moving from point A to A’’)* or a strengthening of the insurgent capacity through the indirect predation channel in a region where they had a high initial impact *(moving from point B to B’)*. 


Quiz: Considering the information presented, to check if you have understood the mechanism correctly, what factors do you believe contribute to an increase in provincial violence?

(1) Increase of the rebel capacity from a high starting point or a worsen of the insurgent strength from a low baseline
(2) Decline of the rebel capacity from a high starting point or an improvement of the insurgent strength from a low baseline
(3) Decline of the rebel capacity from a low starting point or an improvement of the insurgent strength from a high baseline

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("Rebel Force and Violence")
```


<br/>

## Exercise 2 -- Data Overview

This chapter provides the essential background on the main data frame on which the analyses rely, as well as the initial introduction to R.

The data frame covers the years 2001 to 2009 and consists of reports from various institutions as well as the military in the Philippines. 

We explore the data set in depth by learning the R fundamentals of loading new packages, importing `.dta` files, and assigning them to custom objects. We describe the variables recorded and some logical operator that are useful in R. We introduce the Pipe Operator and perform the first data transformations.

Next, descriptive statistics of the data set are examined with our first table, displayed using the `kableExtra` package. Finally, we learn about the important `ggplot2` package, which allows us to create own individual graphics. You will practice it by yourself step by step. 

### Framework

2.1 Introducing the Data Set and getting started with R

2.2 Descriptive Statistics of the Data

<br/>

## Exercise 2.1 -- Introducing the Data Set and getting started with R

The data frame consists of data reported by various credible institutions in the Philippines and the world. The sources of the specific data are described in detail by Crost and Felter (2020, p. 1495-1496).

Four specifications are essential to define before starting with the R application, as mentioned by Crost and Felter (2020, p. 1495-1496): 

* *Measure of conflict intensity*, is the unit of violent incidents with a minimum of one fatality, in a particular province and year.

* *Measure of territorial control*, as an indicator of insurgent strength. Villages with insurgent activities were clustered by rebel influence. The highest category includes villages with permanent rebel presence, arms carrying, and training. This measure is valid, as it shows the armed group's freedom from governmental interference, as previously explained in our mechanism. The provinces were ranked from high to low insurgent strength based on the influenced villages.

* The definition of a *large banana plantation* is a farm with more than 25 hectares of cultivation area.

* *World market prices* are inflation-adjusted and expressed in 2010 USD.

<br/>

**Now we can start by applying our knowledge to the beautiful world of R!**

The authors base their analyses on the data set called **replication_data.dta**, which includes 62 variables. Therefore, to avoid confusion, let us first look at the organization and structure of this data set. This is particularly important in R to familiarize yourself with the given data.

Firstly, we want to read the data frame and assign it to an own variable in R. Since our file format is `.dta`, we need to use a special function that is not supported by R by default. In such cases, in which you want to extend your R version, you can *add defined packages* with more enhanced functions. 

```{r eval=FALSE}
# Run for additional info in the Viewer pane
info("R Basics I: Load new packages, read in .dta files, and assign them to a variable")
```

**Task 2:** Now you are ready to try it by yourself. Using the `library()` function, start by loading the required `haven` package.

```{r "6_4"}
#Load the haven package
```

**Task 3:** Now, please read in the data frame `replication_data.dta` and assign it to the variable `data`. Use the described `read_dta()` function.

```{r "6_5"}
#Read in the data and save it in the correct variable
```

Great! You have correctly saved the data set into the variable `data`.

<br/>

Now, of course you want to look at the entries and see how the data set is structured. To do so, R offers some basic functions that facilitate a preliminary inspection of the data set. To mention the most important one, we can apply the `head()` function to the data set. This function displays the top rows of the data frame, which is passed as an argument into the function. By default, the command shows the first six rows of the data.  

**Task 4:** Use the `head()` command to display the first rows of the data set, which you have previously read in. Remember, you have declared it to your own variable!

```{r "6_6"}
#Use head() to show the first six rows of the data frame
```

The top rows of observation from the data set are visible now. 

**A detailed description of the 62 variables can be found in the following Info block.** 

```{r eval=FALSE}
# Run for additional info in the Viewer pane
info("Variable description of the data set")
```


Quiz: Given the data set presented above, what information does one single row of observation convey?

(1) One row records information for one specific year, in all provinces
(2) One row records information for one specific year, in one specific province

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("Data Set Knowledge")
```


<br/>

## Exercise 2.2 -- Descriptive Statistics of the Data

Before we entail an initial examination of the data set values and statistics, it is beneficial to get you familiar with some of the essential R skills.

**Task 5:** As a first step, load the `haven` package and import the data set `replication_data.dta` into R. Assign the imported data to the object named `data`. *Recall the methods for loading packages and importing data that you learned previously!*

```{r "7_1"}
#Load the necessary package, import the data, and save it in the correct object
```

Firstly, the `subset()` function is noteworthy, as it enables the extraction of a subset of a data set, which fulfills a given criterion and generates a new data frame. *The criterion is applied to the entries in a specific column.* Rows, which do not comply to the criterion are eliminated over all columns. The syntax of this function is `subset(data_set, logical_operation_criterion)`. A documentation of this function can be accessed [here](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/subset).

```{r eval=FALSE}
# Run for additional info in the Viewer pane
info("Logical operators")
```

**Task 6:** Please fill in the blanks to subset the main data frame, where the variable `meancavendish` is positive. It will be assigned to the new data frame called `summary_data_YES`.

```{r "7_2"}
summary_data_YES <- ___(data, ___ > ___)
```

The `select()` function is another useful tool for data manipulation. This function allows the user to *choose specific columns of a data frame and exclude the rest*. This can help to avoid confusion and improve efficiency when working with large data sets and many variables. Documentation of this function can be found [here](https://www.rdocumentation.org/packages/dplyr/versions/0.7.3/topics/select). We apply this function and extend our previously created code, to create the data frame `summary_data_YES`. To do this, we introduce a powerful **operator** that facilitates the construction of more organized and readable R code chains. 

The package `dplyr` contains the **Pipe Operator** `%>%`, which enables the user to *perform multiple operations sequentially without generating unnecessary intermediate results.* The `%>%` operator can be appended at the *end of a line of code* and interpreted as *"... followed by ..."*.

**Task 7:** With that knowledge, the next step is to extend the previous code by filling in the blanks. After created the subset, we want to *select* only the following 16 out of the 62 columns in the data frame:  `cavendish2002_pop`, `lacatan2002_pop`, `saba2002_pop`, `sugar2002_pop`, `rice2002_pop`, `vinc`, `govtvinc`, `envinc`, `civvinc`, `govinitvinc`, `eninitvinc`, `ctm_vinc`, `mus_vinc`, `asg_vinc`, `le_vinc`, `totcas`. *Use the Pipe Operator!*

```{r "7_3"}
library("dplyr")

summary_data_YES <- subset(data, meancavendish > 0) ___
  ___(cavendish2002_pop, ___, saba2002_pop, sugar2002_pop, rice2002_pop, ___, govtvinc, envinc, civvinc, govinitvinc, eninitvinc, ctm_vinc, mus_vinc, asg_vinc, le_vinc, totcas)
```

**Great! We are moving forward and making progress!**

Additionally, in R, a common task is to obtain information or apply a statistical method to a **single column of the entire data frame**. This can be accomplished by accessing a specific column using the `$ Operator`, which has the following syntax: `data_set$column`.

This access can be integrated within various mathematical methods, which will be performed on that column. Some examples of such approaches are *minimum*, *maximum*, *sum*, *mean*, *standard deviation*, or *natural logarithm*. The corresponding R functions are `min()`, `max()`, `sum()`, `mean()`, `sd()`, or `log()`. 

**Task 8:** Please fill in the blanks to compute the *mean* and the *standard deviation* of the `cavendish2002_pop` column. **These values will reappear in the subsequent table of descriptive statistics!**


```{r "7_4"}
___(summary_data_YES$___)

___(summary_data_YES___cavendish2002_pop)
```

The data frame indicates that the average production of Cavendish bananas per capita is 9.36 kg, with a standard deviation of 27.22. 

<br/>

Having acquired some basic knowledge of R, we will now examine the data provided by the authors. To facilitate your understanding of the data, we present the descriptive statistics in Table 1. In this table, we *differentiate between provinces that produce Cavendish bananas and those that do not*.

**Task 9:** The creation of the `summary_data_YES` data frame completed the first step successfully. The subsequent step involves creating the `summary_data_NO` data frame, which reflects the **absence of Cavendish banana production in each province**. Remember the variable `meancavendish`, which denotes the production level of Cavendish bananas. **Use the appropriate logical operator for the exact value!** Choose the same columns as previously stated. *Recall Task 7 if you have problems, the principle is the same!*

```{r "7_5"}
summary_data_NO <- ___(data, meancavendish ___ 0) ___
  ___(cavendish2002_pop, lacatan2002_pop, saba2002_pop, sugar2002_pop, rice2002_pop, vinc, govtvinc, envinc, civvinc, govinitvinc, eninitvinc, ctm_vinc, mus_vinc, asg_vinc, le_vinc, totcas)
```

```{r eval=FALSE}
# Run for additional info in the Viewer pane
info("kableExtra package")
```

**Task 10:** The code below is used to produce the *descriptive statistics of the main data set in Table 1*. To execute the code chunk, click on the `check` button. The code computes the mean and standard deviation of the relevant columns and alternates them in the table. Additionally, the number of provinces and observations are added, the row names are specified, and the `kableExtra` package is employed for optical adjustments of the table. *The code and its comments can be examined to comprehend its functionality.* Furthermore, the Info block above contains a description of the `kableExtra` package.

```{r "7_6"}

library("kableExtra")

df_YES_1 <- round(data.frame(MEAN = colMeans(summary_data_YES), SD = apply(summary_data_YES, 2, sd)), 2) #Creates a new data frame which contains the column "MEAN" and "SD". In these columns, the mean and the standard deviation of the selected variables are created and rounded to two decimal places 

df_YES <- data.frame(MEAN = df_YES_1$MEAN, SD = paste("(", as.character(df_YES_1$SD), ")", sep = "")) #Creates the data frame for the "Yes" column of Table 1 by putting the values of the standard errors in brackets

#The following two lines are doing the same as for the "Yes" column, but now just for the "No" column
df_NO_1 <- round(data.frame(MEAN = colMeans(summary_data_NO), SD = apply(summary_data_NO, 2, sd)), 2)

df_NO <- data.frame(MEAN = df_NO_1$MEAN, SD = paste("(", as.character(df_NO_1$SD), ")", sep = ""))

#Now we have two data frames for Table 1 with each containing two columns. We would now like to merge the two columns of a data set across the rows alternately
n <- nrow(df_YES) #Get the number of rows of one data set. It does not matter from which one, because the two are of the same length

new_df_YES <- data.frame(Yes = character(n * 2)) #We create the final data set necessary for the "Yes" column in Table 1. This one has only one empty column with n*2 rows

#The following two lines fill up the empty rows of the final "Yes" data set. This is done alternately. First the MEAN, then the SD
new_df_YES$Yes[seq(1, n * 2, by = 2)] <- df_YES$MEAN  
new_df_YES$Yes[seq(2, n * 2, by = 2)] <- df_YES$SD  


#The following three lines are doing the same as in the final "Yes" data set, but now just for the final "No" data set
new_df_NO <- data.frame(No = character(n * 2)) 

new_df_NO$No[seq(1, n * 2, by = 2)] <- df_NO$MEAN 
new_df_NO$No[seq(2, n * 2, by = 2)] <- df_NO$SD 

#We have now created two final data sets for each column of the Table 1

#Now we create two new rows that should occur in the Table 1. The first is for the "Number of provinces" and the second is for the "Number of observations"
new_row_1 <- data.frame(
  Yes = length(unique(summary_data_YES$lacatan2002_pop)),
  No = length(unique(summary_data_NO$lacatan2002_pop)))

new_row_2 <- data.frame(
  Yes = nrow(summary_data_YES),
  No = nrow(summary_data_NO))

#By adding the two final data frames for "Yes" and "No" with the two rows together, we finally get the data frame "df_Table_1" that we want to display in Table 1
df_Table_1 <- data.frame(new_df_YES, new_df_NO)%>%
  rbind(., new_row_1) %>%
  rbind(., new_row_2)

#Here we specify the row names manually
new_row_names <- c("Cavendish production (kg per capita)", " ", "Lacatan production", "  ", "Saba production", "   ", "Sugarcane production", "    ", "Rice production", "     ", "Violent incidents", "      ", "Incidents with at least one government casualty", "       ", "Incidents with at least one insurgent casualty", "        ", "Incidents with at least one civilian casualty", "         ", "Government-initiated violent incidents", "          ", "Insurgent-initiated violent incidents", "           ", "Violent incidents involving the NPA", "            ", "Violent incidents involving the MILF", "             ", "Violent incidents involving the ASG", "              ", "Violent incidents involving LE", "               ", "Casualties", "                ", "No. of provinces", "Num.Obs.") 

#Overwrite the row names with the new ones
rownames(df_Table_1) <- new_row_names 

#Optical adjustment of the table with caption, header above, background color and a footnote                  
kable(df_Table_1, format = "html", caption = "TABLE 1. Descriptive statistics.", position = "left") %>%
  kable_styling() %>%
  add_header_above(c(" " = 1, "Cavendish producing province" = 2)) %>%
  row_spec(seq(1, n * 2 , 2), background="#ecf6ff") %>%
  footnote(general = '"The unit of observation is the province-year."',
           general_title = "Notes from Crost and Felter (2020, p. 1497): ",
           footnote_as_chunk = T, title_format = c("italic"))
```

Table 1 presents the descriptive statistics of the main variables for the observation period of 2001 to 2009. The mean and the standard deviation (in parentheses) are reported for each variable. The sample is divided into two groups: *provinces that produce Cavendish bananas* and *provinces that do not*. There are 29 provinces in the former group and 48 provinces in the latter group. The mean per capita production of Cavendish bananas in the producing provinces is 9.36kg. Additionally, the table displays those provinces, which produce Cavendish bananas, also account for a sizable proportion of the cultivation of the domestically consumed Lacatan and Saba varieties, as well as for sugar. Furthermore, we see that the non-producing provinces have a slightly higher average per capita production of rice than the Cavendish cultivating provinces.

As Crost and Felter (2020, p. 1497f.) also noted, Table 1 shows that the Cavendish-producing provinces were confronted *with a higher degree of conflict violence than the non-producing provinces.* The average number of violent incidents per year was 8.78 in the former group and 6.13 in the latter group. Furthermore, the Cavendish-producing provinces also had *higher mean incidents with at least one casualty within the different conflict parties and a higher average number of resulted total casualties*. Insurgents initiated a vast proportion of incidents, although the government also played a significant role. The most active insurgent group was the NPA, followed by the LE (Lawless Elements) group and the MILF. According to the statistic, the ASG was involved in a small proportion of incidents. **These descriptive statistics from the raw data already provide some preliminary evidence to support our hypothesis that the export of the high-value Cavendish banana crop increases conflict potential due to the possible higher revenues for insurgent organizations.**

<br/>

In addition to the descriptive statistics presented in Table 1, it is important to *examine the trends and patterns of commodity prices throughout observation*. A graphical representation of the data can provide a clear and intuitive illustration of the price movements. R and the package `ggplot2` offer a *variety of features that enable the creation of customized plots with embedded data*. Hence, the price developments offer a suitable opportunity for a brief introduction to `ggplot2` and the world of plots in R.

**Task 11:** We start by loading the `ggplot2` package. Afterwards, please import the data set `df_figure_rep.dta` into R. This new data set is specifically prepared to generate a graphical illustration of the commodity price evolution. Assign the imported data to the object named `df_figure_rep`. *Recall the methods of loading packages and importing data that you learned previously!* Finally, have a look at the first rows of the data set with the function `head()`. **Note:** If you want to have an insight look, at how the new data set resulted from the original one (`replication_data.dta`), feel free to look at the **Appendix**. 

```{r "7_7"}
#Load the necessary "ggplot2" package, import the new data set, and save it in the correct object
#Display the first rows of the data frame
```

The data set `df_figure_rep` comprises annual commodity prices for each year of observation. It should be noted that **all prices are expressed in 2010 USD**. For the Lacatan and Saba varieties, only the domestic farmgate prices are reported in the original data set. These prices are converted to 2010 currency by *dividing the domestic farmgate prices by the exchange rate*. The annual domestic farmgate prices (*lacatanprice_farmgate* & *sabaprice_farmgate*) and the exchange rate (*usd_php_xrate*) are also included in the data frame `df_figure_rep` as seen above. Therefore, the necessary columns are `bananaprice`, `sugarprice`, `riceprice`, `lacatanprice` and `sabaprice`, which are expressed in 2010 USD. 

<br/>

That being said, let me introduce you to the beautiful world of `ggplot2`. 

```{r eval=FALSE}
# Run for additional info in the Viewer pane
info("R Basics II: Graphical illustration with ggplot2")
```

Having learned the basics of `ggplot2`, you are now prepared to complete the task of creating the graph for the commodity price evolution step by step.

**Task 12:** To begin with, we present the **price movement of Cavendish banana**. Please fill in the blanks in the following chunk, *which should specify the following:* Remember, the `initial function` to start the creation of the plot. We use the data set `df_figure_rep` and map the `year` variable to the x-axis and the `bananaprice` variable to the y-axis. We draw a `"blue" line` with `geom_line()` to connect the data points. The x-axis should scale from the year `2000 to 2010` by a `step size of 2`. *Recall the previous Info block if you have problems!* **Additionally, it is important to remember the correct usage of quotation marks!**

```{r "7_11",fig.width=10, fig.height=6}
Figure_2_banana <- ___(data = ___, aes(x = year, y = ___)) +  
  ___(color = ___, linetype = "solid", linewidth = 1.5) + 
  scale_x_continuous(breaks = seq(2000, ___, by = ___), limits = c(2000, 2010)) +
  labs(x = "Year", y = "Price (2010 $/kg)", title = "Cavendish Banana") + 
  theme_bw() + #Defines the plot theme
  theme(
    plot.title = element_text(hjust = 0.5),  #Defines the position of the title
    panel.grid.major = element_line(color = "gray"), #Defines the major plot grid line color
    panel.grid.minor = element_blank(), #Defines the minor plot grid line color
    axis.text = element_text(color = "black"), #Defines the axis text color
    axis.ticks = element_line(color = "black"), #Defines the axis ticks line color
    plot.background = element_rect(fill = "white"), #Defines the plot background color
    panel.background = element_rect(fill = "white") #Defines the panel background color
  )

Figure_2_banana
```

**Congratulations!** You have successfully created your first own plot with the `ggplot2` package. This graph shows the time trend of the Cavendish banana price from 2001 to 2009. For comparison purposes, prices have been consistently adjusted to 2010 USD. As stated by Crost and Felter (2020, p. 1498) and the visual representation of the data, we can observe that the price exhibits a downward trend between 2001 and 2003, followed by an upward movement from 2003 onwards with a minor decline during the financial crisis in 2007. *To explore the implications of this pattern, we will first examine the other commodity prices.*

**Task 13:** Now, we aim to present the **price dynamics of the four commodities sugar, Lacatan, Saba, and Cavendish banana in one figure**. To do so, please fill in the blanks in the following code chunk. *The comments behind each line provide specific instructions for the blanks.* **Recall the previous Info block for reference and remind yourself of the correct usage of quotation marks!** The last line of the code chunk is different from the others. It uses the `ggarrange()` function from the `ggpubr` package to *display our four plots of the commodity price movements in one figure.* Therefore, we need to specify the number of columns and rows of the figure as arguments.

```{r "7_12",fig.width=10, fig.height=6}
#Plot for the sugar price: 
___ <- ggplot(data = df_figure_rep, aes(x = year, y = ___)) + #Save the plot in the variable "Figure_2_sugar" and map the "year" variable on the "sugarprice" variable
  geom_line(___ = "blue", linetype = "solid", ___ = 1.5) + #Specify the corresponding arguments
  ___(breaks = seq(2000, 2010, by = 2), limits = c(2000, 2010)) + #Add the function to scale the x-axis
  labs(x = "Year", y = "Price (2010 $/kg)", title = "Sugar") +
  theme_bw() +
  theme(
    plot.title = element_text(hjust = 0.5),
    panel.grid.major = element_line(color = "gray"),
    panel.grid.minor = element_blank(),
    axis.text = element_text(color = "black"),
    axis.ticks = element_line(color = "black"),
    plot.background = element_rect(fill = "white"),
    panel.background = element_rect(fill = "white")
  )

#Plot for the Lacatan banana price:
Figure_2_lacatan <- ___(data = df_figure_rep, aes(x = ___, y = lacatanprice)) + #Create the plot with the initial function and map the "year" variable on the "lacatanprice" variable
  geom_line(color = "blue", linetype = "solid", linewidth = 1.5) +
  scale_x_continuous(breaks = seq(2000, 2010, by = 2), limits = c(2000, 2010)) +
  ___(x = "Year", y = "Price (2010 $/kg)", title = "Lacatan Banana") + #Add the function to label both axis and the title
  theme_bw() +
  theme(
    plot.title = element_text(hjust = 0.5),
    panel.grid.major = element_line(color = "gray"),
    panel.grid.minor = element_blank(),
    axis.text = element_text(color = "black"), 
    axis.ticks = element_line(color = "black"),
    plot.background = element_rect(fill = "white"),
    panel.background = element_rect(fill = "white") 
  )

#Plot for the Saba banana price: 
Figure_2_saba <- ggplot(data = ___, aes(x = ___, y = ___)) + #The "year" variable should now be mapped on the "sabaprice" variable
  ___(color = "blue", linetype = "solid", linewidth = 1.5) + #Add the data point line
  scale_x_continuous(___ = seq(2000, 2010, by = 2), limits = c(2000, 2010)) + #Specify the scale on the x-axis
  labs(x = "Year", y = "Price (2010 $/kg)", title = "Saba Banana") +
  theme_bw() +
  ___( #Modify optical adjustment of the graph
    plot.title = element_text(hjust = 0.5),
    panel.grid.major = element_line(color = "gray"),
    panel.grid.minor = element_blank(),
    axis.text = element_text(color = "black"),
    axis.ticks = element_line(color = "black"),
    plot.background = element_rect(fill = "white"),
    panel.background = element_rect(fill = "white")
  )

#We want to illustrate our four created plots in one figure. We do so with the "ggarrange()" function from the "ggpubr" package
library("ggpubr")

Figure_2 <- ggarrange(Figure_2_banana, Figure_2_sugar, ___, ___, ncol = 2, nrow = 2) #Write down our four created plots as arguments in the "ggarrange()" function

Figure_2 

```

**Great!** According to Crost and Felter (2020, p. 1498) and the presentation of the four commodity prices in one figure, it shows that the price of *sugar follows a similar trend as the Cavendish banana*, but with *higher volatility*. The price of sugar declined slightly from 2001 to 2004, then increased in 2006, before bouncing during the financial crisis in 2007 and rebounding in 2009. In contrast, the price of Lacatan and Saba bananas, consumed nationwide, showed a steady upward trend in prices.


Quiz: If you look at the price development of the Cavendish banana variety, how would you categorize the movement?

(1) As a linear function
(2) As a nonlinear function

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("Linearity of Cavendish banana Price movement")
```


<br/>

## Exercise 3 -- Empirical Analysis

In this chapter, we address the following questions: 

* How can we evaluate if there is a causal relationship between provincial violence and Cavendish banana price fluctuations, considering the regional variation in banana production? 

* What are other factors that affect the results of the underlying framework?

* How can we address these influences?

To answer these questions, we rely on the Difference-in-Difference (DiD) methodology. In this chapter, we produce a general introduction of this approach and its necessary assumption. Moreover, we proceed with a systematic exploration of regression analyses, starting with a preliminary, simple regression model and leading up to the main regression framework at the end of the chapter. 

Throughout this progression, we derive the DiD estimator through manual computation and then elaborate the regression-based methodology that enhances the computational efficiency of the DiD estimator. During our process, we illuminate the significant role of Fixed Effects and Control Variables within the DiD setup. 

In addition, this chapter introduces you to an approach outlined by Kranz (2021) to validate the assumption of parallel trends, which is central to the relevance of the DiD setting. 

Finally, it is shed light upon Cluster Robust Standard Errors and the implementation of the key regression analysis conducted by the researchers, examining the resulting implications. This regression analysis provides the foundation upon which subsequent investigations, extensions and robustness checks are built throughout this Problem Set.

### Framework

3.1 Introduction to the DiD Approach

3.2 DiD Adjustment, Parallel Trend Assumption and Control Variables

3.3 Last Modifications and Key Analysis Results

<br/>

## Exercise 3.1 -- Introduction to the DiD Approach

Fredriksson and Magalhães de Oliveira (2019, p. 519-520) state that the **Difference-in-Difference (DiD) approach** is a common empirical method in economics. The purpose of the DiD estimator is to *measure the causal effect of a treatment or event* on a group that received it (**treatment group**), relative to a group that did not (**control group**). The DiD estimator is obtained by subtracting the difference between the treatment and control group in the *post-treatment phase* from the difference between them in the *pre-treatment phase*. This requires that data on the outcome variable of interest for both, the treatment and control group, are available before and after the treatment, to obtain robust results. 

The inclusion of a control group in the DiD design makes it possible to address for any fluctuations in the outcome variable over time, such as seasonal effects, which are not associated with the general investigation framework. This correction ensures that the estimator remains unbiased, as stated by Kranz (2021).

To express the DiD formally, the following equation can be derived and is suitable for a manual computation of the DiD estimator, as Fredriksson and Magalhães de Oliveira (2019, p. 521) explained:

<br/>

$$DiD = (\overline{y}_{post,tr} - \overline{y}_{post,co}) - (\overline{y}_{pre,tr} - \overline{y}_{pre,co})$$

$\overline{y}$ represents the mean value of the outcome variable for each group and phase. The pre-treatment phase is ${pre}$ and the post-treatment phase is ${post}$. **The post-treatment phase is also commonly referred to as the experimental phase in economic literature.** The group that underwent the intervention is ${tr}$ and the group that did not is ${co}$.  

The approach can be better comprehended by using a graphical representation, as shown in Figure 11:

![](Image_11_DiD.png)

<br/>

A group's trajectory is changed by an event that occurs at a certain time and has a greater impact on it. This group is regarded as the treated group and the measured effect is attributed to the event as the cause of the change in the group’s trajectory. This deviation in trajectory compared to the parallel trend scenario in line with the control group, measures the DiD estimate.

Figure 11 illustrates a key assumption that is required for the DiD approach to be valid and to obtain a consistent estimator for the causal treatment effect. This is the *assumption of parallel trends* in the pre-treatment phase! **It implies that in the absence of treatment, the outcome variable of interest would have evolved in the same way for both the treatment and the control group over time**. Typically, a graphical test of the parallel trend assumption is performed. The assumption leads to the inference that the estimated impact is attributable to the treatment alone and not to a mixture of other factors as well as those that generate different default pre-trends. This enhances the credibility of the estimate, as explained by Fredriksson and Magalhães de Oliveira (2019, p. 523).

<br/>

Having acquired the essential knowledge of the core DiD methodology, we proceed to examine the *baseline approach employed by the study*. As an **iterative process**, we will progressively approach the core baseline regression, that occurs at the end of this chapter. The iterative process towards the end of Chapter 3 is illustrated below:

* *Starting point:* We will conduct an initial small analysis as a base from which to adjust our setting. This small analysis will only involve two years of observation. In this setup, we will compute the DiD estimator manually and verify it with a regression-based approach. **(Exercise 3.1)**

* *First iteration step:* We will adjust the initial small analysis from the starting point and include the *pricing variable* in the regressor. Moreover, we also incorporate Control Variables into the analytical framework. **(Exercise 3.2)**

* *Second iteration step:* We will adjust the regression framework from the first iteration step and incorporate the *production variable* in the regressor. Afterwards, we will employ the key analysis results from the baseline regression of this study. **(Exercise 3.3)**

<br/>

The general framework throughout the study and the iterative process is as follows: 

Crost and Felter (2020, p. 1499) explained that their empirical DiD strategy relies on *fluctuations in the global market price, along with provincial-level changes in the production of Cavendish bananas*. The provinces with Cavendish banana cultivation constitute our **treatment group**, as we anticipate them to be affected by the evolution of the world market price. The provinces without Cavendish banana production form our **control group**. Our observation period is from 2001 to 2009. There, we want to measure the **impact of the treatment, which corresponds to a significant increase in the price of Cavendish bananas, occurred from 2005 onwards, on both groups and consequently the influence on provincial potential for conflict!**

<br/>

*Let us start with the starting point of the iteration process towards the key regression results!* 

<br/>

## Starting Point

Our **first objective is to compute the DiD estimator manually**, applying the formula that we have previously specified. Moreover, at the end of this exercise, we will **verify the computed estimator, using the regression-based approach** for the DiD estimation. To accomplish this task, we employ the helpful R programming language. 

<br/>

**Task 14:** The initial move is to import the main data set for the calculation. The required package should be loaded and the data set `replication_data.dta` should be read in using the `read_dta()` function, as you have previously learned. The resulting data frame should be stored in the variable `data`.

```{r "9_1"}
#Load the necessary package, import the data, and save it in the correct variable
```

The next step aims to subset the data set to include only the observations from the *years 2001 to 2009*. Although the available data are from this time period, there are *two rows of observations that have missing values for all variables*. To exclude these rows, the `filter()` function is applied with the `year column` as the argument. The `na.omit()` command is **not used**, as it would remove any row that has at least one missing entry. 

**Task 15:** Fill in the following blanks using the knowledge you have acquired. *Apply the appropriate logical operator!* Load the required `dplyr` package and make use of the **Pipe Operator**. Filter the data frame according to the year variable. Finally, assign the resulting data frame to the object `data_table`.

```{r "9_2"}
___("dplyr")

___ <- data ___
  ___(., year >= ___ & year <= ___) 
```

<br/>

Since we want to manually compute the DiD estimator first, we need to execute a coherent approach step-by-step. This *step-by-step procedure for manually calculating the DiD estimator is based on the nice Economics and R Blog from Prof. Dr. Sebastian Kranz of Ulm University* which can be accessed [here](https://skranz.github.io/r/2021/10/20/ParallelTrendsPlot.html).

The goal is to calculate the DiD estimator, which **consists of four components**. We need to compute the **means of the provincial number of violent incidents** for the **treatment** and **control** group during the **pre-treatment** and **post-treatment** phase. 

We examine the effect of fluctuating Cavendish banana prices, which have a different impact on both groups due to their distinct cultivation patterns, in relation to the treatment event that occurred in 2005. Therefore, *we define the pre-treatment phase as the years from 2001 to 2005* and the *post-treatment phase (often known as experimental phase) as the years from 2006 to 2009*. 

```{r eval=FALSE}
# Run for additional info in the Viewer pane
info("mutate() function")
```

**Task 16:** For the manual calculation, we need to adjust the central `data_table` data set. *We do it step by step.* In the initial starting point analysis of the DiD methodology, the observation period is not extended over the entire period from 2001 to 2009. Instead, a *subdivided temporal framework is adopted that includes a single year within the pre-treatment phase and another within the post-treatment phase*. Given that the treatment event occurred in the median year 2005, the *years 2003 and 2008* are selected as representative temporal data points for the calculation. This choice is based on the rationale that these years approximate the median of the respective pre- and post-treatment periods. Next, we want to *include additional columns*, which are necessary for the calculation of the DiD estimator constituents. We create the new variables `cavendish_price` and `cavendish_production`, which are the Cavendish price and provincial production volume, respectively. Additionally, we specify the new variable `group`, which has entries that describes if the observation is in the control or treatment group based on the variable `cavendish2002_pop`, indicating the occurrence of provincial Cavendish banana cultivation. Next, we add the variable `treat`, which is a *dummy variable. It takes the value of 1, if the observation is in the treatment group and 0 otherwise.* Moreover, we add the variable `exp` which describes the post-treatment phase. It is a *dummy variable, which takes the value of 1, if the observation is from the years 2006 to 2009 and 0 otherwise.* Lastly, we create the **central interaction variable** `treat_exp` as a multiplication of both variables. **Since we want to estimate the DiD effect on the outcome variable, we need to employ an interaction between two predictors.** As we are interested in the changing trajectory of the treatment group after the treatment event, *these values are of interest*. With the interaction `treat_exp` we address exactly these values, since this **interaction term will only take the value of 1, if the observation of the outcome variable is in the treatment group and in the experimental phase!** Everywhere else the value of the interaction will become zero. The code for this step by step adjustment is given below, just `check` the following chunk.

```{r "9_3"}
data_DiD <- data_table %>%
  filter(., year %in% c(2003, 2008)) %>%
  mutate(
    cavendish_price = bananaprice,
    cavendish_production = cavendish2002_pop,
    group = ifelse(cavendish2002_pop == 0, "control", "treat"),
    treat = ifelse(group == "treat", 1, 0),
    exp = ifelse(year > 2005, 1, 0),
    treat_exp = treat * exp
  )
```

*Great!* With this `data_DiD` data frame it is now possible to calculate the different means for both groups and phases. 

**Task 17:** Your task is now to correctly calculate the mean values of the provincial number of violent incidents `vinc` for the specific groups and phases. `y_pre_tr` describes the mean value of the treatment group in the pre-treatment phase. Likewise, `y_exp_tr` is the mean value of the treatment group in the post-treatment phase. `y_pre_co` and `y_exp_co` are similar just for the control group. Fill in the blanks either with **1** or **0** to correctly filter the observations in the `data_DiD` data frame according to their affiliation to the specific group and phase. **Remember** what the variable `treat` and `exp` tells us!

```{r "9_4"}
y_pre_tr <- mean(filter(data_DiD, treat == ___, exp == ___)$vinc) %>% round(3)
y_exp_tr <- mean(filter(data_DiD, treat == ___, exp == ___)$vinc) %>% round(3)
y_pre_co <- mean(filter(data_DiD, treat == ___, exp == ___)$vinc) %>% round(3)
y_exp_co <- mean(filter(data_DiD, treat == ___, exp == ___)$vinc) %>% round(3)

```

*You have correctly created the mean values for the DiD estimator, great!* 

<br/>

Let us look at the four values which are used to calculate the DiD estimator.

**Task 18:** In the following code chunk, a tabular representation is constructed to illustrate the DiD components. Just `check` the code section. Should you wish to explore the mechanics of the table construction, the comments within the code may offer further insight.

```{r "9_5"}
#Load the necessary "kableExtra" package for optical adjustments of the table
library("kableExtra")

#Create a data frame "const_DiD", which displays the created mean values for every group and phase. As the values are all illustrated in one row, with four columns, we need to transpose the data frame with the "t()" function
const_DiD <- data.frame("Pre.treatment.Treatment.group" = y_pre_tr, "Post.treatment.Treatment.group" = y_exp_tr, "Pre.treatment.Control.group" = y_pre_co, "Post.treatment.Control.group" = y_exp_co) %>%
  t() %>%
  as.data.frame() 

#We are left with a data set, which contains four rows of description and one column with the mean values. This column must be renamed with the function "colnames()"
colnames(const_DiD) <- "Values" 

#Here we create the table output with some optical adjustment using the "kable_styling()" and "row_spec()" specifications
kable(const_DiD, format = "html", caption = "DiD Constituents.", position = "left") %>%
  kable_styling() %>%
  row_spec(seq(1, 2, 1), background="#ecf6ff")

```

The examination of the data presented in the table above reveals that, after the treatment event in 2005, regions engaged in the cultivation of Cavendish bananas (*treatment group*) observed an escalation in the mean provincial number of violent occurrences, rising from 9.409 to 9.818. Conversely, regions avoiding the production of Cavendish (*control group*) witnessed a reduction in the average provincial frequency of violent incidents, which decreased from 5.527 to 4.564.

**Task 19:** Using the previous table, please fill in the following blanks to compute the DiD estimator. **Use the created variables** `y_pre_tr`, `y_exp_tr`, `y_pre_co` and `y_exp_co` **for the calculation, not just the numeric values behind them!** *Apply the knowledge you have learned and the information about the formula provided at the start of this exercise!*

```{r "9_6"}

#First calculate the difference between the means of the two groups during the post-treatment phase
y_exp <- ___ - ___

#Second calculate the difference between the means of the two groups during the pre-treatment phase:
y_pre <- ___ - ___

#Lastly, put the two variables you have just calculated into the following blanks to correctly calculate the DiD estimator according to the formula at the start of this exercise
DiD <- ___ - ___

DiD

```

What does the DiD estimator tell us. *In our initial two-year case*, the DiD estimator yields a positive value. This suggests that, relative to the control group, we *would expect a 1.37 larger increase in the mean number of violent incidents for provinces that cultivate Cavendish bananas!*

<br/>

To verify this DiD coefficient, we adopt a more efficient, accurate, and robust method of estimating it. *Typically, this involves fitting a regression model on the data.* Therefore, we examine a **regression-based approach to estimate the DiD coefficient for the two-year case of the starting point**. This can be done using the `feols()` function from the `fixest` package in R. 

**This function is of crucial importance and will guide us through all the analyses in this Problem Set!**

<br/>

The `feols()` function has the following **syntax:** 

*feols(dependent variable ~ independent variables + Control Variables | Fixed Effects | Instrumental variable, data, weights, cluster)*

<br/>

Before we move forward and verify the manual computed DiD coefficient, it is important to gather the essential knowledge needed for the ongoing development of this Problem Set. Having said that, we now learn about **Fixed Effects in the DiD setup!** 

<br/>

## Fixed Effects (FE)

In the subsequent stages of this Problem Set, *we choose to use the regression-based approach to implement the DiD methodology*, as it allows for faster computation of the estimates and reduces susceptibility to error. Consequently, a clarification of the term Fixed Effects (FE) is necessary, as the authors incorporate them in their further DiD analyses.

The main goal of conducting the regression analysis is to obtain an **unbiased estimate of the DiD coefficient** that enables us to infer possible causal relationships of the Cavendish banana cultivation on the frequency of provincial violence. Collischon and Eberl (2020, p.291f.) state that the *stringent condition of exogeneity* must be satisfied to achieve an unbiased DiD estimate. That is $cor(treat*exp, {\varepsilon}) = 0$ The error term ${\varepsilon}$, which captures the influence of unobserved variables, should be *uncorrelated with the independent interaction term* $treat*exp$. By incorporating FE, we can solve this stringent requirement. For instance, if we add a time-varying FE, like the `year` variable, the interaction term that varies over time should be **independent just of the time-varying component of the error term** ${u}_{t}$, $cor(treat*exp, {u}_{t}) = 0$. Hence, FE models allow us to account for the influence of unobserved variables, which lack reliable data sources, and measure their impact on the outcome variable. 

**Therefore, mentioned by Collischon and Eberl (2020, p.291f.), FE estimations offer the advantage of reducing the possible sources of bias in the estimates.** This requirement is more attainable in most implementations than the stringent exogeneity condition. 

<br/>

Before advancing to our initial small analysis based on the regression approach, and check the correctness of the manual computed initial DiD coefficient, we must verify the validity of a common assumption for FE in regression models, which is usually not an issue in most panel data settings. We evaluate the **balance of our panel data set**. This condition can be evaluated and confirmed, by ensuring that *approximately all provinces have full observations for each year*. 

<br/>

Our aim is to assess the balance of our data set by visualizing it in a graphic. We use a *histogram to display the frequency of observations for each province in the Philippines*, identified by their unique province code `pcode`. The histogram is constructed with the `ggplot2` package and the `geom_histogram()` function. To aggregate the data by province, we apply the `group_by()` and `summarise()` functions.

```{r eval=FALSE}
# Run for additional info in the Viewer pane
info("group_by() in combination with summarise()")
```

**A balanced data set would imply that every province has the same number of recorded years, which is nine in our case, corresponding to the period from 2001 to 2009.**

**Task 20:** To generate the histogram and evaluate the balance of our data set, you need to fill in the blanks using the `group_by()` and `summarise()` functions, which are explained in the Info block above. You also need to use the `ggplot2` package to create a graphical representation of the data. The goal is to *obtain the number of reported years per unique province* of the data set `data_table`. Therefore, you should create a new variable called `Number_of_reported_years` by summarizing the grouped variable `pcode`, which contains the unique province codes. *You should then map this newly created variable on the x-axis* of the histogram.

```{r "9_8",fig.width=10, fig.height=6}
library("ggplot2")

___ %>% #Use the "data_table" data frame as the base of the histogram
  group_by(___) %>% #group_by() the unique province code
  ___("Number_of_reported_years" = n()) %>% #Count the number of reported years of every unique grouped province
  ___(data = ., mapping = aes(___ = Number_of_reported_years)) + #Creates the plot with the defined x-axis
  geom_histogram(binwidth = 1) + #Use the histogram
  scale_x_continuous(breaks = 0:9) + #Scales the x-axis
  xlab("Number of reported years per province") + 
  ylab("Number of provinces") + 
  ggtitle("Balanced data? Number of reported years per province") + 
  theme_bw()
```

What do we obtain? The histogram shows that the yearly observation series is complete for almost all provinces since they report the whole period of nine years. *Only two provinces have missing data for one year each, resulting in an eight-year time span for them.* **Thus, the panel data is largely balanced, allowing us to use FE in our regressions!**

<br/>

To address potential annual patterns and unexpected events, the authors **incorporate year FE into their regression analyses**. This approach allows them to consider hidden influences that remain consistent across all provinces but *fluctuate from year to year*. They are adjusting for variables that vary annually and exert an *influence on all provinces in the Philippines*. For example, this might involve the implementation of stricter national tax laws or alterations in agriculture policies over time, impacting all banana plantations and exporters no matter where they locate themselves in the country.

Moreover, the authors also introduce **FE for each province with their unique provincial code**. Likewise, they consider visible influences that remain consistent over time but *differ among provinces*. This entails addressing factors that exhibit stability across years but show *variations between different provinces across the country*. For instance, one could consider specific geographical factors such as farmland fertility or proximity to the nearest major export harbor. These factors uniquely impact the corresponding plantations in the specific province but remain constant over the years.

<br/>

Having acquired a deeper understanding of FE and noting that the *authors use both annual and provincial FE in their regression analyses*, we are now ready to authenticate the manual computed DiD coefficient, taking these influences into account. The optimal approach to substantiate this would be a systematic presentation within a table.

<br/>

A convenient way to display the regression estimates obtained by the `feols()` function is to use the `modelsummary()` function from the `modelsummary` package. This function requires the `feols()` output to be *passed as a list argument*. It **produces a well-formatted table that summarizes the estimated coefficients and other relevant statistics**. The table appearance can be customized by specifying output options such as title, significance stars, the number of displayed dependent variables, notes, and some additional statistics. The `modelsummary()` function can be combined with the `kableExtra` package to enhance the table output. 

**Task 21:** To conduct the described *basic initial regression analysis*, it is necessary to fill in the blanks within the following chunk. It is important to note that the objective is to *explain the variable representing the provincial incidence of violence* `vinc`, operationalized by the constructed interaction term `treat_exp`. Attention must be paid to the FE that the authors have accounted for. These should be accurately integrated into the specified positions within the `feols()` function. *Remember that the authors use year and provincial code FE!* The `modelsummary()` function should then be provided with the `reg_DiD` regression object as a parameter. As the analysis results in a single regression output, it is **not** mandatory to present the regression as a list!

```{r "9_9"}
library("fixest")
library("modelsummary")

reg_DiD = ___(vinc ~ ___ | ___ + ___, data = data_DiD) #Performs the regression analysis

modelsummary(___,
             title = "Verifying the DiD coefficient of the initial small analysis", #Defines the Title of the table
             stars = c("*" = 0.1, "**" = 0.05, "***" = 0.01), #Adds the significance stars
             fmt = 3, #Rounds the coefficients and standard errors for 3 decimal places
             gof_omit = "R2 Within Adj.|AIC|BIC|Std.Errors|FE:", #Removes some additional statistics
             output = "kableExtra") %>%
             row_spec(seq(1, 2 ,2), background="#ecf6ff") #Optical adjustment of the table with different background color 
```

In the statistical output of this regression analysis, we determine the estimated regression coefficient `treat_exp`. Additionally, the output equips us with the standard error and the significance level of the coefficient. Moreover, the statistic provides a comprehensive evaluation of the overall model quality, evidenced by the number of observations, the R-squared values, and the corresponding root-mean-square error of the model. *This represents a substantial benefit over the manual computation of the DiD estimate, as it offers a more efficient analysis.*

Furthermore, the resulting regression coefficient, associated with the interaction term `treat_exp` as our DiD estimator, is in line with the result of our manual calculation. The estimator yields a positive value of 1.37 with a standard error of zero and is highly statistically significant at the 1% level.

<br/>


Quiz: We end this exercise with a small but **mandatory Quiz**. Is the obtained positive DiD treatment effect in line with the knowledge from Exercise 2 about the CSF and the mechanisms of the relationship between varying prices of Cavendish bananas and conflict violence? Does it make sense intuitively?

(1) It is consistent with the knowledge gained
(2) It is inconsistent with the knowledge gained

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("DiD Hypothesis")
```


<br/>

## Exercise 3.2 -- DiD Adjustment, Parallel Trend Assumption and Control Variables

In the previous exercise, we outlined the theoretical underpinnings of the DiD framework through a preliminary small analysis. This served to demonstrate the manual computation of the DiD estimator and to provide an initial understanding of the regression-based methodology that will be used throughout subsequent analyses within this Problem Set. 

**Thus far, our analysis has not verified the parallel trend assumption, which is essential within our analytical framework. Consequently, this raises the question of the appropriateness of using the DiD methodology.**

Because of that, we now proceed to a *careful modification of the DiD framework used in the previous exercise, towards the model of the key results at the end of Chapter 3. This iterative process involves incremental modifications to our initial DiD model, aimed at testing the parallel trend assumption and integrating additional variables into the regression-based approach.* 

The ultimate goal is to **move from the initial small DiD model to the central regression model on which the authors base their findings.** The **key regression specification** that the authors employ is the following regression:

$${Y}_{it} = {\beta}_{0} + {\beta}_{1} * {Cavendish}_{i} * {Price}_{t} + {\alpha}_{i} + {\lambda}_{t} + {\varepsilon}_{it}$$

Let us have a look at this regression and the comments from Crost and Felter (2020, p. 1499) to fully understand the goal of the iterative modification process. The subscripts ${i}$ and ${t}$ indicate the province and year of observation, respectively. The dependent variable of interest, ${Y}_{it}$, measures the frequency of violent conflicts in the province ${i}$ at year ${t}$. The key independent variable is the interaction term of ${Cavendish}_{i} * {Price}_{t}$, where ${Cavendish}_{i}$ is the per capita Cavendish banana production in province ${i}$ and ${Price}_{t}$ is the *natural logarithm* of the world price of Cavendish bananas in year ${t}$. In addition to the interaction term, the regression model includes province FE ${\alpha}_{i}$ and year FE ${\lambda}_{t}$ to control for unobserved heterogeneity across provinces and time periods. The error term, ${\varepsilon}_{it}$, captures the influence of all other unknown and unobserved explanatory variables. 

As shown in the formula and stated by Crost and Felter (2020, p. 1499), the coefficient of relevancy is ${\beta}_{1}$, which reflects the DiD estimator. It measures how the global market price and the Cavendish banana production in each province affect the conflict intensity. If ${\beta}_{1}$ is **positive, it suggests that higher prices are associated with more conflict in Cavendish banana-producing provinces.**

**This regression specification is the central regression that will be applied to the data, and the main target of the modification process towards it.**

*Let us move on to the first iteration step!*

<br/>

**Task 22:** The initial move is as always to import the main data set for the analysis. The required package should be loaded and the data set `replication_data.dta` should be read in using the `read_dta()` function, as you have previously learned. The resulting data frame should be stored in the variable `data`.

```{r "10_1"}
#Load the necessary package, import the data, and save it in the correct variable
```

**Task 23:** The next step is to fill in the following blanks to subset the data set and include only the observations from the *years 2001 to 2009*. *Apply the appropriate logical operator!* Load the required `dplyr` package and make use of the **Pipe Operator**. Filter the data frame according to the year variable. Finally, assign the resulting data frame to the object `data_table`. Have a look at the last exercise if you have difficulties!

```{r "10_2"}
___("dplyr")

___ <- data ___
  ___(., year >= ___ & year <= ___) 
```

The first stage in the iterative refinement of the evolving DiD model, with the aim of aligning it with the main regression analysis outlined by the authors, **involves the integration of the price development of Cavendish banana**. This is achieved by **adjusting the interaction term within the model framework!**

To do this, we need to consider the framework established in the previous model, where we introduced the variable `exp`. This denotes the temporal phase, either before or after the treatment event, relevant to each observation. The observation period, which spanned from 2001 to 2009, was divided based on the crucial treatment pricing event in 2005, thereby *categorizing observations according to their pricing context*. Therefore, we can now **substitute** the `exp` variable with the **price development of Cavendish banana**. Consequently, our analysis now attempts to explain the provincial number of violent incidents through an interaction term composed of the `treat` and the price variable. 

**Task 24:** Because of that, we need to adjust the central `data_table` data set. This procedure is like in the last exercise, but with some different specifications. Here we use the whole observation period from 2001 to 2009, **not just two years**. Moreover, we also include additional columns. The new variables `cavendish_price`, `cavendish_production`, `group` and `treat` are created as in the previous exercise. What is new is the creation of the adjusted interaction variable `treat_price`. This is a multiplication of these two variables. As we are interested in the changing trajectory of the treatment group after the treatment event, *these values are of interest*. With the interaction `treat_price` we address exactly these values, since this *interaction term will only take the values of the Cavendish banana price, if the observation of the outcome variable is in the treatment group!* Everywhere else the value of the interaction will become zero. Just `check` the following chunk.

```{r "10_3"}
data_DiD_modify <- data_table %>%
  mutate(
    cavendish_price = bananaprice,
    cavendish_production = cavendish2002_pop,
    group = ifelse(cavendish2002_pop == 0, "control", "treat"),
    treat = ifelse(group == "treat", 1, 0),
    treat_price = treat * cavendish_price
  )
```

**Great!** This `data_DiD_modify` data frame will be the base of our iterative refinement process towards the key analysis regression employed by the authors. 

<br/>

We will now improve our existing small regression model, as outlined in the previous exercise, by incorporating the recently formulated interaction term, denoted `treat_price`, into our analytical framework.

**Task 25:** Fill in the blanks to run the regression of *iteration step one towards the key regression analysis*. Remember what our key functions are for performing the regression and displaying the regression statistics! Moreover, use the **newly created interaction term as a regressor in the analysis** to substitute the old `treat_exp` variable from the previous specification. Apply the regression to the newly created data frame.

```{r "10_4"}
library("fixest")
library("modelsummary")
library("kableExtra")

DiD_reg_iteration = ___(vinc ~ ___ | year + pcode, data = ___)

___(DiD_reg_iteration,
             title = "DiD Iteration Step 1 towards the Key Regression Analysis", 
             stars = c("*" = 0.1, "**" = 0.05, "***" = 0.01), 
             fmt = 3, 
             gof_omit = "R2 Within Adj.|AIC|BIC|Std.Errors|FE:", 
             output = "kableExtra") %>%
             row_spec(seq(1, 2 ,2), background="#ecf6ff")

```

What does the `treat_price` estimator tell us. In this first iteration, our DiD estimator yields a positive and little significant value. This suggests that, relative to the control group, we would expect a 3.646 larger increase in the mean number of violent incidents for provinces that cultivate Cavendish bananas, *as a result of a USD1 rise in the global market price of Cavendish banana.* The standard error of the estimator is 1.86. Compared to the estimator of 1.37 from the initial small specification from the previous exercise, **we find statistical evidence that the inclusion of the price development of Cavendish banana significantly increases the frequency of violent events in banana-producing provinces compared to non-cultivating areas!**

<br/>

**As we move forward, it is essential to address the verification of the parallel trend assumption in the DiD setup, which has not been examined so far.** 

Therefore, we will now assess this hypothesis. Nevertheless, given the increased complexity associated with this task, a useful method for evaluating this assumption is outlined by Kranz (2021). This *methodology consists of a series of procedural steps*, which we will perform in R:

1) Estimation of the DiD regression with all Control Variables as regressors, if any exist.

2) Creation of a fictional new data frame in which we fix all independent variables, including the Control Variables, at a constant value of their *mean value* for both, the treatment and control group. *This data set would correspond to the case where no treatment event occurred.* 

3) Predictions for the outcomes in both groups are subsequently generated using the data frame with constant regressors as explained in the second step. *This procedure assumes temporal constancy within the independent variables.* Following this prediction, the residuals derived from the regression of step one are incorporated into the predicted values as *random fluctuations*.

4) Generate a plot of the outcomes.

<br/>

*Let us dive into the verification of the parallel trend assumption according to Kranz (2021)!*

<br/>

We have already performed the first step described by Kranz (2021) by running the modified regression and storing it in the variable `DiD_reg_iteration`, as we do not yet include Control Variables.  

**Task 26:** Second, we create the new data frame `dat0` in which we fix all the regressors at a *constant value of their mean value*. We do this by filling in the blanks. Calculate the `mean` value of our price variable `cavendish_price`. For the `treat` variable, the mean is not necessary because it is a dummy variable, and the interaction term of interest simply changes its values according to the important price variable. Then, to create the `dat0` data frame, overwrite the initial Cavendish prices with the created mean value `mean_cavendish_price`. Finally, create the important interaction term by incorporating the new `cavendish_price` variable.

```{r "10_5"}
mean_cavendish_price <- ___(data_DiD_modify$___)

dat0 <- data_DiD_modify %>% 
  mutate(
   cavendish_price = ___,
   treat_price = treat * ___
)
```

**Task 27:** In the third step, described by Kranz (2021), we predict the outcomes in both groups using the data frame `dat0` with constant regressors. Following this prediction, the residuals derived from the initial regression of this exercise `DiD_reg_iteration` are incorporated into the predicted values. We save these values in the `df_par_trend` data frame, which is an exact copy of the central `data_DiD_modify` data set. **We do this because overwriting data sets over and over could lead to common errors and incorrect values.** In the `df_par_trend` data frame, we save the predicted values in the new column `y0_pred`. Just `check` the following chunk.

```{r "10_6"}

#Creates an exact copy of the central "data_DiD_modify" data set
df_par_trend <- data_DiD_modify

#Predicts the outcomes using constant regressors and incorporates residuals as random fluctuations
df_par_trend$y0_pred <- predict(DiD_reg_iteration, dat0) + resid(DiD_reg_iteration)

```

**Task 28:** Lastly, we *plot the generated outcomes to verify the parallel trend assumption*. The graphic displays the temporal variation of the average number of violent incidents for both treatment and control group. The comments in the code chunk explain the steps involved in generating the graphic. Please read the comments and `check` the chunk.

```{r "10_7",fig.width=10, fig.height=8}

#Load the necessary "ggplot2" package
library("ggplot2")

#We want to display the graphic for the evolution of the number of violent incidents over the observation period. To do so, we firstly need to comprise the data set "df_par_trend" with the "group_by()" and "summarise()" function. We group for the variables "group", "year", and "treat". To display the pathway of both groups over the period of observation, we need to calculate the mean of the outcome variable "vinc" for every specific year and group. With that, we want to verify the parallel trend assumption of the initial small regression from last exercise. The same is applicable for the predicted "y0_pred" values, since we also want to verify the assumption for the first iteration process with the price-adjusted interaction term  
df_aggregate <- df_par_trend %>%
  group_by(group, year, treat) %>%
  summarise(
    y = mean(vinc),
    y0_pred = mean(y0_pred)
  )

#With the following "ggplot()" function, we create the necessary graphic.
ggplot(data = df_aggregate, mapping = aes(x = year, y = y, color = group)) +
  geom_line(linewidth = 1, linetype = "dashed") +
  geom_line(mapping = aes(y = y0_pred), linewidth = 1) +
  geom_vline(xintercept = 2005, linewidth = 1) +
  labs(x = "Year", y = "mean number of violent incidents", title = "Verifying Parallel Trends") +
  scale_x_continuous(breaks = seq(2001, 2009, by = 1), limits = c(2001, 2009)) +
  theme_bw() +
  annotate("label", x = 2002, y = 14, label = "pre-treatment phase") +
  annotate("label", x = 2008, y = 14, label = "post-treatment phase")

```

With this graphic, it is possible to *verify the parallel trend assumption*. According to Kranz (2021), this assumption implies that the control and treatment group would *experience parallel developments, if there were no treatment intervention*. However, the problem is that we cannot monitor the counterfactual pathway for the treatment group without the treatment, so this assumption is not fully testable. Therefore, a widespread practice is to *visually inspect whether the pre-treatment developments of both groups are parallel!* 

This graph provides a *visual representation of the temporal data*. The x-axis describes the temporal progression of the observed period, while the y-axis quantifies the average incidence of violent occurrences at the provincial level. The **bold black vertical line marks the treatment event** that occurs in the year 2005. **Two different trajectories are shown.** The **control group**, which is characterized by the absence of Cavendish banana production, is represented by the **red trajectory**. Conversely, the **treatment group**, which includes provinces engaged in Cavendish cultivation, is represented by the **blue trajectory**. These lines trace the annual evolution of the mean provincial violence for each respective group. 

In the representation, we **distinguish between the trajectory of violence outlined by our preliminary small study**, using the `treat_exp` regressor, represented by the **dashed lines**, and the **trajectory outlined by the specification from the first iteration step**, using the `treat_price` regressor, represented by the **solid lines**.

According to the regression specification, the trajectory of the *control group is expected to remain constant, resulting in a matching of the respective graphs*. The analysis becomes particularly interesting when examining the trajectory of the *treatment group*. A test of the parallel trend hypothesis during the pre-treatment phase shows that the trajectory, represented by the *dashed line, approximates that of the control group*. The subsequent modifications through the first iteration process, indicated by the **solid line, suggest an increasing alignment of the trajectory of the treatment group with that of the control group, reaching almost complete parallelism!** The post-treatment trajectories for the treatment group are almost similar for both the initial small analysis and the modification of iteration step one under price inclusion.
 
Therefore, we **find strong graphical evidence for the applicability of the DiD estimator through the correct verification of the parallel trend assumption!** Furthermore, the graphic indicate that the *control group exhibits a consistently lower frequency of violent incidents than the treatment group during the entire period of observation.* 

<br/>

So far, we presented a regression-oriented approach to investigate the correlation between the frequency of violent occurrences at the provincial level and the prevalence of Cavendish banana cultivation within those provinces.

Our investigation is concerned with the question of **whether the notable fluctuation in Cavendish banana prices observed in 2005 had a greater effect on the frequency of conflict in Cavendish cultivation areas than in non-cultivation provinces.**

The previous graphical examination of the first iterative process reveals a nearly parallel trajectory in pre-treatment trends from 2001 to 2005. However, should there be deviation from parallelism in preceding unobserved years, stochastic variations may be responsible for the observed trends. *Therefore, simply incorporating the relevant variables into the regression analysis typically proves inadequate and is responsible for possible inconclusive logical statements.*

Instead, Kranz (2021) mentioned that it becomes **mandatory to involve additional Control Variables aimed at identifying unaccounted variance within the model.** This is due to the potential existence of unobserved variations in the environment that may act as confounding factors influencing the observed number of provincial violent incidents. *Within the treatment and control group, the disturbance variable exhibits differing patterns over the observed period.* To illustrate that, certain provinces engaged in the cultivation of Cavendish bananas may have been exposed to abnormally high levels of precipitation and heavy rainfall conditions in specific years. The production of Cavendish bananas has been adversely affected by these meteorological conditions, resulting in a diminished output relative to other regions that also engage in the cultivation but are geographically disparate.

Due to the presence of *confounding variables, it remains uncertain whether the pre-trend in provincial incidents for both groups was always parallel.* As a result, we do not have any guarantee that our regression model has accounted for all the hidden variations so far. **In our study, the authors attempt to mitigate potential shortfalls and biases by incorporating Control Variables!**

<br/>

## Control Variables

The inclusion of Control Variables can clarify and correct the possible discrepancies due to confounding factors that diverge from the expected parallel trends. **Recognizing their potential impact on the violence indicator through the supply opportunity of bananas, Crost and Felter account for variations in climatic conditions across provinces.**

The potential for *omitted variable bias can be diminished* by using this approach. Greene (2012, p. 259) notes that a fundamental assumption underlying most of linear regression analyses is the *lack of correlation between the regressor variable and the error term*, $cor(treat*price, {\varepsilon}) = 0$. With that it is possible to isolate the influence of the independent variable on the outcome variable of interest. However, in practical implementations, it is common for the error term to include unobserved variables that, despite being excluded from the regression model, exert an influence on the dependent variable through the regressor, $cor(treat*price, {\varepsilon}) ≠ 0$. *The absence of this key assumption, that the unobserved inferences within the error term remain uncorrelated with the independent variable, leads to endogeneity of the regressor and therefore to the derivation of biased coefficient estimates.* Consequently, the phenomenon, which arises when a variable is correlated with the independent regressor and not included in the regression model, is called *omitted variable bias of the coefficient estimate*. 

Recall that the error term contains all unobserved variables that may affect the outcome and the independent variable. **Therefore, it is mandatory to incorporate those variables from the error term into the regression as Control Variables.** This step is essential in mitigating the endogeneity of the independent regressor and therefore the omitted variable bias. **Thus, the introduction of Control Variables is essential for evaluating a causal relationship attributable to the treatment in our DiD framework.**

The authors include the following common Control Variables in their analyses, which serve to mitigate potential confounding factors that could bias the estimated results:

* `zrain`: Annual rainfall index

* `wetrain`: Wet season rainfall index

* `wettemp`: Temperature during the wet season (mean)

* `temperature`: Temperature during the dry season (mean)

* `typhoon`: Dummy variable, whether the province was hit by a major typhoon or not

<br/>

**These weather impacts and meteorologic events in specific provinces of the Philippines have a significant influence on the Cavendish banana production**. Therefore, these five variables exhibit a high correlation with the independent interaction term $treat*price$, which results in an endogenous regressor, as they are not yet part of the regression but are included in the error term. By controlling for these variables in our analyses, we remove them from the error term and explicitly include them in the regression. Afterwards, we expect the correlation to become nearly zero $cor(treat*price, {\varepsilon}) ≈ 0$. 

**To keep in mind, a correlation coefficient of zero is an idealized value that is never attained exactly in empirical applications, rather, it is only approximated by small values that are close to zero! This is because many more unobserved confounding variables may be part of the error term, which may also influence the regressor but cannot be precisely identified.**

<br/>

*Let us incorporate Control Variables into the regression analysis as a next step of the iteration process towards the model of the key results at the end of Chapter 3! The verification of the parallel trend assumption of this modified DiD approach will also be considered with the help of Kranz (2021).*

<br/>

**Task 29:** As a first step, described by Kranz (2021), fill in the blanks to run the regression of iteration step one towards the key regression analysis **with Control Variables.** *Here we try to explain the frequency of provincial violence with our pricing interaction term* `treat_price` under the *consideration of the described Control Variables*. Remember what our key function is to run the regression, and what our Control Variables are! Apply the regression to the known data frame `data_DiD_modify`.

```{r "10_8"}
DiD_reg_iteration_1 = ___(vinc ~ treat_price + ___ + wetrain + ___ + temperature + ___ | year + pcode, data = ___)

modelsummary(___,
             title = "DiD Iteration Step 1 with Control Variables", 
             stars = c("*" = 0.1, "**" = 0.05, "***" = 0.01), 
             fmt = 3, 
             gof_omit = "R2 Within Adj.|AIC|BIC|Std.Errors|FE:", 
             output = "kableExtra") %>%
             row_spec(seq(1, 2 ,2), background="#ecf6ff")

```

What does the `treat_price` estimator tell us here. In this iteration including Control Variables, our DiD estimator yields a positive and little significant value. This suggests that, relative to the control group, we would expect a 4.775 larger increase in the mean number of violent incidents for provinces that cultivate Cavendish bananas, *as a result of a USD1 rise in the global market price of Cavendish banana.* The standard error of the estimator is 2.34. **Compared to the estimator of 3.646 from the first iteration process without Control Variables, we find statistical evidence that the inclusion of the climatic conditions in form of Control Variables significantly increases the frequency of violent events in banana-producing provinces compared to non-cultivating areas!** Furthermore, we can see how the different Control Variables affect the dependent variable of interest, with the annual rainfall index (`zrain`) being the only significant one. 

<br/>

**Task 30:** Second, as outlined by Kranz (2021) to verify the parallel trends, we create the new data frame `dat1` in which we fix all the regressors and Control Variables at a constant value of their `mean`. We do this by filling in the blanks. You have already calculated the variable `mean_cavendish_price` in a previous chunk of this exercise. To finally create the `dat1` data frame, calculate the mean values for all Control Variables. Finally, generate the important interaction term incorporating the `cavendish_price` variable.

```{r "10_9"}
dat1 <- data_DiD_modify %>% 
  mutate(
   cavendish_price = mean_cavendish_price,
   zrain_mean = ___(zrain),
   wetrain_mean = mean(___),
   wettemp_mean = mean(wettemp),
   temperature_mean = mean(___),
   typhoon_mean = ___(typhoon),
   treat_price = treat * ___
)
```

**Task 31:** In the third step, characterized by Kranz (2021), we predict the outcomes in both groups using the data frame `dat1` with constant regressors. Following this prediction, the residuals derived from the regression `DiD_reg_iteration_1` are incorporated into the predicted values. We save these values in the `df_par_trend` data frame, which you have generated previously. In this, we save the predicted values in the new column `y0_pred_it_1`. Just `check` the following chunk.

```{r "10_10"}
#Predicts the outcomes using constant regressors and incorporates residuals as random fluctuations
df_par_trend$y0_pred_it_1 <- predict(DiD_reg_iteration_1, dat1) + resid(DiD_reg_iteration_1)

```

**Task 32:** Lastly, we *plot the generated outcomes to verify the parallel trend assumption*. The graphic displays the temporal variation of the average number of violent incidents for both treatment and control group. In the graph, **we compare the trajectories of the iteration process 1 including and excluding Control Variables.** It follows the same procedure as the previous representation at the start of this exercise, just `check` it.

```{r "10_11",fig.width=10, fig.height=8}

df_aggregate_1 <- df_par_trend %>%
  group_by(group, year, treat) %>%
  summarise(
    y0_pred = mean(y0_pred),
    y0_pred_it_1 = mean(y0_pred_it_1)
  )

ggplot(data = df_aggregate_1, mapping = aes(x = year, y = y0_pred, color = group)) +
  geom_line(linewidth = 1, linetype = "dashed") +
  geom_line(mapping = aes(y = y0_pred_it_1), linewidth = 1) +
  geom_vline(xintercept = 2005, linewidth = 1) +
  labs(x = "Year", y = "mean number of violent incidents", title = "Verifying Parallel Trends with Control Variables") +
  scale_x_continuous(breaks = seq(2001, 2009, by = 1), limits = c(2001, 2009)) +
  theme_bw() +
  annotate("label", x = 2002, y = 14, label = "pre-treatment phase") +
  annotate("label", x = 2008, y = 14, label = "post-treatment phase")

```

With this graphic, it is possible to *verify the parallel trend assumption*. This graph provides a visual representation of the temporal data. The general setting of the axes and trajectories is like in the graphic before, without the incorporation of Control Variables. 

However, one thing is different. We now **distinguish between the trajectory of violence outlined by our first iteration step**, using the `treat_price` regressor **without Control Variables, represented by the dashed lines**, and the **trajectory outlined by the specification from the first iteration step**, using the `treat_price` regressor **with Control Variables, represented by the solid lines!** 

As before, the trajectory of the control group is expected to remain constant. A test of the parallel trend hypothesis during the pre-treatment phase shows that the **treatment trajectory with Control Variables, represented by the solid line, approximates that of the control group more than the dashed line without the Control Variables.** The modification through the addition of Control Variables, on the first iteration process, therefore suggest an increasing alignment of the trajectory of the treatment group with that of the control group, reaching almost 100% parallelism!


Quiz: Through the findings of the graphical representation above, does it make sense to incorporate Control Variables into ongoing regression analyses?

(1) It does make sense
(2) It does not make sense

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("Control Variables Conclusion")
```


<br/>

## Exercise 3.3 -- Last Modifications and Key Analysis Results

Remember, our interaction term of the baseline regression specification of the key analysis results is ${Cavendish}_{i} * {Price}_{t}$. *It captures the multiplication of the price variable and the output of Cavendish bananas.*


Quiz: Throughout the iterative process, we have used the interaction term `treat_price` as a way of explaining the provincial incidence of violence. Consequently, what modifications can be made to this interaction term in the final iteration process to capture the one of the key analysis results?

(1) Integrate the provincial code
(2) Integrate the provincial Cavendish production
(3) Integrate the provincial weather conditions

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("Last Iteration Process")
```

Why is this applicable? The usefulness of the `treat` variable lies in its function as a *binary indicator*, identifying provinces as part of the treatment group if they engage in Cavendish production (indicated by a value of 1) or the control group if they do not (indicated by a value of 0). *The Cavendish production variable also follows this distinction. A value other than zero indicates the presence of Cavendish cultivation in a province, placing it in the treatment group, while a value of zero indicates the absence of such production, placing the province in the control group!* Consequently, the Cavendish production value serve as an additional measure to differentiate between the two groups.

<br/>

*Let us have a look at this regression modification as the second and last iteration process towards the key results!*

<br/>

**Task 33:** The initial move is as always to import the main data set for the analysis. The required package should be loaded and the data set `replication_data.dta` should be read in using the `read_dta()` function, as you have previously learned. The resulting data frame should be stored in the variable `data`.

```{r "11_1"}
#Load the necessary package, import the data, and save it in the correct variable
```

**Task 34:** The next step is to fill in the following blanks to subset the data set and include only the observations from the *years 2001 to 2009*. *Apply the appropriate logical operator!* Load the required `dplyr` package and make use of the **Pipe Operator**. Filter the data frame according to the year variable. Finally, assign the resulting data frame to the object `data_table`.

```{r "11_2"}
___("dplyr")

___ <- data ___
  ___(., year >= ___ & year <= ___) 
```

The last stage in the iterative refinement of the evolving DiD model, with the aim of aligning it with the main regression analysis outlined by the authors, involves the **integration of the development of provincial Cavendish banana production output. This is achieved by adjusting the interaction term within the model framework.**

As described at the start, to do this, our aim is to substitute the `treat` variable of the interaction term with the Cavendish production output.

**Task 35:** Because of that, we need to adjust the central `data_table` data set. This procedure is like in the last exercise, but with some different specifications. Please fill in the blanks to include additional columns. The new columns `cavendish_price` and `cavendish_production` are just the renamed variables of the columns `bananaprice` and `cavendish2002_pop` respectively, for a better understanding. Moreover, *create the central interaction term* `prod_price`, which is a multiplication of the created Cavendish production and price variable. The interaction term `prod_price` *will only take the values of the Cavendish banana value, if the observation of the outcome variable is in the treatment group!* Everywhere else the value of the interaction will become zero. **We specify the "Cavendish banana value" as a linguistic term of the multiplication of the banana output with its price!**

```{r "11_3"}
df_modify_CV <- data_table %>%
  mutate(
    cavendish_price = ___,
    cavendish_production = ___,
    group = ifelse(cavendish2002_pop == 0, "control", "treat"),
    prod_price = ___ * ___
  )
```

<br/>

We will now improve the existing regression analysis under the *incorporation of Control Variables*, as outlined in the previous exercise, by substituting the `treat_price` interaction term with the newly created *Cavendish banana value* `prod_price` in our analytical framework.

**Task 36:** Fill in the blanks to run the regression of the last iteration step towards the key regression analysis. Remember what our key functions are for performing the regression and displaying the regression statistics! Moreover, use the newly created interaction term as a regressor to explain the frequency of provincial violence. Incorporate all Control Variables! Apply the regression to the newly created data frame `df_modify_CV`.

```{r "11_4"}
library("fixest")
library("modelsummary")
library("kableExtra")

DiD_reg_CV = ___(___ ~ ___ + zrain + wetrain + wettemp + temperature + ___ | year + pcode, data = ___)

___(___,
             title = "Last Iteration Step with Cavendish Banana Value as Regressor", 
             stars = c("*" = 0.1, "**" = 0.05, "***" = 0.01), 
             fmt = 3, 
             gof_omit = "R2 Within Adj.|AIC|BIC|Std.Errors|FE:", 
             output = "kableExtra") %>%
             row_spec(seq(1, 2 ,2), background="#ecf6ff") 

```

What does the Cavendish banana value estimator (`prod_price`) tell us here. In this last iteration, our DiD estimator yields a small positive and non-significant value. This suggests that, relative to the control group, we would expect an 0.238 larger increase in the mean number of violent incidents for provinces that cultivate Cavendish bananas, *as a result of a USD1 rise in the global market price of Cavendish banana in combination with a provincial baseline Cavendish banana production of 1kg!* The standard error of the estimator is 0.128. Furthermore, we can see how the different Control Variables affect the dependent variable of interest, of which only the annual rainfall index (`zrain`) and the wet season rainfall index (`wetrain`) are significant. 

<br/>

**Great, we are approaching the key baseline regression specification used by the researchers in their analysis. However, there are still two minor specifications included by the authors that need to be addressed.**

<br/>

In the previous last iteration, it was observed that the DiD estimator under consideration did not yield a statistically significant result. Moreover, the estimator presented interpretation challenges due to the *manifestation of price increases in absolute US dollar terms.* Consequently, the researchers adopted the **natural logarithm of the Cavendish banana price in their fundamental regression framework**. This change allows for a more intuitive interpretation of the estimator, as it now reflects the **percentage increase in the world market price of Cavendish banana, a metric that is more commonly used.**

The second modification introduced by the authors is the implementation of **Cluster Robust Standard Errors as the standard default for error estimation.** 

<br/>

*Both modifications will now be discussed and applied!*

<br/>

## Cluster Robust Standard Errors

A question that still needs to be addressed is *how to choose the appropriate standard errors for the regression analyses*. The regression method only provides an estimate of the coefficient $\hat{\beta}$, which may differ from the true coefficient ${\beta}$. Therefore, $\hat{\beta}$ is a random variable that has its own standard error, which can be estimated. Stated by Abadie et al. (2017, p. 3f.), the standard error is a *measure of reliability of the coefficient estimate*. It indicates the **degree of precision of the regression coefficient estimator**. The **variance of the estimator** can be expressed by the following formula, where $\Omega$ is the covariance matrix and $\mathbf{X}$ is the matrix that contains a column of ones and the independent variables of the regression: 

$$\mathbb{V}(\hat{\beta}) = (\mathbf{X}^{T}\mathbf{X})^{-1} * (\mathbf{X}^{T}\Omega\mathbf{X}) * (\mathbf{X}^{T}\mathbf{X})^{-1}$$

According to Abadie et al. (2017, p. 3f.) the **default normal standard error in R** does not account for any clustering and assumes that the covariance matrix $\Omega$ is *diagonal*. $\Omega$ exclusively comprises non-zero elements along the diagonal, representing the variances, while all off-diagonal elements, denoting the covariances, are zero. Based on that crucial and necessary assumption regarding the R default standard error, the **final formula for the standard error estimate can be described as follows**, where $\sigma^{2}$ represents the variance of the regression error term $\varepsilon$: 

$$\hat{SE}(\hat{\beta}) = \sqrt{\mathbb{V}(\hat{\beta})} = \sqrt{\sigma^{2} * (\mathbf{X}^{T}\mathbf{X})^{-1}}$$

The error terms need to satisfy the *iid (independent and identically distributed) assumption* for an unbiased and precise estimation of the **default R regression coefficient standard error**. However, our study employs *panel data* that consists of several annual observations, which are categorized into *provincial clusters*. Therefore, the authors relax the iid restriction and apply **provincial Cluster Robust Standard Errors** in the regressions, since the limitation of iid error terms cannot be guaranteed to hold. **This method allows the error terms to correlate among themselves in the specific provincial cluster, without affecting the estimates of the regression coefficients!**

*For our needs in this Problem Set, this was the most important part of understanding Cluster Robust Standard Errors!*

For a more in-depth look at this complex subject, it is highly recommended to read the following economic articles:

* Abadie, A., Athey, S., Imbens, G. W., Wooldridge, J. M., (2023): *When should you adjust standard errors for clustering?* The Quarterly Journal of Economics, 138(1), page 1-35. To access, please click [here](https://academic.oup.com/qje/article/138/1/1/6750017) to be directed.

* Cameron, A. C., Miller, D. L., (2015): *A Practitioner’s Guide to Cluster-Robust Inference.* Journal of Human Resources, 50(2), page 317-372. To access, please click [here](https://jhr.uwpress.org/content/50/2/317) to be directed. 

<br/>

## Key Analysis Results

Our aim is to validate the primary hypothesis posed in the quiz of the previous Exercise 3.1 through a deep analytical examination of the key results. *The hypothesis stated that a rise in the global market price of Cavendish banana induces a relatively higher frequency of violent incidents in provinces with Cavendish banana cultivation.* It would imply that the treatment effect and thus the DiD estimator is positive and statistical significant! 

To verify the hypothesis, the authors employ the following primary regression specification that you have already explored: 

$${Y}_{it} = {\beta}_{0} + {\beta}_{1} * {Cavendish}_{i} * {Price}_{t} + {\alpha}_{i} + {\lambda}_{t} + {\varepsilon}_{it}$$

If you want to review the regression description, have a look again at Exercise 3.2.

What we have not described so far is that Crost and Felter (2020, p. 1499) stated that they use the **province population in 2000 as weights for the observations. Moreover, they cluster the standard errors at the province level to account for potential heteroskedasticity.**

<br/>

Having reviewed the theoretical framework of the key regression analysis as an iterative process of the whole Chapter 3 of this Problem Set, **we will now perform the key analysis with the natural logarithm and Cluster Robust Standard Error modifications!**

<br/>

*We control for year and provincial FE, using the province population of year 2000 as weights, and employ provincial Cluster Robust Standard Errors in all the regression analyses of this Problem Set*, utilizing the central `feols()` function from the `fixest` package. 

To provide a comprehensive overview of the regression model, it is useful to include some additional statistics at the bottom of the created regression table. These statistics can be added by creating a custom data frame with the `tribble()` function that consists of extra rows. The rows contain information such as the *mean of the dependent variable, the presence of Control Variables, and the number of provinces* included in the specific regression.

<br/>

Before performing the central regression, **one essential comment is necessary to connect the iteration process of Chapter 3 and the key regression analysis!** 

In the last iteration step towards the key regression analysis, we have used the Cavendish banana value `prod_price`, calculated as *cavendish_production times cavendish_price*, as the independent variable. **We have stated that in their key regression, the authors use the natural logarithm of the price variable.** The regressor is then: *cavendish_production times log(cavendish_price)*. **The authors store this resulting interaction term in the central variable** `logcavendishinter2002_pop`!

<br/>

**Task 37:** The following code chunk demonstrates how to perform the key baseline regression analysis in R. *Please pay attention to the comments in the code to deeply understand the logic behind the table creation!* With practice, you will soon be able to do it on your own. Please click on the `check` button.

```{r "11_5"}

#To show the regression results with the "modelsummary()" function, we need to save the regression specifications in a list
Table_2_list <- list(
  
  "(1)" = feols(vinc ~ logcavendishinter2002_pop | year + pcode, data = data_table, weights =  data_table$pop2000, cluster = data_table$pcode), #The first regression with the "feols()" function. "vinc" is the dependent variable, which represents the number of provincial violent incidents. "logcavendishinter2002_pop" is the independent variable and represents the described interaction term of Cavendish banana value with its logarithmic price. "year" and "pcode" are FE variables. The data on which the regression is based on is "data_table". The observations are weighted with the province population in 2000 ("pop2000" variable). Furthermore, standard errors are clustered at provincial level with the "pcode" variable
  
  "(2)" = feols(vinc ~ logcavendishinter2002_pop + zrain + wetrain + wettemp + temperature + typhoon | year + pcode, data = data_table, weights = data_table$pop2000, cluster = data_table$pcode), #In the second regression, we extend the first one with the described Control Variables "zrain", "wetrain", "wettemp", "temperature", and "typhoon" to get more precise and unbiased estimates
  
  "(3)" = feols(vinc ~ logcavendishinter2002_pop + F_logcavendishinter2002_pop | year + pcode, data = data_table, weights = data_table$pop2000, cluster = data_table$pcode), #In the third regression, we extend our baseline approach from regression (1) with an additional independent variable called "F_logcavendishinter2002_pop". This represents the Cavendish banana production times "Lead of Log Price". This "Lead" corresponds to the Log Price in period t+1
  
  "(4)" = feols(vinc ~ logcavendishinter2002_pop + F_logcavendishinter2002_pop + zrain + wetrain + wettemp + temperature + typhoon | year + pcode, data = data_table, weights = data_table$pop2000, cluster = data_table$pcode) #In the last regression, we extend the third one with the described Control Variables
  
)

#We create a tribble, which contains rows that should be involved in the final Table 2. In this tribble, we incorporate the "Mean of dependent variable", rounded for two decimal places, an overview if "Control variables" are used or not, and the "number of provinces", for the specific regressions
rows <- tribble(~term, ~"(1)", ~"(2)", ~"(3)", ~"(4)",
                "Mean of dependent variable", as.character(sprintf("%.2f", mean(data_table$vinc))), as.character(sprintf("%.2f", mean(data_table$vinc))), as.character(sprintf("%.2f", mean(data_table$vinc))), as.character(sprintf("%.2f", mean(data_table$vinc))), 
                "Control variables", "No", "Yes", "No", "Yes", 
                "Year FE", "Yes", "Yes", "Yes", "Yes",
                "Province FE", "Yes", "Yes", "Yes", "Yes",
                "No. of provinces", as.character(length(unique(data_table$pop2000))), as.character(length(unique(data_table$pop2000))), as.character(length(unique(data_table$pop2000))), as.character(length(unique(data_table$pop2000)))) 

#Defines the position of the additional rows of the tribble in the regression Table
attr(rows, 'position') <- c(5:9) 

#The following "modelsummary()" function creates Table 2 with its coefficients, standard errors, and additional rows. Some specifications of how the table looks are adjustable
modelsummary(Table_2_list,
             title = "TABLE 2. The value of banana production and civil conflict.", #Defines the title of the table
             stars = c("*" = 0.1, "**" = 0.05, "***" = 0.01), #Adds the significance stars
             fmt = 3, #Rounds the coefficients and standard errors for 3 decimal places
             coef_map = c("logcavendishinter2002_pop" = "Cavendish prod. (kg per cap.) x Log Price", "F_logcavendishinter2002_pop" = "Cavendish prod. x Lead of Log Price"), #The name of the shown independent variables are overwritten
             coef_omit = "^(?!.*log|.*F_log)", #Just keeps the variables starting with "log" or "F_log" in the table. This coefficient estimates are the essential ones for the possible causal interpretation
             gof_omit = "R2|R2 Adj.|AIC|BIC|RMSE|Std.Errors|FE:", #Removes some additional statistics
             add_rows = rows, #Adds the specified tribble with the additional rows
             notes = 'Notes from Crost and Felter (2020, p. 1500): "Control variables are rainfall and temperature during the wet and dry season, as well as an indicator that takes the value 1 if the province was hit by a major typhoon. Standard errors, clustered at the province level, are in parentheses." *Significant at 10% level, **significant at 5% level, and ***significant at 1% level.', #Adds a note
             output = "kableExtra") %>%
             add_header_above(c(" " = 1, "Dependent variable Violent incidents" = 4)) %>% #Optical adjustment of the table with header above  
             row_spec(seq(1, 4 ,2), background="#ecf6ff") #Optical adjustment of the table with different background color  

```

Table 2 provides insights into the key baseline regression model. **The model examines how the provincial conflict intensity varies with the global market price and the provincial Cavendish banana production.** Column (1) presents the regression results of the interaction term between the Cavendish banana production and the Log Price *(Cavendish banana value)* on the dependent variable of violent incidents. 

The table underlines the finding of Crost and Felter (2020, p. 1499) that the coefficient estimate of the first column is positive and statistically significant at the level of 5%. This suggests a relative increase in conflict intensity in Cavendish banana-producing provinces, compared to non-producing provinces, induced by a world Cavendish price rise. 

Column (2) replicates the same regression as column (1) but with the addition of the Control Variables that we discussed earlier, which helps us to reduce the bias of our estimator. 

According to the table and Crost and Felter (2020, p. 1499f.), the coefficient estimate with the extra Control Variables is marginally higher at 0.156. This regression implies that a province with a baseline Cavendish banana production of 1kg per capita and a hypothetical 10% rise in the global market price, would have $$0.156*1*0.10 = 0.0156$$ more violent crimes, compared to non-producing provinces. This value may seem negligible, but it suggests that the **price volatility contributes to a considerable rise in violent occurrences during the period of observation.** To illustrate the magnitude of this effect, we examine the period from 2003 to 2009. Our data set (see column *bananaprice*) shows that the Cavendish banana price increased from 0.47USD in 2003 to 0.88USD in 2009. This represents a rise of more than $$(0.88/0.47-1)*100 = 87$$ percent. Based on our estimate in column (2) and a standard mean production of 9.36kg Cavendish bananas as shown in Table 1, this implies that we would observe extra $$0.156*9.36*0.87 = 1.27$$ brutal incidents per year in provinces where Cavendish bananas are grown. Given that there are 29 Cavendish banana-producing provinces during the monitoring period, this estimate suggests that we would see additional $$1.27×29 ≈ 37$$ violent incidents per year in the entire Philippines. *This highlights the large scale of the estimate in column (2).*

As explained by Crost and Felter (2020, p. 1499-1500), the authors want to make sure that the provinces with varying banana production volumes had the *same trend in conflict before the price shock, even under the consideration of other conflict-influencing factors.* To verify the validity of this **parallel trend**, they perform a placebo test in columns (3) and (4) of the table. They include the **"lead" of the interaction term** ${Cavendish}_{i} * {Price}_{t+1}$ in the baseline regressions of columns (1) and (2). To rule out the possibility of nonparallel time trends, the authors *test the null hypothesis that the estimated lead coefficient is equal to zero*. A significant rejection of this hypothesis would indicate that the parallel trend assumption is violated. The authors examine columns (3) and (4) as a robustness check of columns (1) and (2). They find that the standard interaction term is highly significant at the 1% level, while the *lead coefficient is insignificant and negligible*.


Quiz: What do the insignificant and negligible lead coefficients imply?

(1) The null hypothesis can be rejected
(2) The null hypothesis cannot be rejected

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("Robustness Check and Null Hypothesis")
```


<br/>

## Exercise 4 -- Robustness Check

In this chapter, we want to verify the main results of the baseline regression approach of the previous exercise, with two robustness checks against plausible issues.

First, we extend our baseline regression equation and explore the influence of the global market price on the occurrence of provincial violent incidents using the Instrumental Variable strategy. This is to evaluate the relevance of the possible problem of **reverse causality**.

Second, to shed light on the potential problem with **spatial correlations**, we examine the Spatial Regression technique.

### Framework

4.1 The Problem of Reverse Causality

4.2 Spatial Regression

<br/>

## Exercise 4.1 -- The Problem of Reverse Causality

In this exercise, we want to address the **potential problem of reverse causality by using Instrumental Variable regression as a robustness test** of the baseline regression specification of Table 2. For that purpose, as Crost and Felter (2020, p. 1500) explain, we modify our baseline approach from the preceding chapter and examine the variation in conflict across provinces with varying levels of Cavendish banana production over time. Therefore, the following regression specification is employed:

$${Y}_{it} = {\beta}_{0} + \sum_{j=2001, j≠2005}^{2009} {\theta}_{j} * {Cavendish}_{i} * \mathbb{1}({Year}_{t} = j) + {\alpha}_{i} + {\lambda}_{t} + {\varepsilon}_{it}$$

This regression specification is a *modification of the baseline regression*, using the same variables and subscripts. The difference is that the new regression includes the *sum of the interaction term over the years 2001 to 2009, excluding 2005*. Remember that 2005 is the treatment year! Moreover, the interaction term is now ${\theta}_{j} * {Cavendish}_{i} * \mathbb{1}({Year}_{t} = j)$, where $\mathbb{1}({Year}_{t} = j)$ is an indicator function that equals 1 if ${Year}_{t}$ is equal to the year j of the sum iteration, and 0 otherwise. Here, j is any year from 2001 to 2009, except 2005. 

According to Crost and Felter (2020, p. 1500f.), the **slope coefficient of the association between a provinces initial output of Cavendish bananas and the conflict intensity in year j**, compared to the excluded gradient of year 2005, is represented by ${\theta}_{j}$. Consequently, if we explore a graphical representation of the ${\theta}_{j}$ development, it indicates a slope coefficient of zero for the year 2005. The *coefficient* ${\theta}_{j}$ *enables us to examine whether the variation in prices empowers the conflict intensity in provinces that cultivate Cavendish bananas.* If this is the case, the temporal pattern of the ${\theta}_{j}$ coefficient **would reflect the dynamics of the Cavendish market price!**

We will *verify this hypothesis as a first robustness check of the results from Table 2 in the subsequent graph* by plotting the ${\theta}_{j}$ coefficient and the global market price over time.

<br/>

**Task 38:** Importing *the data sets for the tabular and graphical analysis* is the first step. The required package should be loaded and the data set `replication_data.dta` should be read in using the `read_dta()` function. Furthermore, the resulting data frame should be stored in the variable `data`. **Moreover**, read in the data frame `merged_data.dta` and store it in the variable `merged_data`. *This new data set is specifically prepared to generate the graphical illustration* of the ${\theta}_{j}$ coefficient. Finally, *have a look at the first rows of the new data set* with the function `head()`. The first columns of the data frame should look familiar to you! **Note:** If you want to have an insight look, at how the new data set `merged_data.dta` resulted from the original one (`replication_data.dta`), feel free to look at the **Appendix**. 

```{r "13_1"}
#Load the necessary package, import both data, and save them in their correct variables. Do not forget to display the first rows!
```

The data frame `df_figure_rep` from the Chapter 2 is extended to form the new data set `merged_data`, which has the same first nine columns and 41 additional ones. These columns provide the values required for the graphical representation of the ${\theta}_{j}$ coefficient for each year in the observation period from 2001 to 2009. The columns with the **prefix "beta" contain the coefficients for all commodities**, while the other columns contain the **variances, standard deviations, lower and upper bounds of the 95% confidence interval, and the** `prize_z` **columns for all goods**. The `prize_z` value is computed as *[(price in the current year – price in 2005) / price standard deviation]*.

**Task 39:** To verify the stated hypothesis, whether the variation in prices empowers the conflict intensity in provinces that cultivate Cavendish bananas, we now want to plot the pattern of the ${\theta}_{j}$ coefficient and the global market price over time. Furthermore, we want to examine the 95% confidence interval as well. Please fill in the blanks in the following chunk to generate the graphic. Some sections might be familiar to you from the graphical representation of the commodity prices in Exercise 2.2 before, some might not. **Please refer to the comment instructions for guidance on the tasks and their purposes.**

```{r "13_2",fig.width=10, fig.height=6}
library("ggplot2")
library("ggpubr")
#In the first graph, we are trying to display different data that are scaled differently. To display them together in one plot, a pre-transformation is necessary!
ylim.prim_1 <- c(___, 1.3) #Set the scale of the primary y-axis from -1.3 to 1.3
ylim.sec_1 <- c(0.4, 1) #Sets the scale of the secondary y-axis from 0.4 to 1

#Pre-transformation to display the differently scaled data in one plot
___ <- diff(ylim.prim_1) / diff(ylim.sec_1) #Create the variable "b_1" which is the difference of values in "ylim.prim_1" divided with the difference of values in "ylim.sec_1"
a_1 <- ylim.prim_1[1] - b_1 * ylim.sec_1[1] #Creates the variable "a_1" which is the first value of "ylim.prim_1" minus "b_1" times the first value of "ylim.sec_1". Both "b_1" and "a_1" are necessary to cope with the difference in scale of the data

___ <- ggplot(data = merged_data, aes(x = year)) + #Save this plot in the variable "Figure_3_Bananas". The data are from the data frame "merged_data". We want to plot the development over our years from the observation period. This needs to be adjusted in the aesthetics
  ___(aes(y = ___, color = "slope coefficient (θ)"), linetype = "solid", linewidth = 1.5) + #Display the primary data as a line. The data scaled on the y-axis is the slope coefficient θ for Cavendish bananas, called "beta". To create a legend, our color argument is defined in the aesthetics with a solid line type for the coefficient
  geom_line(aes(y = ___ + b_1 * ___, color = "Cavendish price"), linetype = "dashed", linewidth = 1.5) + #Our secondary data scaled on the y-axis is the price, called "bananaprice". To display this different scaled data with the "beta" in one plot, we need to multiply the "bananaprice" with "b_1" and add "a_1" in terms of the transformation
  scale_y_continuous(name = "slope coefficient (θ)", ___ = sec_axis(~ (. - a_1) / b_1, name = "price (2010 $/kg)")) + #The y-axis should be primary scaled by the "beta" column with the name "slope coefficient (θ)". We furthermore create the secondary y-axis with the name "price (2010 $/kg)" for the transformed "bananaprice" data. This can be done via the "sec.axis" argument in the "scale_y_continuous()" function. It is a backward transformation of the primary axis, which is done via ~ (. - a_1) / b_1. With that, we can display both data in one plot
  ___(values = c("blue", "red")) + #Defines the color of the lines for the price and the slope coefficient with the "scale_color_manual()" function
  scale_x_continuous(breaks = seq(2000, 2010, by = 2), limits = c(2000, 2010)) + #The scale on the x-axis should go from 2000 to 2010 and this always in two steps
  labs(x = "Year", title = "Cavendish Bananas") + #Here we define the labs on the x-axis and the title of this plot
  theme_bw() + #Defines the plot theme
  labs(color = NULL) + #Get rid of the separate color argument occurrence in the legend
  theme(
    plot.title = element_text(hjust = 0.5), 
    panel.grid.major = element_line(color = "gray"), 
    panel.grid.minor = element_blank(), 
    axis.text = element_text(color = "black"),  
    axis.ticks = element_line(color = "black"), 
    plot.background = element_rect(fill = "white"), 
    panel.background = element_rect(fill = "white"), 
    legend.position = "bottom", 
    legend.box.background = element_rect(color = "black"), 
    legend.box.margin = margin(0.5, 0.5, 0.5, 0.5) 
  )

#The second graph replicates the analysis from the first, but with an extension that the second graph also shows the 95% confidence interval of the slope coefficient. Since this graph also faces the same issue of disparate scales, a pre-transformation is required to combine the price development, the slope coefficient, and the confidence interval in one single plot

ylim.prim_2 <- c(___, 4) #Set the scale of the primary y-axis from -3 to 4
ylim.sec_2 <- c(0, ___) #Set the scale of the secondary y-axis from 0 to 1.6

#Pre-transformation to display the differently scaled data in one plot
b_2 <- ___(ylim.prim_2) / diff(___) #Construct the variable "b_2" following the same principle as in the first part above
a_2 <- ylim.prim_2[___] - b_2 * ___[1] #Construct the variable "a_2" following the same principle as in the first part above

#We create the plot according to the same principle as for "Figure_3_Bananas" above. The difference is that we now add our created confidence interval to the plot. We also apply a transformation for the "bananaprice" to ensure that we can illustrate it with the "beta" and the 95% confidence interval in one plot 
Figure_3_Conf <- ggplot(data = merged_data, aes(x = year)) +
  ___(aes(ymin = ___, ___ = cihigh, fill = "confidence interval"), alpha = 0.5) + #Adds our 95% confidence interval to the plot with the "geom_ribbon()" function. In the aesthetics we specify that our "ymin" is the "cilow" column and "ymax" is the created "cihigh" column. For the legend, we define our fill argument as "confidence interval"
  ___(aes(y = ___, color = "slope coefficient (θ)"), linetype = "solid", linewidth = 1.5) + #Display the primary data as a line. The data scaled on the y-axis is the slope coefficient theta for Cavendish bananas, called "beta"
  geom_line(aes(y = a_2 + b_2 * bananaprice, color = "Cavendish price"), linetype = "dashed", linewidth = 1.5) + 
  scale_y_continuous(name = "slope coefficient (θ)", sec.axis = sec_axis(~ (. - a_2) / b_2, breaks = seq(0, 1.6, by = 0.4), name = "price (2010 $/kg)")) + 
  scale_color_manual(values = c("blue", "red")) +
  scale_fill_manual(values = "grey") + #Defines the color of the area for the confidence interval
  scale_x_continuous(breaks = seq(2000, 2010, by = 2), limits = c(2000, 2010)) +
  labs(x = "Year", title = "With Confidence Intervals") +
  theme_bw() +
  labs(color = NULL, fill = NULL) + #Get rid of the separate color and fill argument occurrence in the legend
  theme(
    plot.title = element_text(hjust = 0.5),
    panel.grid.major = element_line(color = "gray"),
    panel.grid.minor = element_blank(),
    axis.text = element_text(color = "black"),
    axis.ticks = element_line(color = "black"),
    plot.background = element_rect(fill = "white"),
    panel.background = element_rect(fill = "white"),
    legend.position = "bottom",
    legend.box.background = element_rect(color = "black"),
    legend.box.margin = margin(0.5, 0.5, 0.5, 0.5)
  )

#We want to illustrate our two created plots in one figure. We do so with the "ggarrange()" function and specify the number of columns and rows in the figure
Figure_3 <- ggarrange(Figure_3_Bananas, Figure_3_Conf, ncol = 2, nrow = 1)

Figure_3 #Shows the created figure
```

Both plots display how the price of Cavendish banana as well as the estimated slope coefficient from the adjusted regression specification ${\theta}_{j}$ changed throughout our study. The figure as well as the results by Crost and Felter (2020, p. 1501) indicate that the **estimated slope coefficient and the price movement exhibit a simultaneous temporal trend**. Following the path, they both decline sharply from 2001 to 2003. Afterwards, both rise mostly till 2008, with a minor drop in 2007. A large divergence occur from 2008 to the end of the observation period since the price movement rise steadily, while the coefficient is estimated to face the opposite direction and drop significantly. Over time, the 95% confidence interval for the slope coefficient provides insights into the expected range of values for the true coefficient. The 95% confidence interval indicates that *we are 95% confident that the true slope coefficient lies within this range*. The interval serves as a measure of the fluctuation and uncertainty in the slope across time. The simultaneous time pattern suggests that the relationship between **how much Cavendish bananas in a province are produced and the number of violent incidents is much stronger when the global market price is high!** Given that the fluctuation in Cavendish prices consistently fall within the 95% confidence interval throughout the entire timeline, coupled with the highly similar temporal trends of the estimated ${\theta}_{j}$ coefficient and the price, the likelihood of this happening by random chance is low. **This reinforces the certainty that the causal relationship of crop values on the conflict intensity was truly represented by the estimates of Table 2 before!** 

<br/>

This causal relationship may appear to be simple and logical. However, from an empirical perspective, there is an *issue with this causal chain that could significantly bias our estimates*. The issue is the possibility of **reverse causality**. 

Given that the Philippines, as discussed in Chapter 1 of this Problem Set, ranks as the second largest global exporter of bananas, the *economic and social dynamics within the nation possess the potential to exert a substantial influence on the prevailing world market price!* As posited by Crost and Felter (2020, p. 1501), this suggests the conceivable emergence of a scenario wherein the **arising conflicts within the Philippines influenced the global market banana price**. A possible reverse causality mechanism is that the expanded frequency of armed conflicts in regions where bananas are cultivated, disrupt the banana supply chain, as rebel groups may resort to destroying plantations if their extortion demands are not satisfied. This creates a supply shortage that does not match the constant demand for bananas in the world market, leading to an excess demand that drives up the global market price. This creates a vicious cycle, as the increased market price provides a strong motivation for armed rebel groups to raid more plantations. *An upward bias in the estimates of Table 2* may occur through this reversed causal relationship. 

To investigate this problem of reverse causality and check whether this actually biases the estimates, we make use of the **Instrumental Variable Regression**. 

<br/>

## Instrumental Variable Regression

The method of Instrumental Variable (IV) is a statistical technique that allows for consistent and unbiased estimation of causal effects in the presence of endogeneity. 
As stated by Pokropek (2016, p.4), utilizing the IV approach enables the **identification of the exogenous variation in the effect of the endogenous regressor on the outcome variable, allowing for the estimation of the causal impact**. Consequently, this confines us to use the portion of the predictor that does not correlate with the unobservable factors in the error term. This can be accomplished by incorporating the IV as an additional variable in the regression to measure the causal impact of the regressor on the dependent variable of interest. In our case, the outcome variable of interest is the **provincial number of violent incidents** (`vinc`). We try to explain it with the possible endogenous baseline interaction term of **Cavendish value** (`logcavendishinter2002_pop`) as our predictor. Due to the possible problem of reverse causality of the world price, we need to test whether the Cavendish value is indeed endogenous or not. For simplicity, let us denote $Z$ as our helpful IV and $U$ symbolizes the set of unobservable factors in the error term that influence both, the outcome variable and the endogenous regressor. *The causality of the impact between our baseline interaction term and the number of provincial incidents requires empirical estimation.*

To address the possible endogeneity problem of the Cavendish value term, the selected **IV must satisfy three assumptions for its validity**, according to Pokropek (2016, p.4). The first criterion for a valid instrument $Z$ is its **relevancy**. This means that $Z$ has a *non-zero correlation* with the endogenous predictor, or $cor(Z,Cavendish value) ≠ 0$. The second criterion is the **exogeneity** of $Z$. This implies that $Z$ is *independent from the error term* $U$, or $cor(Z,U) = 0$. Finally, $Z$ must satisfy the **exclusion restriction**, meaning that *it is no independent constituent of the initial regression model*. Consequently, should the instrument $Z$ adhere to these requisite conditions, **it only influences the violent incidents via its impact on the Cavendish banana value!** The validity of an IV is illustrated by the following Figure 12 based on Pokropek (2016, p.5):

![](Image_12_Instrument.png)

<br/>


Quiz: In accordance with the assumptions previously studied, do you consider the IV in scenario a) of Figure 12 above to be valid?

(1) Valid Instrumental Variable
(2) Invalid Instrumental Variable

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("IV Validity Check I")
```


Quiz: In accordance with the assumptions previously studied, do you consider the IV in scenario b) of Figure 12 above to be valid?

(1) Valid Instrumental Variable
(2) Invalid Instrumental Variable

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("IV Validity Check II")
```


Quiz: In accordance with the assumptions previously studied, do you consider the IV in scenario c) of Figure 12 above to be valid?

(1) Valid Instrumental Variable
(2) Invalid Instrumental Variable

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("IV Validity Check III")
```

Having learned about the **issue of reverse causality and how to address it using the IV regression method**, you are now required to identify an appropriate IV for the global market price. *The challenge is to identify one factor that fulfills the IV assumptions, has a significant impact on the global banana market price, and is independent of the Philippines conflict intensity.*

<br/>

According to Crost and Felter (2020, p. 1501), **rainfall in Ecuador** serves as an **appropriate IV for the analysis**. *What is the rationale behind this choice?* As established in the first chapter, Ecuador dominates the global banana export market, with its share accounting for 27% of the total banana export volume worldwide. *The IV is justified by the relationship between high precipitation in Ecuador and the significant reduction of global banana export, as the banana crop is vulnerable to root diseases under excessive moisture ground conditions*. As a result of this contraction in supply, in combination with the occurring global excess demand, the price of bananas in the world rises. The same vicious loop, which was observed in the Philippines with prior levels of conflict intensity, is also present in this case, albeit **without the reverse causality, because the general weather situation cannot be influenced**. In addition, **rainfall in Ecuador** meets all the restrictions described above. Hence, we **employ an IV approach to address the potential endogeneity of the global banana price**. *We use the Ecuadorian rainfall as an exogenous instrument for the price, as shown in the following table!*

```{r eval=FALSE}
# Run for additional info in the Viewer pane
info("Integrating IV into the feols() function")
```

*Let us dive into the IV regression analysis!*

<br/>

**Task 40:** The first step aims to filter the data set `data` to include only the observations from the *years 2001 to 2009*. This task is like the one in the preceding exercise of this Problem Set. Complete it independently and refer to the previous chapters if you encounter any difficulties. Remember to load the `dplyr` package for the Pipe Operator! Save the new data frame in the variable `data_table`. 

```{r "13_3"}
#Load the necessary package and filter the main data set "data" to include only the years from 2001 to 2009
```

**Task 41:** Given the structure of a regression model in R presented by the previous table, *complete the following code by applying the acquired knowledge and follow the instructions in the comments.* Recall that the **IV Rainfall in Ecuador** is used to **instrument the price variable**. The *endogenous independent variable* is `logcavendishinter2002_pop`, which represents the product of Cavendish banana production in kg and *Log Price*. The respective IV is `logpinter_pop`, which represents the product of Cavendish banana production in kg and *Rainfall in Ecuador*.

```{r "13_4"}
#The principle and procedure of this chunk is in general the same as that from Table 2 before. Now, the IV is new

library("fixest")
library("modelsummary")
library("kableExtra")

Table_3_list <- list( #Creates the necessary list for the "modelsummary()" function
  
  "(1)" = feols(___ ~ temperature + ___ | year + pcode | ___ ~ ___, data = data_table, weights =  data_table$pop2000, cluster = data_table$pcode), #Our outcome variable of interest is the number of violent incidents "vinc". We want to explain it with the variables "temperature" and "typhoon" as Control Variables and our endogenous independent variable "logcavendishinter2002_pop". We want to use our instrument "logpinter_pop" to manage the endogeneity of "logcavendishinter2002_pop". FE, weights, and the Cluster Robust Standard Errors follow the same principle as in Table 2 before
  
  "(2)" = feols(vinc ~ temperature + typhoon + ___ + ___ | year + pcode | logcavendishinter2002_pop ~ ___, data = data_table, weights =  data_table$pop2000, cluster = data_table$pcode), #Here we do the same as in (1) but now under the additional incorporation of the Control Variables "zrain" and "wetrain" to get rid of a potential bias in the estimates
  
#Columns (3) and (4) describe the first stage of the "Two-Stage-Least-Squares" IV regression method, where we regress the endogenous independent variable on all instruments. More information will follow after the table is displayed
  
  "(3)" = feols(___ ~ ___ | year + pcode, data = data_table, weights =  data_table$pop2000, cluster = data_table$pcode), #Here we regress the endogenous independent variable just on its instrument
  
  "(4)" = feols(___ ~ ___ + zrain + ___ + temperature + typhoon | year + pcode, data = data_table, weights = data_table$pop2000, cluster = data_table$pcode) #Here we regress the endogenous independent variable on its instrument and the other used Control Variables

)

#We create a tribble, which contains rows that should be involved in the final table like it was done in Table 2 before
rows <- tribble(~term, ~"(1)", ~"(2)", ~"(3)", ~"(4)",
                "Mean of dependent variable", as.character(sprintf("%.2f", mean(data_table$vinc))), as.character(sprintf("%.2f", mean(data_table$vinc))), as.character(sprintf("%.2f", mean(data_table$cavendish2002_pop))), as.character(sprintf("%.2f", mean(data_table$cavendish2002_pop))), 
                "Control variables", "No", "Yes", "No", "Yes",
                "Year FE", "Yes", "Yes", "Yes", "Yes",
                "Province FE", "Yes", "Yes", "Yes", "Yes",
                "No. of provinces", as.character(length(unique(data_table$pop2000))), as.character(length(unique(data_table$pop2000))), as.character(length(unique(data_table$pop2000))), as.character(length(unique(data_table$pop2000))))

#Defines the position of the additional rows in the regression table
attr(rows, 'position') <- c(5:9) 

#The following "modelsummary()" function creates Table 3 with its coefficients, standard errors, and additional rows. Some specifications of how the table looks are adjustable
modelsummary(Table_3_list, 
             title = "TABLE 3. Robustness test: Instrumenting price with rainfall in Ecuador.",
             stars = c("*" = 0.1, "**" = 0.05, "***" = 0.01),
             fmt = 3,
             coef_map = c("fit_logcavendishinter2002_pop" = "Cavendish prod. (kg per cap.) x Log Price", "logpinter_pop" = "Cavendish prod. x Rainfall in Ecuador"),
             coef_omit = "^(?!.*log)",
             gof_omit = "R2|R2 Adj.|AIC|BIC|RMSE|Std.Errors|FE:",
             add_rows = rows,
             notes = 'Notes from Crost and Felter (2020, p. 1502): "All regressions control for rainfall and temperature during the wet and dry season, as well as an indicator that takes the value 1 if the province was hit by a major typhoon. Standard errors, clustered at the province level, are in parentheses." *Significant at 10% level, **significant at 5% level, and ***significant at 1% level.',
             output = "kableExtra") %>%
             add_header_above(c(" " = 1, "IV \n Violent incidents" = 2, "First stage \n Cavendish prod. x \n Log US banana price" = 2)) %>%
             row_spec(seq(1, 4 ,2), background="#ecf6ff")

```

The IV procedure estimates are presented in Table 3. Crost and Felter (2020, p. 1501f.) state that the coefficients in columns (1) and (2) are slightly different from the corresponding ones in Table 2, but the difference is negligible. Furthermore, they are highly significant. Columns (1) and (2) *verify that there is a positive relationship between elevated levels of rainfall in Ecuador and the global banana market price.* 

Moreover, the IV estimator can be calculated using two least squares estimate, which is the so-called **"Two-Stage-Least-Squares" (2SLS)** method. Columns (3) and (4) describe the first stage of the 2SLS IV regression method, *where we regress the endogenous independent variable on all instruments*. The coefficients of both regressions, including and excluding Control Variables, are similar and statistically significant at the 1% level. The positive sign of the coefficient indicates a positive correlation between the IV and the endogenous variable. **This supports the validity of using rainfall in Ecuador as an instrument!**


Quiz: Given the magnitude of the coefficients in columns (1) and (2) of Table 3, does the positive relationship between elevated levels of rainfall in Ecuador and the global banana price encourage the occurrence of reverse causality?

(1) It does support the presence of reverse causality
(2) It does not support the presence of reverse causality

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("Table 3 Implications")
```


<br/>

## Exercise 4.2 -- Spatial Regression

As stated by Crost and Felter (2020, p. 1502), another worry could arise by looking at the mean banana production by provinces in Figure 8 at the start of the Problem Set. It is noticeable that Cavendish bananas, used mainly for export, are *predominantly grown in the regions of Mindanao and the island group of Visayas*. Therefore, a potential limitation of the analysis and the estimates presented in Table 2 is the **spatial distribution of Cavendish banana cultivation** in the Philippines. Given the proximity of the two regions, we may encounter the **issue of a high degree of spatial clustering in the Philippine banana export sector**. As a result, standard error estimates may be biased towards the bottom by spatially correlated unsupervised impacts. That is why we need to test for this problem!

<br/>

To account for the issue with the potential bias, two approaches can be used according to Crost and Felter (2020, p. 1502). First, **run several regressions that account for FE's of island groups over time**. In that process, each regression should *limit the spatial scope of the data differently*, for instance, we just examine observations from Mindanao. This is necessary because we want to exclude the possibility that our findings are influenced by hidden impacts on a specific island group. As a second approach, following the method explained by the American economist Timothy G. Conley, we compute **standard errors that are immune to spatial autocorrelation**. 

<br/>

Spatial autocorrelation is an important aspect to consider and manage in econometrics as well as empirical economics. Conley (2010, p. 303) explains that the main concept of spatial models is that the **interdependence among their respective observations can be described by a collection of geographical positions**. These positions or locations introduce novel structural features in the models because **observations that are geographically closer to each other tend to correlate more, but as they get increasingly separated, they converge to independence!** 

<br/>

According to Amgalan et al. (2022, p. 920), various empirical models rely on *territorial locations as a key factor*, as they capture the spatial aspects of several natural and social events. To detect the spatial context for the relevant characteristics, geo-based information like *longitudinal and latitudinal coordinates or region codes* are frequently applied. **The degree of correlation between observations that are closely neighboring in space is called spatial autocorrelation**. If neighboring values tend to resemble each other more than anticipated, it is indicated by positive spatial autocorrelation. Conversely, a negative spatial autocorrelation is indicated if neighboring values tend to resemble each other less than anticipated. 

The following *two examples of positive spatial autocorrelation* described by Amgalan et al. (2022, p. 920), should help you to follow the concept logically. Consider the *distribution of temperature over various regions as a natural example*. Locations in proximity exhibit greater similarity in temperature values, while those at a distance from each other tend to show less resemblance. *Social spatial autocorrelation is exemplified by the distribution of languages or dialects within a country or region*. Typically, regions with comparable linguistic characteristics are situated in proximity, while territories with distinct languages or dialects tend to be more distant from one another. 

<br/>

In fact, as stated by Conley (2010, p. 303), the **geographic positions for the observations are the essential elements in all spatial models**. Modeling spatial distributions provides a main advantage by enabling the concise representation of complex interdependence cross-observing samples, through the *respective observation distances!* 

To cope with the impacting spatial autocorrelation, we employ the `conleyreg()` function from the `conleyreg` package to obtain consistent coefficient estimates and robust standard errors that *account for spatial autocorrelation* as explained by Timothy G. Conley. **Hence, this function allows us to estimate regression models with Conley standard errors**. *Please refer to the Info block below, which contains a brief explanation of the essential components of the function syntax, which are required for our purpose!*

```{r eval=FALSE}
# Run for additional info in the Viewer pane
info("conleyreg() function for regression models with Conley standard errors")
```

As mentioned before, following Crost and Felter (2020, p. 1502), we proceed to perform the regression analysis using the *two approaches that we have previously introduced.*

**Task 42:** As usual, we need to import the data set that we will analyze. The required package should be loaded and the data set `replication_data.dta` should be read in. The resulting data frame should be stored in the variable `data`. 

```{r "14_1"}
#Load the necessary package, import the data, and save it in the correct variable
```

**Task 43:** The following step aims to filter the data set `data` to include only the observations from the *years 2001 to 2009*. This task is like the ones in the preceding exercises of this Problem Set. Complete it independently and refer to the previous chapters if you encounter any difficulties. Remember to load the `dplyr` package for the Pipe Operator! Save the new data frame in the variable `data_table`.

```{r "14_2"}
#Load the necessary package, filter the data set according to the right yearly period, and save it in the correct variable
```

**Task 44:** Moreover, we require *two additional data frames*, derived from our table data frame `data_table`. The first data frame should include *only the observations that belong to the provinces* of `mindanao` or `visayas`. These provinces are represented by separate columns in the `data_table` data frame and are *dummy variables, which take the value of 1 if the observation is from that province, and 0 otherwise.* Please complete the following blanks.

```{r "14_3"}
data_table_mind_visa <- ___ %>%
  filter(., ___ == 1 | visayas == ___)  

```

**Task 45:** Great! Next, we create the second data frame **based on the one we have just computed** (`data_table_mind_visa`). Please fill in the blanks, such that the resulting new data frame only includes the observations from `mindanao`.

```{r "14_4"}
data_table_mindanao <- data_table_mind_visa ___
  filter(., ___ == ___) 

```

**Task 46:** Having established the theoretical framework and the necessary data frames, the next move is to conduct the empirical analysis in the following code chunk. **Complete the missing parts by tracking the additional guidance and explanations in the comments.**  *The first part of Crost and Felter's approach is represented by the first three columns of the output table, while the fourth column shows the results of the spatial regression with Conley standard errors!* **Don't worry, the checking of this chunk could take a bit!**

```{r "14_5"}
library("conleyreg")

Table_4_list <- list(
  
  "(1)" = feols(___ ~ ___ + zrain + wetrain + wettemp + temperature + typhoon | year + pcode + ___ * year + visayas * ___, data = ___, weights =  data_table$pop2000, cluster = data_table$pcode), #The first basic regression in which we try to explain the number of violent incidents ("vinc") with the Cavendish banana value ("logcavendishinter2002_pop"). Also like in the regressions before, we include our default Control Variables. This regression is based on our basic data frame "data_table" with the weights and Cluster Robust Standard Errors like in the previous tables. But now we make use of the Island-group-by-time FE in addition to our standard "year" and "pcode" FE. To incorporate that, we add the interaction term of both provinces, Mindanao and Visayas, with the "year" variable to our standard FE's
  
  "(2)" = ___(vinc ~ logcavendishinter2002_pop + zrain + wetrain + wettemp + temperature + typhoon | year + pcode + mindanao * year, data = ___, weights =  ___$pop2000, cluster = ___$pcode), #In the second regression we perform the same estimation as in the first one, but now we adjust the spatial scope of the used observations. We restrict our observations to the provinces of Mindanao and Visayas only. To cope with that, we use the first of the newly created data frames from before 
  
  "(3)" = feols(___ ~ logcavendishinter2002_pop + zrain + wetrain + wettemp + temperature + typhoon | year + pcode, data = ___, weights =  ___$pop2000, cluster = ___$pcode), #In the last regression of the first approach from Crost and Felter, we narrow the geographical circle and only restrict the observations on the province Mindanao alone. To cope with that, we use the second of the newly created data frames from before

  "(4)" = ___(vinc ~ logcavendishinter2002_pop + zrain + wetrain + wettemp + temperature + typhoon + as.factor(pcode) + as.factor(year), data = data_table, dist_cutoff = ___, lat = "latcoord", lon = "longcoord", time = "year", unit = "pcode", lag_cutoff = ___) #In the last column of the table, we execute the second approach from the authors to cope with spatial autocorrelation. We use the central function of the conleyreg package to conduct the regression with unbiased Conley standard errors. In that function, the authors specify a spatial bandwidth of 5000 (km) and a maximum time lag of 9 years. Latitudinal and longitudinal geographic coordinates are given in our initial data_table data set with the provincial code as a stationary variable
  
)

#The rest of the chunk follows the same principle as usual, with extra rows to provide more information and optical adjustments of the table’s appearance

rows <- tribble(~term, ~"(1)", ~"(2)", ~"(3)", ~"(4)",
                "Mean of dependent variable", as.character(sprintf("%.2f", mean(data_table$vinc))), as.character(sprintf("%.2f", mean(data_table_mind_visa$vinc))), as.character(sprintf("%.2f", mean(data_table_mindanao$vinc))), as.character(sprintf("%.2f", mean(data_table$vinc))),
                "Control variables", "Yes", "Yes", "Yes", "Yes",
                "Island-group-by-time FE", "Yes", "Yes", "Yes", "No",
                "Mindanao and Visayas only", "No", "Yes", "Yes", "No",
                "Mindanao only", "No", "No", "Yes", "No",
                "Conley standard errors", "No", "No", "No", "Yes",
                "No. of provinces", as.character(length(unique(data_table$pop2000))), as.character(length(unique(data_table_mind_visa$pop2000))), as.character(length(unique(data_table_mindanao$pop2000))), as.character(length(unique(data_table$pop2000))))

attr(rows, 'position') <- c(3:9)

modelsummary(Table_4_list,
             title = "TABLE 4. Robustness tests for spatially correlated shocks.",
             stars = c("*" = 0.1, "**" = 0.05, "***" = 0.01),
             fmt = 3,
             coef_map = c("logcavendishinter2002_pop" = "Cavendish prod. (kg per cap.) x Log Price"),
             coef_omit = "^(?!.*log)",
             gof_omit = "R2|R2 Adj.|AIC|BIC|RMSE|Std.Errors|FE",
             add_rows = rows,
             notes = 'Notes from Crost and Felter (2020, p. 1503): "All regressions control for rainfall and temperature during the wet and dry season, as well as an indicator that takes the value 1 if the province was hit by a major typhoon. Standard errors are in parentheses. In columns (1)–(3), standard errors are clustered at the province level. In column (4), standard errors are robust to spatial and temporal autocorrelation, [...] with a spatial bandwidth of 5000 km and a maximum lag of 9 years." *Significant at 10% level, **significant at 5% level, and ***significant at 1% level.',
             output = "kableExtra") %>%
             add_header_above(c(" " = 1, "Violent incidents" = 4)) %>%
             row_spec(seq(1, 2 ,2), background="#ecf6ff")

```

*The table provides insights into the author's methodology.* As Crost and Felter (2020, p. 1502) explained, and as shown in Table 4, *the first three columns correspond to the first stage of their approach*. In that, they account for FE's of Cavendish banana-producing island groups over time, with each regression limiting the spatial scope of the data differently. *The idea is to take the relatively high degree of spatial clustering in the Cavendish banana export sector of the Philippines into consideration.* A comparison of the estimates from the first three columns with those from our default regression in Table 2 reveals a **high level of similarity**. In addition, the estimates are statistically significant at the 5% level. By utilizing FE's for different island groups in combination with time, to account for unsupervised effects that are correlated across territories, **columns (1) to (3) display that the estimates are not affected and remain solid**. By examining the results of column (4), which controls for the problem of spatial autocorrelation, we can see that the estimates are still extremely statistically significant at the 1% level with the Conley standard errors that are durable to spatial autocorrelation.


Quiz: How does the evidence from Table 4 affect our confidence in the unbiasedness of the baseline regression estimates in Table 2, concerning territorial correlation?

(1) More confident
(2) Less confident

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("Evidence Table 4")
```


<br/>

## Exercise 5 -- Further Analyses

In this exercise we analyze the impact of insurgent armed disputes, the actors, and the victims of these controversies. Moreover, we examine other factors that might influence the frequency of provincial violent events apart from just the Cavendish banana value of the baseline approach in Chapter 3. Additionally, we illuminate potential heterogeneous effects. 

<br/>

Given the established relationship between the provincial Cavendish banana output, the global market price, and the frequency of violent events through the rebel mechanism, it is imperative to **examine the actors involved in the initiation and the victimization of the violence**. Therefore, Crost and Felter (2020, p. 1504) aim to examine the hypothesis that a *higher Cavendish banana value (which is the baseline interaction term) enhances the strength of the rebel organizations to effectively confront any opposing parties*.

**Task 47:** As usual, we begin each new exercise by importing the data set that we will analyze. The required package should be loaded and the data set `replication_data.dta` should be read in. Store the resulting data frame in the variable `data`. 

```{r "15_1"}
#Load the necessary package, import the data, and save it in the correct variable
```

**Task 48:** Like in the last exercise, subset the data set to include only the observations from the *years 2001 to 2009*. Complete it independently and refer to the previous chapters if you encounter any difficulties. Remember to load the `dplyr` package for the Pipe Operator! Save the new data frame in the variable `data_table`.

```{r "15_2"}
#Load the necessary package, filter the data set according to the right yearly period, and save it in the correct variable
```

**Task 49:** The following code implements the regressions to *test the hypothesis regarding the rebel capacity*. These regressions have a consistent structure that employs the central `feols()` function like in the tables before. The dependent variable in each regression is the frequency of provincial violent disputes, which are explained by the baseline Cavendish banana value and all Control Variables. The five regressions vary only in the *operationalization of the violent incidents*, which depends on the **initiator of the violence** and the **number of incidents with at least one fatality of one particular opposing party**. To execute the code chunk, click on the `check` button.

```{r "15_3"}

library("fixest")
library("modelsummary")
library("kableExtra")

Table_5_list <- list(
  
  "(1)" = feols(govinitvinc ~ logcavendishinter2002_pop + zrain + wetrain + wettemp + temperature + typhoon | year + pcode, data = data_table, weights =  data_table$pop2000, cluster = data_table$pcode), #The outcome variable of interest is the number of resulted incidents, initiated by the government "govinitvinc"
  
  "(2)" = feols(eninitvinc ~ logcavendishinter2002_pop + zrain + wetrain + wettemp + temperature + typhoon | year + pcode, data = data_table, weights =  data_table$pop2000, cluster = data_table$pcode), #The outcome variable of interest is the number of resulted incidents, initiated by the insurgents "eninitvinc"
  
  "(3)" = feols(govtvinc ~ logcavendishinter2002_pop + zrain + wetrain + wettemp + temperature + typhoon | year + pcode, data = data_table, weights =  data_table$pop2000, cluster = data_table$pcode), #The outcome variable of interest is the number of violent incidents with at least one government casualty "govtvinc"
  
  "(4)" = feols(envinc ~ logcavendishinter2002_pop + zrain + wetrain + wettemp + temperature + typhoon | year + pcode, data = data_table, weights =  data_table$pop2000, cluster = data_table$pcode), #The outcome variable of interest is the number of violent incidents with at least one insurgent casualty "envinc"
  
  "(5)" = feols(civvinc ~ logcavendishinter2002_pop + zrain + wetrain + wettemp + temperature + typhoon | year + pcode, data = data_table, weights =  data_table$pop2000, cluster = data_table$pcode) #The outcome variable of interest is the number of violent incidents with at least one civilian casualty "civvinc"
  
)

#The rest of the chunk follows the same principle as usual, with extra rows to provide more information and optical adjustments of the table’s appearance

rows <- tribble(~term, ~"(1)", ~"(2)", ~"(3)", ~"(4)", ~"(5)",
                "Mean of dependent variable", as.character(sprintf("%.2f", mean(data_table$govinitvinc))), as.character(sprintf("%.2f", mean(data_table$eninitvinc))), as.character(sprintf("%.2f", mean(data_table$govtvinc))), as.character(sprintf("%.2f", mean(data_table$envinc))), as.character(sprintf("%.2f", mean(data_table$civvinc))),
                "Control variables", "Yes", "Yes", "Yes", "Yes", "Yes",
                "Year FE", "Yes", "Yes", "Yes", "Yes", "Yes",
                "Province FE", "Yes", "Yes", "Yes", "Yes", "Yes",
                "No. of provinces", as.character(length(unique(data_table$pop2000))), as.character(length(unique(data_table$pop2000))), as.character(length(unique(data_table$pop2000))), as.character(length(unique(data_table$pop2000))), as.character(length(unique(data_table$pop2000))))

attr(rows, 'position') <- c(3:7)

modelsummary(Table_5_list,
             title = "TABLE 5. Who initiates and who suffers the violence?",
             stars = c("*" = 0.1, "**" = 0.05, "***" = 0.01),
             fmt = 3,
             coef_map = c("logcavendishinter2002_pop" = "Cavendish prod. (kg per cap.) x \n Log Price"),
             coef_omit = "^(?!.*log)",
             gof_omit = "R2|R2 Adj.|AIC|BIC|RMSE|Std.Errors|FE:",
             add_rows = rows,
             notes = 'Notes from Crost and Felter (2020, p. 1504): "All regressions control for rainfall and temperature during the wet and dry season, as well as an indicator that takes the value 1 if the province was hit by a major typhoon. Standard errors, clustered at the province level, are in parentheses." *Significant at 10% level, **significant at 5% level, and ***significant at 1% level.',
             output = "kableExtra") %>%
             add_header_above(c(" " = 1, "Government" = 1, "Insurgents" = 1, "Armed Forces" = 1, "Insurgent" = 1, "Civilian" = 1)) %>%
             add_header_above(c(" " = 1, "Initiated by" = 2, "Casualties suffered among" = 3)) %>%
             row_spec(seq(1, 2 ,2), background="#ecf6ff")

```

According to the research conducted by Crost and Felter (2020, p. 1504), the evidenced Table 5 is divided into two parts. On the left-hand side, the influence of the Cavendish banana value on the **initiator of the fierce actions** is estimated. The estimates on the right-hand side reflect the impact of the Cavendish banana value on **multiple conflict parties who have experienced at least one casualty in the armed disputes**. The effect is roughly the same for both government-initiated and insurgent-initiated violent actions, as shown by columns (1) and (2). However, only the effect for the insurgent-initiated disputes is statistically significant at the 1% level. The estimated coefficient of column (2) implies that a province with a standard provincial production of 9.36kg bananas and a price rise of 87%, *as described in Exercise 3.3 in combination with Table 1*, would experience $$0.082 * 9.36 * 0.87 = 0.6677$$ more insurgent-initiated violent crimes, compared to a non-producing province. A notable observation is that the coefficient estimates are similarly low, yet the *mean of the dependent variable, which represents the average number of violent incidents initiated by the insurgents, is 4.31 and significantly higher than that of the government*. Moreover, the magnitude of the impact is most pronounced in accidents involving one or more governmental fatalities, unveiled in columns (3) to (5). Comparatively, the impact of violent actions with rebel and civilian fatalities is notably diminished. On average, the number of violent incidents in a province, with one or more civilian deaths, is relatively *"little"*, when comparing it to the other parties. All three estimates have ridiculously small values, but they are all statistically significant at the 5% level or lower. The estimated coefficient of column (3) implies that a province with a baseline Cavendish banana production of 1kg per capita and a hypothetical 10% rise in the global market price, would experience $$0.133 * 1 * 0.10 = 0.0133$$ more armed disputes with one or more governmental deaths, compared to a non-producing province. **If we extrapolate this to a larger amount of average banana production and a higher degree of price increase to all banana-producing provinces in the Philippines, this assumes a significantly high value!** Based on our estimates in column (3), a standard provincial production of 9.36kg bananas and a price rise of 87%, *as described in Exercise 3.3 in combination with Table 1*, it would imply that the whole Philippines would experience additional $$0.133 * 9.36 * 0.87 * 29 ≈ 32$$ armed disputes with one or more governmental deaths, per year!


Quiz: Based on the analytical outcomes presented in Table 5, is it possible to reject the hypothesis by Crost and Felter (2020, p. 1504) regarding the strength of the rebel organizations?

(1) The hypothesis can be rejected
(2) The hypothesis cannot be rejected

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("Hypothesis Table 5")
```

<br/>

Given the **positive relationship** between the Cavendish banana value and aggregated rebel strength, it is essential to *identify the relative contribution of each rebel group to the conflict*. Hence, the authors further present a comparative analysis of the NPA, MILF, and ASG insurgent groups by estimating their respective effects on violence. Background on these groups was provided in Chapter 1 of this Problem Set.

**Task 50:** The code presented below performs regressions to *examine the variation in the share of violent incidents across different groupings of rebel organizations.* The regressions have a consistent structure with the central `feols()` function, the main interaction term as a regressor, and the inclusion of all Control Variables as in previous tables. Similar to Table 5, the outcome variable of interest differs by rebel group. One outcome variable represents the **number of violent incidents associated to one specific rebel organization**. To execute the code chunk, click on the `check` button.

```{r "15_4"}

Table_6_list <- list(
  
  "(1)" = feols(ctm_vinc ~ logcavendishinter2002_pop + zrain + wetrain + wettemp + temperature + typhoon | year + pcode, data = data_table, weights =  data_table$pop2000, cluster = data_table$pcode), #The outcome variable of interest is the number of violent incidents involving the NPA "ctm_vinc"
  
  "(2)" = feols(mus_vinc ~ logcavendishinter2002_pop + zrain + wetrain + wettemp + temperature + typhoon | year + pcode, data = data_table, weights =  data_table$pop2000, cluster = data_table$pcode), #The outcome variable of interest is the number of violent incidents involving the MILF "mus_vinc"
  
  
  "(3)" = feols(asg_vinc ~ logcavendishinter2002_pop + zrain + wetrain + wettemp + temperature + typhoon | year + pcode, data = data_table, weights =  data_table$pop2000, cluster = data_table$pcode) #The outcome variable of interest is the number of violent incidents involving the ASG "asg_vinc"
  
)

#The rest of the chunk follows the same principle as usual, with extra rows to provide more information and optical adjustments of the table’s appearance

rows <- tribble(~term, ~"(1)", ~"(2)", ~"(3)",
                "Mean of dependent variable", as.character(sprintf("%.2f", mean(data_table$ctm_vinc))), as.character(sprintf("%.2f", mean(data_table$mus_vinc))), as.character(sprintf("%.2f", mean(data_table$asg_vinc))), 
                "Control variables", "Yes", "Yes", "Yes",
                "Year FE", "Yes", "Yes", "Yes",
                "Province FE", "Yes", "Yes", "Yes",
                "No. of provinces", as.character(length(unique(data_table$pop2000))), as.character(length(unique(data_table$pop2000))), as.character(length(unique(data_table$pop2000))))

attr(rows, 'position') <- c(3:7)

modelsummary(Table_6_list,
             title = "TABLE 6. Effect on conflict of different rebel groups.",
             stars = c("*" = 0.1, "**" = 0.05, "***" = 0.01),
             fmt = 3,
             coef_map = c("logcavendishinter2002_pop" = "Cavendish prod. (kg per cap.) x Log Price"),
             coef_omit = "^(?!.*log)",
             gof_omit = "R2|R2 Adj.|AIC|BIC|RMSE|Std.Errors|FE:",
             add_rows = rows,
             notes = 'Notes from Crost and Felter (2020, p. 1505): "All regressions control for rainfall and temperature during the wet and dry season, as well as an indicator that takes the value 1 if the province was hit by a major typhoon. Standard errors, clustered at the province level, are in parentheses." *Significant at 10% level, **significant at 5% level, and ***significant at 1% level.',
             output = "kableExtra") %>%
             add_header_above(c(" " = 1, "NPA" = 1, "MILF" = 1, "ASG" = 1)) %>%
             add_header_above(c(" " = 1, "Violent incidents involving" = 3)) %>%
             row_spec(seq(1, 2 ,2), background="#ecf6ff")

```

We will discuss the main findings and implications of Table 6. As reported by Crost and Felter (2020, p. 1504), the table provides a comparative analysis of the impacts of provincial Cavendish banana output in combination with the global market price, on the **frequency of violent events by three rebel groups**. The pronounced influence of banana value is *most prominently observed in violent actions including the NPA*. This is in accordance with the mechanism described earlier, in which this organization **sustains its financial resources through the extortion of banana plantations**. The observed effect attains a moderate level of significance at the 10% threshold. Moreover, the impact remains consistent for both the MILF and ASG, albeit with low magnitudes. Notably, the effect associated with the ASG attains statistical significance at the 5% level, whereas the effect affiliated with the MILF lacks statistical significance. This analysis reveals that the **highest proportion of violent incidents were committed by the NPA organization**, as evidenced by a notably elevated average frequency of armed disputes across the regions during the period of observation.

<br/>

After performing multiple regression analyses, we wonder **what other factors might influence the number of violent events in each province apart from the value of Cavendish banana**. To answer this question, Crost and Felter (2020, p. 1504f.) examine how the impacts vary, depending on the *initial levels of three features* in different provinces.

* The first feature is to consider the role of **poverty**. Miguel (2007, p. 51f.) argues that the main triggers of civil wars in developing countries are *poverty and declining earnings*. This could be explained by the fact that poverty leads to armed aggression that targets assets and natural resources. This is what is known as the *"poverty-violence nexus"*. In addition, the *opportunity cost effect* arises because the lack of legal income opportunities makes entering a violent faction more appealing for unemployed younger males, particularly when they have few other possibilities for income, education, or social mobility. *The poorer the people are, the lower the barrier of risk-engaging becomes.* This results in increased looting or smuggling actions, which in turn strengthens the rebelling organizations. **This factor could increase the likelihood of conflict.**

* According to Crost and Felter (2020, p. 1505), **road infrastructure** is another crucial factor to consider. The designed road network in the Philippines **could reduce the intensity of the conflict** because it enables the governmental authorities to swiftly counter the insurgent extortion attacks.

* The final factor that the researchers identified as a possible determinant of the frequency of violent incidents is the **proportion of the population that follows Islam**. These individuals may sympathize with or belong to Muslim organizations such as the MILF or ASG. These receive financial support from Islamic countries such as Saudi Arabia and others, to overthrow the Philippine government and establish an Islamic state, as outlined previously in the first exercise of this Problem Set. **This situation could increase the probability of violence.**

```{r eval=FALSE}
# Run for additional info in the Viewer pane
info("complete.cases() function in R")
```

**Task 51:** To perform the analyses under the consideration of the **three stated features**, we *first need to adapt* our central data frame `data_table`. This is necessary because we have values that are *not available for the variable* `povertyinter`, which is the interaction term of *Cavendish banana value times poverty rate*. We want to get rid of the NA values. To do so, we make use of the `complete.cases()` function. **Review the Info block above** and fill in the blanks to create the new data frame `data_table_complete` for the analyses. 

```{r "15_8"}

data_table_complete <- ___[___(data_table$___), ] 

```

We now obtain a data frame that contains all the variables and a complete set of observations for the `povertyinter` variable. This resulted in the exclusion of *16 rows that had missing values for this variable across all the columns*. With this data frame, in combination with the central data set `data_table`, we proceed to **conduct the analyses on the described three features.**

**Task 52:** We aim to perform the regressions and examine, *which of the three factors might influence the number of violent actions besides the value of Cavendish banana*. The structure of the regressions is well known. In each, we include all Control Variables, year and province FE, and weight the observations by the province population in 2000. We also cluster the standard errors at the province level to correct for potential heteroskedasticity. However, we introduce the **poverty rate in the first regression**, the **proportion of Muslim population in the second regression,** and the **road infrastructure in the third**. In the **final regression, we include all three factors** to assess their joint significance. Fill in the blanks in the following chunk under the incorporation of the instructions and explanations in the comments. **Moreover, one comment is essential to know! Each new regressor of the three possible features incorporates the Cavendish banana value as an interaction!** *This is because we have shown so far that the Cavendish banana value has a significant impact on provincial violence. If we would not include this as a regressor in the specific regression, we would automatically shift the Cavendish banana value into the error term and face the problem of endogeneity with biased estimates!*

```{r "15_9"}

Table_7_list <- list(
  
  "(1)" = feols(vinc ~ ___ + ___ + zrain + wetrain + wettemp + temperature + typhoon | year + pcode, data = ___, weights =  ___$pop2000, cluster = ___$pcode), #We want to explain the number of violent incidents "vinc" with the baseline interaction term of Cavendish banana value "logcavendishinter2002_pop" for comparison. Moreover, we incorporate the variable "povertyinter", which is an extension of the baseline interaction term by multiplying the provincial poverty rate to it. Since we use this variable, we have to apply the regression on the newly created data frame. There exists a full set of observations for the poverty rate
  
  "(2)" = ___(vinc ~ logcavendishinter2002_pop + ___ + zrain + wetrain + wettemp + temperature + typhoon | year + pcode, data = ___, weights =  ___$pop2000, cluster = ___$pcode), #In this regression, we do not want to incorporate the poverty rate, but the proportion of Muslim population instead. Therefore, the variable "musliminter" is an extension of the baseline interaction term, like with the poverty rate before, by multiplying the percentage of the population to it. Given that the poverty rate is not relevant for our analysis, we employ our central table data frame "data_table" that contains a complete set of observations for the variables of interest
  
  "(3)" = feols(vinc ~ logcavendishinter2002_pop + ___ + zrain + wetrain + wettemp + temperature + typhoon | year + pcode, data = data_table, weights =  data_table$pop2000, cluster = data_table$pcode), #In this regression, we want to incorporate the road density instead, which can be done with the variable "roadinter", which is also an extension of the baseline interaction term
  
  "(4)" = feols(vinc ~ ___ + povertyinter + ___ + musliminter + zrain + wetrain + wettemp + temperature + typhoon | year + pcode, data = ___, weights =  ___$pop2000, cluster = ___$pcode) #In the last regression we incorporate all three factors besides the Cavendish banana value. Since we use the variable "povertyinter", we have to apply the regression on the newly created data frame. There exists a full set of observations for the poverty rate
  
)

#The rest of the chunk follows the same principle as usual, with extra rows to provide more information and optical adjustments of the table’s appearance

rows <- tribble(~term, ~"(1)", ~"(2)", ~"(3)", ~"(4)",
                "Mean of dependent variable", as.character(sprintf("%.2f", mean(data_table$vinc))), as.character(sprintf("%.2f", mean(data_table$vinc))), as.character(sprintf("%.2f", mean(data_table$vinc))), as.character(sprintf("%.2f", mean(data_table$vinc))),
                "Control variables", "Yes", "Yes", "Yes", "Yes",
                "Year FE", "Yes", "Yes", "Yes", "Yes",
                "Province FE", "Yes", "Yes", "Yes", "Yes",
                "No. of provinces", as.character(length(unique(data_table_complete$pop2000))), as.character(length(unique(data_table$pop2000))), as.character(length(unique(data_table$pop2000))), as.character(length(unique(data_table_complete$pop2000))))

attr(rows, 'position') <- c(9:13)

modelsummary(Table_7_list,
             title = "TABLE 7. Heterogeneity analysis.",
             stars = c("*" = 0.1, "**" = 0.05, "***" = 0.01),
             fmt = 3,
             coef_map = c("logcavendishinter2002_pop" = "Cavendish prod. (kg per cap.) x Log Price", "povertyinter" = "Cavendish prod. x Log Price x Poverty rate", "roadinter" = "Cavendish prod. x Log Price x Road density", "musliminter" = "Cavendish prod. x Log Price x \n Percent Muslim population"),
             coef_omit = "^(?!.*log |.*inter)",
             gof_omit = "R2|R2 Adj.|AIC|BIC|RMSE|Std.Errors|FE:",
             add_rows = rows,
             notes = 'Notes from Crost and Felter (2020, p. 1505): "All regressions control for rainfall and temperature during the wet and dry season, as well as an indicator that takes the value 1 if the province was hit by a major typhoon. Data on percentage Muslim population and road density (percentage of villages with highway access) come from the 2000 Census. Data on the poverty rate come from the 1997 Family Income and Expenditure Survey (FIES). All three variables are expressed as deviations from the sample mean so that the coefficient in the first row represents the difference-in-differences estimate for the average province. Standard errors, clustered at the province level, are in parentheses." *Significant at 10% level, **significant at 5% level, and ***significant at 1% level.',
             output = "kableExtra") %>%
             add_header_above(c(" " = 1, "Violent incidents" = 4)) %>%
             row_spec(seq(1, 8 ,2), background="#ecf6ff")

```

Table 7 presents the results of the regression analyses of the Cavendish value in combination with the *three described provincial characteristics, on the regional number of violent actions*. The table and Crost and Felter (2020, p. 1505f.) report that the Cavendish banana value, interacted with the poverty rate or the proportion of the population that follows Islam, *has no significant effect on the dependent variable*, as shown in columns (1) and (2). The coefficient estimate in column (1) is close to zero and not statistically significant, while the coefficient estimate of the extended interaction term in column (2) is negative and not statistically significant. The same conclusion holds for column (4). The *joint significance test for the three factors yields an insignificant result, indicating that the provincial number of accidents remains unchanged after accounting for these factors simultaneously*. However, column (3) reveals a noteworthy interaction effect of the Cavendish banana value in combination with the road density. The estimated coefficient is negative with high magnitude and a statistical significance at the 1% threshold. **This implies that the impact of Cavendish banana value on the violent frequency per region is substantially lower in areas where the street density is elevated.**


Quiz: How does this result reflect the author's intention for considering the factor of road infrastructure in their analysis?

(1) It is in line with the intention of the authors
(2) It is not in line with the intention of the authors

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("Intention Table 7")
```


<br/>

## Exercise 6 -- Possible Mechanisms

In this exercise you will dive into *potential interpretations for the outcomes* observed earlier in the regressions. These examined the connection between the occurrence of violent events at the provincial level and various modifications of the baseline interaction term involving the Cavendish banana value. Our objective is to *illuminate potential pathways* connecting the plant values and instances of armed disputes.

<br/>

Building on that, Crost and Felter (2020, p. 1506) conduct an **initial investigation of the effect of pre-existing rebel dominance in banana-producing provinces**. The focus is to examine the relationship between the rise in the value of Cavendish banana and the escalation of provincial violence under the question of *how the provincial rebel control affect this relationship.* As illustrated in Figure 10 of Exercise 1.2 of this Problem Set, using the *Contest-Success-Function (CSF)*, we expect that there exists a concave link between rebel strength (relative to the government) and violence. The *potential for violence is therefore allocated to the strength of the insurgent group*. To verify the concept of this CSF, we **examine whether the value of Cavendish banana influences the provincial violent actions differently, depending on the level of baseline NPA control in each province.** The CSF implies that violence is minimal in areas with either low or high level of NPA strength. We also investigate the **impact of the banana value and the variation in provincial baseline NPA control on the number of villages under the NPA authority**.

**Task 53:** As usual, at the start of each exercise, we begin by importing the data set that we will analyze. Read in the data frame `replication_data.dta` and store it in the variable `data`. 

```{r "16_1"}
#Load the necessary package, import the data, and save it in the correct variable
```

**Task 54:** As always, subset the data set to include only the observations from the *years 2001 to 2009*. Complete it independently and refer to the previous chapters if you encounter any difficulties. Save the new data frame in the variable `data_table`

```{r "16_2"}
#Load the necessary package, filter the data set according to the right yearly period, and save it in the correct variable
```

**Task 55:** To perform the analysis of examining the role of baseline rebel control, we face the same issue with the `data_table` data frame as in the exercise before. We need to adjust this set because we have values that are *not available for the variable* `infiltrated`, which is the **number of villages controlled by the NPA insurgent organization**. *We want to get rid of these NA values!* To do so, we make use of the `complete.cases()` function. *Create the new data frame* `data_table_inf`  based on `data_table`. This newly created data set should *incorporate all columns containing a full set of observation* for the `infiltrated` variable. Remind yourself of how the `complete.cases()` function is applicable and how the *square brackets* are utilized. **The concept is like you have seen before!** Nevertheless, if you have problems, take a look at the last exercise and see how it is done there!

```{r "16_3"}
#Based on "data_table", utilize the function in the right way, incorporate the square brackets, use the correct variable of interest, and save it in the appropriate variable
```

By selecting this data frame, which includes all variables and a complete set of observation for the `infiltrated` variable, we eliminated **462 rows that had missing values for the corresponding variable** for any of the columns. This is a *substantial amount of data loss*, which could be **attributed to the difficulty, risk, and non-transparency of collecting data on the number of villages under NPA authority!**

**Task 56:** Equipped with this data set, in combination with the central `data_table` data frame, we proceed to conduct the analysis mentioned at the start of this exercise. In column (1), we examine the impact of low, medium, or high baseline NPA control on violent actions. In columns (2) and (3) we furthermore investigate the effect of the number of villages under NPA authority. To execute the code chunk, click on the `check` button. Explanations can be viewed in the comments. 

```{r "16_4"}

library("fixest")
library("modelsummary")
library("kableExtra")

Table_8_list <- list(
  
  "(1)" = feols(vinc ~ noinfilXlogcavinter02_pop + infil_pcntg0Xlogcavinter02_pop + infil_pcntg50Xlogcavinter02_pop + zrain + wetrain + wettemp + temperature + typhoon | year + pcode, data = data_table, weights =  data_table$pop2000, cluster = data_table$pcode), #We try to explain the number of provincial violent actions with three extensions of our standard Cavendish value interaction term. "noinfilXlogcavinter02_pop" is the extension by multiplying the standard interaction term with low insurgent NPA control, "infil_pcntg0Xlogcavinter02_pop" with medium NPA control and "infil_pcntg50Xlogcavinter02_pop" is the multiplication with high insurgent NPA strength. These variables are extensions of the baseline Cavendish value interaction term because of the same principle with the endogeneity problem, that we employed in the previous Table 7 with the three investigation features. We use the central "data_table" data set because we do not need observations for the variable "infiltrated" 
  
  "(2)" = feols(infiltrated ~ logcavendishinter2002_pop + zrain + wetrain + wettemp + temperature + typhoon | year + pcode, data = data_table_inf, weights =  data_table_inf$pop2000, cluster = data_table_inf$pcode), #Here we try to explain the number of villages under NPA authority, called "infiltrated", with the basic Cavendish value "logcavendishinter2002_pop". It is necessary to use the newly created data frame "data_table_inf" due to the problem of missing observations 
  
  "(3)" = feols(infiltrated ~ noinfilXlogcavinter02_pop + infil_pcntg0Xlogcavinter02_pop + infil_pcntg50Xlogcavinter02_pop + zrain + wetrain + wettemp + temperature + typhoon | year + pcode, data = data_table_inf, weights =  data_table_inf$pop2000, cluster = data_table_inf$pcode) #In the last regression, we regress the number of villages under NPA authority ("infiltrated") with the three different extensions of the standard interaction term, to incorporate the different levels of baseline NPA strength. Furthermore, it is also necessary to use the newly created data frame "data_table_inf", since we employ the "infiltrated" column
  
)

#The rest of the chunk follows the same principle as usual, with extra rows to provide more information and optical adjustments of the table’s appearance

rows <- tribble(~term, ~"(1)", ~"(2)", ~"(3)",
                "Mean of dependent variable", as.character(sprintf("%.2f", mean(data_table$vinc))), as.character(sprintf("%.2f", mean(data_table_inf$infiltrated))), as.character(sprintf("%.2f", mean(data_table_inf$infiltrated))),
                "Control variables", "Yes", "Yes", "Yes",
                "Year FE", "Yes", "Yes", "Yes",
                "Province FE", "Yes", "Yes", "Yes",
                "No. of provinces", as.character(length(unique(data_table$pop2000))), as.character(length(unique(data_table_inf$pop2000))), as.character(length(unique(data_table_inf$pop2000))))

attr(rows, 'position') <- c(9:13)

modelsummary(Table_8_list,
             title = "TABLE 8. The role of baseline insurgent control.",
             stars = c("*" = 0.1, "**" = 0.05, "***" = 0.01),
             fmt = 3,
             coef_map = c("logcavendishinter2002_pop" = "Cavendish prod. (kg per cap.) x Log Price", "noinfilXlogcavinter02_pop" = "Cavendish prod. x Log Price x Low control", "infil_pcntg0Xlogcavinter02_pop" = "Cavendish prod. x Log Price x Medium control", "infil_pcntg50Xlogcavinter02_pop" = "Cavendish prod. x Log Price x High control"),
             coef_omit = "^(?!.*log |.*pop)",
             gof_omit = "R2|R2 Adj.|AIC|BIC|RMSE|Std.Errors|FE:",
             add_rows = rows,
             notes = 'Notes from Crost and Felter (2020, p. 1506): "All regressions control for rainfall and temperature during the wet and dry season, as well as an indicator that takes the value 1 if the province was hit by a major typhoon. Standard errors, clustered at the province level, are in parentheses." *Significant at 10% level, **significant at 5% level, and ***significant at 1% level.',
             output = "kableExtra") %>%
             add_header_above(c(" " = 1, "Violent \n incidents" = 1, "Number of villages \n controlled by NPA" = 2)) %>%
             row_spec(seq(1, 8 ,2), background="#ecf6ff")

```

Main findings of this table are as follows. Crost and Felter (2020, p. 1506) report that the Cavendish banana value has a differential effect on the frequency of violent actions across provinces with varying levels of baseline NPA strength, based on the estimates from column (1) in Table 8. Specifically, they find that a **rise in the Cavendish banana value is associated with growing violence in low and medium NPA enforcement areas, while it is associated with a significant violence reduction in counties with strong NPA regulation**. The estimated coefficient for low insurgent control is positive, but little in magnitude, relative to the medium and high control estimate. The medium strength coefficient is also positive, statistically significant as well and large in size. For high NPA baseline control, the estimate is clearly negative. **These results are in line with the mechanism of the CSF specified earlier**. This function predicts that provincial violence declines if the rebels have low territorial enforcement relative to the governmental authorities. However, as seen in column (1), a marginal increase in violent events occurs in this low base scenario if the Cavendish value rises. *This is since a higher banana value induces the rebel organizations to augment their provincial influence and strive for more power. This leads to a slight escalation in violence which is evident here.* **The medium and high rebel strength scenarios are also compatible with the CSF**. In the medium scenario, we expect that the degree of violence will be the highest in regions where the rebel and governmental strength is balanced. This is because both sides will seek to establish their dominance over the territory. This hypothesis is consistent with the estimated coefficient, *which shows a significant rise in the likelihood of conflict when the Cavendish banana value increases*. Furthermore, the last regression estimate of column (1) confirms the expected outcome that provincial conflict diminish significantly under the high control scenario. *This outcome occurs as the enhanced value of Cavendish banana enables the NPA to continue the spread of supremacy over territories where they are increasingly organized*. This results in a reduction of violent incidents due to the government's limited capability to challenge the rebels for dominance in that location.

<br/>

As Crost and Felter (2020, p. 1507) indicate, the results in columns (2) and (3) of Table 8 *provide empirical support for the mechanism in column (1)*, by examining how the variation in the Cavendish value affects the number of villages under NPA influence. The result in column (2) reveals that there is a **positive and statistically significant effect of the value of Cavendish banana on the number of towns under NPA impact**. Based on this estimated coefficient, a standard provincial production of 9.36kg bananas and a price rise of 87%, as described in Exercise 3.3 in combination with Table 1, this would imply that the Cavendish banana-producing provinces would experience additional $$1.588 * 9.36 * 0.87 * 29 ≈ 375$$ villages that are under the supremacy of the armed NPA group in the whole Philippines per year. *This value is exceptionally high*. The findings presented in column (3) imply that the **initial stage of NPA insurgent strength is responsible for the magnitude of the impact** observed in column (2). Upon integrating the varying baseline situations of insurgent influence, it becomes apparent that the effect of the Cavendish value on the number of villages under NPA authority is *more pronounced when the initial level of insurgent control is elevated*. This observation is in line with what is intuitively expected.

<br/>

According to our research, **large Cavendish banana farms are mainly being forced to pay extortion money to rebel groups who use the fees to finance their violent activities.** We propose that the *opportunity cost effect* explains why large plantations are more attractive targets for insurgents, as they can generate more revenue by raiding one big farm instead of many small ones. This is because raiding smaller farms entails a higher cost of extortion, as it requires more troop movement and coordination than raiding a big farm. Therefore, the expected payoff and the cost-benefit ratio are higher for large plantations, when the concentration of banana cultivation is high. *To verify this mechanism, we need to examine the effect of farm size and market concentration on the likelihood of extortion and thus the number of violent incidents!*

<br/>

Following Crost and Felter's (2020, p. 1507) observation, the Philippine banana industry exhibits a **strong degree of concentration** in a few large-scaled plantations. These plantations are characterized by having a land area of **more than 25 hectares**. We explore, if the *impact of Cavendish banana value on exacerbating conflict shows variations depending on the scale of farms where the plants are cultivated*, aiming to explain the underlying mechanism.

**Task 57:** To complete this task, you need to substitute the empty blanks in the following code segment and refer to the explanations provided here. We use the main table data frame `data_table` for this regression purpose. The first two regressions of the table try to explain the *number of violent incidents using two variations of our baseline Cavendish value interaction term*. As mentioned by Crost and Felter (2020, p. 1507), the variable `plantationmedinter` is constructed by *multiplying the baseline interaction term with the proportion of banana plants in big plantations that fall below the median value* in our sample. Similarly, the variable `plantationmedinter2` is created by *multiplying the standard Cavendish value term with the proportion of banana trees in big plantations that exceed the median value* in our sample. In columns (1) and (2) we use both variables and regress it on the number of incidents as the dependent variable. The only difference is that in column (2) we *additionally include all described Control Variables* to obtain more accurate and consistent estimates of the effect. Then, we extend the analysis of the determinants of violent riots through the introduction of two new interaction terms in columns (3) and (4). As Crost and Felter (2020, p. 1508) explained, the first interaction term, `plantationtreesinter`, captures the *interaction of the global banana price and the amount of banana plants in plantations with more than 25 hectares of agricultural land*. The second interaction term, `bananatreesinter`, records the relationship between the *price and the amount of high-yielding banana trees in the Philippines overall*. In both columns, we use these two variables as regressors, but in column (4) we furthermore control for all Control Variables. We employ FE, weights, and Cluster Robust Standard Errors as in the preceding tables.

```{r "16_5"}

Table_9_list <- list(
  
  "(1)" = feols(___ ~ ___ + ___ | year + pcode, data = data_table, weights =  data_table$pop2000, cluster = data_table$pcode),
  
  "(2)" = ___(vinc ~ plantationmedinter + plantationmedinter2 + ___ + wetrain + wettemp + ___ + typhoon | year + pcode, data = data_table, weights =  data_table$pop2000, cluster = data_table$pcode),
  
  "(3)" = feols(vinc ~ ___ + ___ | year + pcode, data = data_table, weights =  data_table$pop2000, cluster = data_table$pcode),
  
  "(4)" = ___(___ ~ plantationtreesinter + bananatreesinter + zrain + ___ + wettemp + temperature + ___ | year + pcode, data = data_table, weights =  data_table$pop2000, cluster = data_table$pcode)
  
)

#The rest of the chunk follows the same principle as usual, with extra rows to provide more information and optical adjustments of the table’s appearance

rows <- tribble(~term, ~"(1)", ~"(2)", ~"(3)", ~"(4)",
                "Mean of dependent variable", as.character(sprintf("%.2f", mean(data_table$vinc))), as.character(sprintf("%.2f", mean(data_table$vinc))), as.character(sprintf("%.2f", mean(data_table$vinc))), as.character(sprintf("%.2f", mean(data_table$vinc))),
                "Control variables", "No", "Yes", "No", "Yes",
                "Year FE", "Yes", "Yes", "Yes", "Yes",
                "Province FE", "Yes", "Yes", "Yes", "Yes",
                "No. of provinces", as.character(length(unique(data_table$pop2000))), as.character(length(unique(data_table$pop2000))), as.character(length(unique(data_table$pop2000))), as.character(length(unique(data_table$pop2000))))

attr(rows, 'position') <- c(9:13)

modelsummary(Table_9_list,
             title = "TABLE 9. The role of banana plantations.",
             stars = c("*" = 0.1, "**" = 0.05, "***" = 0.01),
             fmt = 3,
             coef_map = c("plantationmedinter" = "Cavendish prod. x Log price x \n Plantation percentage below median", "plantationmedinter2" = "Cavendish prod. x Log price x \n Plantation percentage above median", "plantationtreesinter" = "Banana trees in plantations (per cap.) x Log price", "bananatreesinter" = "Banana trees (per cap.) x Log price"),
             coef_omit = "^(?!.*plant|.*bana)",
             gof_omit = "R2|R2 Adj.|AIC|BIC|RMSE|Std.Errors|FE:",
             add_rows = rows,
             notes = 'Notes from Crost and Felter (2020, p. 1507): "For this analysis, we define banana plantations as farms larger than 25 hectares, the largest size category recorded in the Agricultural Census of the Philippines. Control variables are rainfall and temperature during the wet and dry season, as well as an indicator that takes the value 1 if the province was hit by a major typhoon. Standard errors, clustered at the province level, are in parentheses." *Significant at 10% level, **significant at 5% level, and ***significant at 1% level.',
             output = "kableExtra") %>%
             add_header_above(c(" " = 1, "Violent incidents" = 4)) %>%
             row_spec(seq(1, 8 ,2), background="#ecf6ff")

```

Table 9 provides insights into the effects of the Cavendish value extensions and the newly explored interaction terms on the occurrence of violence. Based on the table and the description of Crost and Felter (2020, p. 1507f.), the coefficient estimates of pillars (1) and (2) reveal how the evolution of the Cavendish banana value affects the number of violent disputes in **provinces with different shares of banana plants in plantations with more than 25 hectares of land**. The previously analyzed positive association between Cavendish banana value and conflict intensity is statistically significant just in regions of the Philippines, **where the median value for the share of banana plants in large-scale farms is exceeded**. We obtain negative coefficients for regions with the share of banana plants being lower than the median, but they do not reach the level of statistical significance. This observation reveals the *working of the described opportunity cost mechanism* and emphasizes the tendency of the rebel organizations to *target their extortion efforts on large plantations with extensive banana cultivation!*

The relationship between the local distribution of banana plants as well as their productivity, and the frequency of violent events, is examined in columns (3) and (4) of Table 9. Given that we incorporate Control Variables in column (4), these coefficients can be seen as our most reliable ones. The estimate for the first regressor is highly significant at the 1% threshold. On the basis of this estimate, if we assume that we are looking at only one Cavendish banana tree in a plantation of a single province, and a price rise of 87%, as described in Exercise 3.3 in combination with Table 1, we would expect a significant increase in violence. In particular, **one additional banana plant situated in a large-scale farm** would cause $$2.558 * 1 * 0.87 * 1 ≈ 2$$ more violent events per year in that region where the plantation is situated. *This number is extraordinarily high when you consider that we only looked at one additional banana plant!*

The second regressor estimates in columns (3) and (4) indicate that the price, in combination with the overall amount of high-yielding banana trees, is not significantly associated with the number of violent accidents at the provincial level. Therefore, Crost and Felter (2020, p. 1508) mentioned that the conflict intensity, in regions where banana plants are cultivated in minor plantations, **was not exposed to price fluctuations**. The total number of high-yielding banana trees includes the banana plants of small farms as well, but the insignificant effect indicates that these trees are *not a relevant factor for the rebel’s extortion decisions*. These findings indicate that the **agricultural scale of a farm is a crucial factor in shaping the impact of Cavendish value fluctuations on civil disputes**. Thus, we can *emphasize the cost-effect mechanism and its implications in combination with the indirect predation effect, that the rebel organizations will primarily blackmail money from large-scale farms!*

<br/>

After examining the effects of Cavendish banana value on the provincial violence rates, Crost and Felter (2020, p. 1508f.) mention in their final analysis some supplementary evidence on **how the market concentration influences civil disputes**. *The impact of various rising agricultural commodity values on the occurrence of violence in the Philippines requires further investigation.* Therefore, the next analysis focus on five commodities that were previously explored in preliminary exercises: **Cavendish banana, Saba banana, Lacatan banana, rice, and sugar**. These commodities have *distinct characteristics in terms of market structure*. Therefore, a comparative study of the crops influence on the number of incidents, accounting for their varying market structure, *requires normalization of the initial per capita provincial output for the five agricultural commodities*. This can be done by presenting the **initial output as standard errors from the average of the sample**.

**Task 58:** The following chunk performs multiple regressions that investigate the **relationship between various commodities and the number of violent incidents in the Philippines**, controlling for different types of market structures. As previously mentioned, the *normalized values for each commodity* are used in the regressions. Moreover, *we incorporate the influence of the provincial level of NPA insurgent control for the sugar commodity into our analysis*. In every model, all the Control Variables, year and province FE, Cluster Robust Standard Errors, and weights for the observations are employed as in previous tables. The data source is the central table data frame `data_table`, which does not have any missing observations for the variables of interest. To run the code segment, click on the `check` button. **Please examine the explanations in the comments to comprehend the logic and steps involved!**  

```{r "16_6"}

Table_10_list <- list(
  
  "(1)" = feols(vinc ~ logcavendishinter_std + logriceinter_std + logsugarinter_std + zrain + wetrain + wettemp + temperature + typhoon | year + pcode, data = data_table, weights =  data_table$pop2000, cluster = data_table$pcode), #As in all four regressions, we want to analyze the impact on the recorded violent events. In this one, we just incorporate the commodities of Cavendish banana, rice, and sugar since they all differ in their respective market structure and are not related to each other. The first regressor is "logcavendishinter_std", which is the interaction term of the Cavendish banana production standard deviation and the Log Cavendish price. The second regressor is "logriceinter_std", which describes the interaction term of the rice production standard deviation and the Log rice price. Moreover, the last regressor is "logsugarinter_std", which also characterize the interaction term of the normalized sugar value and the Log sugar price
  
  "(2)" = feols(vinc ~ logcavendishinter_std + logriceinter_std + noinfilXlogsugarinter_std + infil_pcntg0Xlogsugarinter_std + infil_pcntg50Xlogsugarinter_std + zrain + wetrain + wettemp + temperature + typhoon | year + pcode, data = data_table, weights =  data_table$pop2000, cluster = data_table$pcode), #In this regression, we just explore the impact of the normalized Cavendish banana and rice interaction term. Additionally, we expect that the sugar commodity has a significant impact on the number of provincial incidents, as sugar is also a vulnerable good in the Philippines. Therefore, according to the CSF, we incorporate the different baseline NPA provincial strengths as extensions of the normalized sugar interaction term (sugar production standard deviation times Log sugar price). "noinfilXlogsugarinter_std" is the extension with low NPA control, "infil_pcntg0Xlogsugarinter_std" with medium NPA strength and "infil_pcntg50Xlogsugarinter_std" is the extension with high provincial influence
  
  "(3)" = feols(vinc ~ logcavendishinter_std + logriceinter_std + logsugarinter_std + logsabaownpriceinter_std + loglacatanownpriceinter_std + zrain + wetrain + wettemp + temperature + typhoon | year + pcode, data = data_table, weights =  data_table$pop2000, cluster = data_table$pcode), #In the third regression, we expand the regression analysis of (1) with the normalized Saba banana ("logsabaownpriceinter_std") and Lacatan banana ("loglacatanownpriceinter_std") interaction term. Through that, we incorporate the different market structures of Lacatan and Saba, as these bananas are mainly cultivated for domestic consumption  
  
  "(4)" = feols(vinc ~ logcavendishinter_std + logriceinter_std + logsabaownpriceinter_std + loglacatanownpriceinter_std + noinfilXlogsugarinter_std + infil_pcntg0Xlogsugarinter_std + infil_pcntg50Xlogsugarinter_std + zrain + wetrain + wettemp + temperature + typhoon | year + pcode, data = data_table, weights =  data_table$pop2000, cluster = data_table$pcode) #Moreover, the last regression is a expansion as well. We incorporate the normalized Saba banana and Lacatan banana interaction term to the regression analysis of (2) with the different baseline provincial NPA strengths 
  
)

#The rest of the chunk follows the same principle as usual, with extra rows to provide more information and optical adjustments of the table’s appearance

rows <- tribble(~term, ~"(1)", ~"(2)", ~"(3)", ~"(4)",
                "Mean of dependent variable", as.character(sprintf("%.2f", mean(data_table$vinc))), as.character(sprintf("%.2f", mean(data_table$vinc))), as.character(sprintf("%.2f", mean(data_table$vinc))), as.character(sprintf("%.2f", mean(data_table$vinc))),
                "Control variables", "Yes", "Yes", "Yes", "Yes",
                "Year FE", "Yes", "Yes", "Yes", "Yes",
                "Province FE", "Yes", "Yes", "Yes", "Yes",
                "No. of provinces", as.character(length(unique(data_table$pop2000))), as.character(length(unique(data_table$pop2000))), as.character(length(unique(data_table$pop2000))), as.character(length(unique(data_table$pop2000))))

attr(rows, 'position') <- c(17:21)

modelsummary(Table_10_list,
             title = "TABLE 10. Other crops and civil conflict.",
             stars = c("*" = 0.1, "**" = 0.05, "***" = 0.01),
             fmt = 3,
             coef_map = c("logcavendishinter_std" = "Cavendish Prod. (SD) x Log Cavendish Price", "logsabaownpriceinter_std" = "Saba Prod. (SD) x Log Saba Price", "loglacatanownpriceinter_std" = "Lacatan Prod. (SD) x Log Lacatan Price", "logriceinter_std" = "Rice Prod. (SD) x Log Rice Price", "logsugarinter_std" = "Sugar Prod. (SD) x Log Sugar Price", "noinfilXlogsugarinter_std" = "Sugar prod. x Log Sugar Price x Low control", "infil_pcntg0Xlogsugarinter_std" = "Sugar prod. x Log Sugar price x Medium influence", "infil_pcntg50Xlogsugarinter_std" = "Sugar prod. x Log Sugar price x High influence"),
             coef_omit = "^(?!.*log|.*fil)",
             gof_omit = "R2|R2 Adj.|AIC|BIC|RMSE|Std.Errors|FE:",
             add_rows = rows,
             notes = 'Notes from Crost and Felter (2020, p. 1508): "All regressions control for rainfall and temperature during the wet and dry season, as well as an indicator that takes the value 1 if the province was hit by a major typhoon. Note that production levels are expressed in standard deviations to make estimates comparable across crops. Standard errors, clustered at the province level, are in parentheses." *Significant at 10% level, **significant at 5% level, and ***significant at 1% level.',
             output = "kableExtra") %>%
             add_header_above(c(" " = 1, "Violent incidents" = 4)) %>%
             row_spec(seq(1, 16 ,2), background="#ecf6ff")

```

A comprehensive analysis of Table 10 reveals that, consistent with the previous tables, the value of **Cavendish banana is a highly significant predictor of the number of provincial violent acts**. This can be attributed to the fact that *Cavendish bananas are grown in large-scale centralized monoculture plantations for export purposes*, as reported by Crost and Felter (2020, p. 1509).


Quiz: Based on the estimates presented in Table 10, which commodities are statistically not meaningful in explaining the variation of civil disputes?

(1) Cavendish banana, Saba banana and Lacatan banana
(2) Cavendish banana, rice, and sugar
(3) Rice, Lacatan banana and Saba banana
(4) Sugar, rice, and Saba banana

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("Commodities Table 10")
```

In contrast, Crost and Felter (2020, p. 1509) in combination with the empirical analysis of columns (1) and (3) of Table 10 suggest that there is a **positive and highly significant relationship between the rise of provincial sugar output and the escalation in the frequency of armed events**. These sugar coefficients imply that provinces, which have a *greater mean sugar output than the national average by one standard deviation, would experience 0.189 violent disputes more if the global market price of sugar rise by 10%*. The Philippine **sugar market resembles the Cavendish banana market in its high degree of centralization and density of sugar plantations**. This implies that *market concentration, as a measure of centralization, has a significant impact on the rising frequency of violent incidents* in these sectors. To examine the local distribution of the sugar effect, we refer to columns (2) and (4), following the same approach as in Table 8. These columns indicate that the **sugar impact is more pronounced in regions with low and medium levels of initial NPA insurgent strength**. Conversely, the effect diminishes as the provincial insurgent control increases, as shown by the negative and insignificant estimates. This *finding is in line with the evidence we obtained for the Cavendish bananas in Table 8*.

<br/>

Additionally, as described by Crost and Felter (2020, p. 1509), we conduct a graphical analysis to **examine the temporal dynamics of civil disputes in regions with distinct levels of initial crop output, as a check for the findings in Table 10**. These findings suggest that *only Cavendish banana and sugar production have a significant and positive effect on armed incidents. This effect is stronger in provinces with low and medium initial NPA rebel control*, while the other crops do not have a meaningful effect. Our approach relies on the specific ${\theta}_{j}$ estimates obtained from a regression that is similar to the one explained at the start of Exercise 4.1. This regression incorporates interactions of the *five initial crop output quantities and the annual indicator function*. Hence, the ${\theta}_{j}$ coefficient enables us to **record the gradient of the association of annual armed disputes and the regional power of plant cultivation**. As shown in **regression equation of Exercise 4.1**, we exclude the *year 2005* from the analysis and thus ${\theta}_{j}$ represents the slope in year j compared to the gradient of the omitted year 2005. Consequently, the graphical representation indicates a *slope coefficient of zero for the year 2005*. **To enable comparison with Table 10, the initial crop outputs, to conclude on the ${\theta}_{j}$ coefficients, and the corresponding commodity prices are normalized to a common scale as standard errors of the sample average over the entire observation period!** 

The following graphic is divided into five sections, each representing one of the five crops: Cavendish banana, sugar, rice, Lacatan banana, or Saba banana. In each division, we display the temporal value of the ${\theta}_{j}$ crop coefficient along with the temporal variation of the specific commodity price. *We can then evaluate the validity of the results in Table 10 by comparing the commodities* ${\theta}_{j}$ *coefficients with the price trend during the monitoring range*. **If there is a high degree of correlation between the two variables, we can confidently accept the findings in Table 10!** Otherwise, we can reject them as invalid.

**Task 59:** To perform the graphical analysis, it is necessary to import the needed data set. The required package should be loaded already. Read in the data frame `merged_data.dta` and store it in the variable `merged_data`. This data set, *that you have already used*, is specifically prepared to generate the graphical illustration of the ${\theta}_{j}$ coefficients for the five described commodities. **Note:** If you want to have an insight look, at how the new data set `merged_data.dta` resulted from the original one (`replication_data.dta`), feel free to look at the **Appendix**. 

```{r "16_7"}
#Import the data and save it in the correct variable
```

**Task 60:** The graphical analysis requires creating *separate frames for each commodity* and arranging them together using the `ggarrange()` function. **Pre-transformations are necessary to plot the variables on dual y-axes in one illustration**. The following code chunk displays the *association between violence intensity and the normalized prices of Cavendish banana, sugar, rice, Lacatan banana, and Saba banana*. Please click on the `check` button to execute the code. The comments explain the steps involved in the code, but the logic of the pre-transformation, the dual y-axes, and the correct legend is like the figure from Exercise 2.2 before.

```{r "16_8",fig.width=10, fig.height=10}

library("ggplot2")
library("ggpubr")

#We are trying to display different data that are scaled differently. To display them together in one plot, a pre-transformation is necessary for every separate graphic!

#Cavendish banana plot: 
ylim.prim_1 <- c(-1.3, 1.3) #Sets the scale of the primary y-axis from -1.3 to 1.3
ylim.sec_1 <- c(-2, 2) #Sets the scale of the secondary y-axis from -2 to 2

#Pre-transformation to display the differently scaled data in one plot
b_1 <- diff(ylim.prim_1) / diff(ylim.sec_1)
a_1 <- ylim.prim_1[1] - b_1 * ylim.sec_1[1]

#Creates the one graphic for the Cavendish banana commodity. There, we plot the theta coefficient, called "beta", on the primary and the normalized Cavendish banana price, called "bananaprice_z", on the secondary y-axis. Due to the different scales, the price needs to be adjusted with the pre-transformation values. The yearly observation period should occur on the x-axis. The rest of the procedure is the same principle as that described in the own created figure before
Figure_4_Cavendish <- ggplot(data = merged_data, aes(x = year)) +
  geom_line(aes(y = beta, color = "slope coefficient (θ)"), linetype = "solid", linewidth = 1.5) +
  geom_line(aes(y = a_1 + b_1 * bananaprice_z, color = "Cavendish price"), linetype = "dashed", linewidth = 1.5) +
  scale_y_continuous(name = "slope coefficient (θ)", sec.axis = sec_axis(~ (. - a_1) / b_1, name = "price (S.D.)")) +
  scale_color_manual(values = c("blue", "red")) +
  scale_x_continuous(breaks = seq(2000, 2010, by = 2), limits = c(2000, 2010)) +
  labs(x = "Year", title = "Cavendish Bananas") +
  theme_bw() +
  labs(color = NULL) +
  theme(
    plot.title = element_text(hjust = 0.5),
    panel.grid.major = element_line(color = "gray"),
    panel.grid.minor = element_blank(),
    axis.text = element_text(color = "black"),
    axis.ticks = element_line(color = "black"),
    plot.background = element_rect(fill = "white"),
    panel.background = element_rect(fill = "white"),
    legend.position = "bottom",
    legend.box.background = element_rect(color = "black"),
    legend.box.margin = margin(0.5, 0.5, 0.5, 0.5)
)

#Sugar plot: 
ylim.prim_2 <- c(-2, 2.5) #Sets the scale of the primary y-axis from -2 to 2.5
ylim.sec_2 <- c(-1.5, 2.5) #Sets the scale of the secondary y-axis from -1.5 to 2.5

#Pre-transformation to display the differently scaled data in one plot
b_2 <- diff(ylim.prim_2) / diff(ylim.sec_2)
a_2 <- ylim.prim_2[1] - b_2 * ylim.sec_2[1]

#Creates the one graphic for the sugar commodity. There, we plot the theta coefficient, called "betasugar", on the primary and the normalized sugar price, called "sugarprice_z", on the secondary y-axis. Due to the different scales, the price needs to be adjusted with the pre-transformation values. The yearly observation period should occur on the x-axis. The rest of the procedure is the same principle as that described in the own created figure before, except for one small adjustment of the "scale_color_manual()" argument, to correctly receive the right legend order for a consistent scheme over the entire figure
Figure_4_Sugar <- ggplot(data = merged_data, aes(x = year)) +
  geom_line(aes(y = betasugar, color = "slope coefficient (θ)"), linetype = "solid", linewidth = 1.5) +
  geom_line(aes(y = a_2 + b_2 * sugarprice_z, color = "sugar price"), linetype = "dashed", linewidth = 1.5) +
  scale_y_continuous(name = "slope coefficient (θ)", sec.axis = sec_axis(~ (. - a_2) / b_2, name = "price (S.D.)")) +
  scale_color_manual(values = c("blue", "red"), breaks = c("sugar price", "slope coefficient (θ)")) + #Defines the line colors for the sugar price and the slope coefficient theta. Besides that, the definition of the breaks argument is also mandatory to get the right legend order 
  scale_x_continuous(breaks = seq(2000, 2010, by = 2), limits = c(2000, 2010)) +
  labs(x = "Year", title = "Sugar") +
  theme_bw() +
  labs(color = NULL) +
  theme(
    plot.title = element_text(hjust = 0.5),
    panel.grid.major = element_line(color = "gray"),
    panel.grid.minor = element_blank(),
    axis.text = element_text(color = "black"),
    axis.ticks = element_line(color = "black"),
    plot.background = element_rect(fill = "white"),
    panel.background = element_rect(fill = "white"),
    legend.position = "bottom",
    legend.box.background = element_rect(color = "black"),
    legend.box.margin = margin(0.5, 0.5, 0.5, 0.5)
)

#Rice banana plot: 
ylim.prim_3 <- c(-1.7, 0.3) #Sets the scale of the primary y-axis from -1.7 to 0.3
ylim.sec_3 <- c(-1, 2.5) #Sets the scale of the secondary y-axis from -1 to 2.5

#Pre-transformation to display the differently scaled data in one plot
b_3 <- diff(ylim.prim_3) / diff(ylim.sec_3)
a_3 <- ylim.prim_3[1] - b_3 * ylim.sec_3[1]

#Creates the one graphic for the rice commodity. There, we plot the theta coefficient, called "betarice", on the primary and the normalized rice price, called "riceprice_z", on the secondary y-axis. Due to the different scales, the price needs to be adjusted with the pre-transformation values. The yearly observation period should occur on the x-axis. The rest of the procedure is the same principle as that described in the own created figure before
Figure_4_Rice <- ggplot(data = merged_data, aes(x = year)) +
  geom_line(aes(y = betarice, color = "slope coefficient (θ)"), linetype = "solid", linewidth = 1.5) +
  geom_line(aes(y = a_3 + b_3 * riceprice_z, color = "rice price"), linetype = "dashed", linewidth = 1.5) +
  scale_y_continuous(name = "slope coefficient (θ)", sec.axis = sec_axis(~ (. - a_3) / b_3, name = "price (S.D.)")) +
  scale_color_manual(values = c("blue", "red")) +
  scale_x_continuous(breaks = seq(2000, 2010, by = 2), limits = c(2000, 2010)) +
  labs(x = "Year", title = "Rice") +
  theme_bw() +
  labs(color = NULL) +
  theme(
    plot.title = element_text(hjust = 0.5),
    panel.grid.major = element_line(color = "gray"),
    panel.grid.minor = element_blank(),
    axis.text = element_text(color = "black"),
    axis.ticks = element_line(color = "black"),
    plot.background = element_rect(fill = "white"),
    panel.background = element_rect(fill = "white"),
    legend.position = "bottom",
    legend.box.background = element_rect(color = "black"),
    legend.box.margin = margin(0.5, 0.5, 0.5, 0.5)
)

#Lacatan banana plot: 
ylim.prim_4 <- c(-3, 3) #Sets the scale of the primary y-axis from -3 to 3
ylim.sec_4 <- c(-2.5, 2.5) #Sets the scale of the secondary y-axis from -2.5 to 2.5

#Pre-transformation to display the differently scaled data in one plot
b_4 <- diff(ylim.prim_4) / diff(ylim.sec_4)
a_4 <- ylim.prim_4[1] - b_4 * ylim.sec_4[1]

#Creates the one graphic for the domestically consumed Lacatan banana commodity. There, we plot the theta coefficient, called "betalacatan", on the primary and the normalized Lacatan banana price, called "lacatanprice_z", on the secondary y-axis. Due to the different scales, the price needs to be adjusted with the pre-transformation values. The yearly observation period should occur on the x-axis. The rest of the procedure is the same principle as that described in the own created figure before
Figure_4_Lacatan <- ggplot(data = merged_data, aes(x = year)) +
  geom_line(aes(y = betalacatan, color = "slope coefficient (θ)"), linetype = "solid", linewidth = 1.5) +
  geom_line(aes(y = a_4 + b_4 * lacatanprice_z, color = "Lacatan price"), linetype = "dashed", linewidth = 1.5) +
  scale_y_continuous(name = "slope coefficient (θ)", sec.axis = sec_axis(~ (. - a_4) / b_4, name = "price (S.D.)")) +
  scale_color_manual(values = c("blue", "red")) +
  scale_x_continuous(breaks = seq(2000, 2010, by = 2), limits = c(2000, 2010)) +
  labs(x = "Year", title = "Lacatan bananas") +
  theme_bw() +
  labs(color = NULL) +
  theme(
    plot.title = element_text(hjust = 0.5),
    panel.grid.major = element_line(color = "gray"),
    panel.grid.minor = element_blank(),
    axis.text = element_text(color = "black"),
    axis.ticks = element_line(color = "black"),
    plot.background = element_rect(fill = "white"),
    panel.background = element_rect(fill = "white"),
    legend.position = "bottom",
    legend.box.background = element_rect(color = "black"),
    legend.box.margin = margin(0.5, 0.5, 0.5, 0.5)
)

#Saba banana plot: 
ylim.prim_5 <- c(-0.5, 2.5) #Sets the scale of the primary y-axis from -0.5 to 2.5
ylim.sec_5 <- c(-1, 2) #Sets the scale of the secondary y-axis from -1 to 2

#Pre-transformation to display the differently scaled data in one plot
b_5 <- diff(ylim.prim_5) / diff(ylim.sec_5)
a_5 <- ylim.prim_5[1] - b_5 * ylim.sec_5[1]

#Creates the one graphic for the domestically consumed Saba banana commodity. There, we plot the theta coefficient, called "betasaba", on the primary and the normalized Saba banana price, called "sabaprice_z", on the secondary y-axis. Due to the different scales, the price needs to be adjusted with the pre-transformation values. The yearly observation period should occur on the x-axis. The rest of the procedure is the same principle as that described in the own created figure before
Figure_4_Saba <- ggplot(data = merged_data, aes(x = year)) +
  geom_line(aes(y = betasaba, color = "slope coefficient (θ)"), linetype = "solid", linewidth = 1.5) +
  geom_line(aes(y = a_5 + b_5 * sabaprice_z, color = "Saba price"), linetype = "dashed", linewidth = 1.5) +
  scale_y_continuous(name = "slope coefficient (θ)", sec.axis = sec_axis(~ (. - a_5) / b_5, name = "price (S.D.)")) +
  scale_color_manual(values = c("blue", "red")) +
  scale_x_continuous(breaks = seq(2000, 2010, by = 2), limits = c(2000, 2010)) +
  labs(x = "Year", title = "Saba bananas") +
  theme_bw() +
  labs(color = NULL) +
  theme(
    plot.title = element_text(hjust = 0.5),
    panel.grid.major = element_line(color = "gray"),
    panel.grid.minor = element_blank(),
    axis.text = element_text(color = "black"),
    axis.ticks = element_line(color = "black"),
    plot.background = element_rect(fill = "white"),
    panel.background = element_rect(fill = "white"),
    legend.position = "bottom",
    legend.box.background = element_rect(color = "black"),
    legend.box.margin = margin(0.5, 0.5, 0.5, 0.5)
)

#We want to illustrate our five created plots in one figure. We do so with the "ggarrange()" function and specify the number of columns and rows for the final graphical representation
Figure_4 <- ggarrange(Figure_4_Cavendish, Figure_4_Sugar, Figure_4_Rice, Figure_4_Lacatan, Figure_4_Saba, ncol = 2, nrow = 3)

Figure_4

```


Quiz: Based on the graphical analysis presented in this figure, how do these results compare with the tabular findings reported in Table 10?

(1) The results are consistent with the findings of Table 10
(2) The results are inconsistent with the findings of Table 10

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("Commodity Hypothesis Figure 4")
```

<br/>

In conclusion, this chapter has explored various potential explanations for the empirical patterns that we have identified for the occurrence of civil conflict. Crost and Felter (2020, p. 1509) conclude that the **indirect predation and opportunity cost mechanism provide the most plausible clarification for our findings**. Cavendish banana exporters are subject to *extortion by insurgent organizations, especially the investigated NPA, who use the acquired financial resources to enhance their regional supremacy by acquiring more weapons, military hardware, and actively recruiting more troops*. The analyses revealed that the escalation of insurgent strength is especially pronounced in regions where the control of an armed organization was *already considerable*. This is because the insurgents can effortlessly extract a sizable share of the surplus from the agricultural estates with minimal obstruction from the state forces. This would *reduce the occurrence of violent disputes, aligning it with the principles of the CSF framework* that was previously explained in Exercise 1.2. As we saw varying signs from a positive to a negative impact of commodity values on violent incidents across increasing initial levels of NPA insurgent strength in Table 8 and 10, the occurrence is hard to account by either the indirect predation or the opportunity cost mechanism in isolation. This arises the possibility of an *alternative mechanism which underlines the findings and cannot be dismissed*.

Crost and Felter (2020, p. 1509f.) provide another clarification, who argue that the *market dominance of farm holders in domestic labor markets is enhanced by the banana sector centralization*. Therefore, this could reduce the elasticity of labor compensation concerning variations in commodity prices. The **opportunity costs of armed incidents would then be less affected by a rise in the global banana market price than by a rise in commodity prices in which the employment distribution is more diverted**. This could potentially result in a substantial reduction in violent disputes.

<br/>

In addition, Crost and Felter (2020, p. 1511) elaborate on the *discovered lack of empirical support for the value growth of our non-export goods rice, Lacatan, and Saba banana, by invoking the concepts of opportunity cost and indirect predation*. The **transaction costs of blackmailing money from the numerous and dispersed small farmers and retailers**, which are primary agents in the cultivation and distribution of these plants, probably **exceed the possible extractable profit of extortion**.


Quiz: Given this premise, what are the implications of observing high transaction costs?

(1) Elevated transaction costs may increase the number of blackmail attempts
(2) Elevated transaction costs may decrease the number of blackmail attempts

```{r eval=FALSE}
# Run line to answer the quiz above
answer.quiz("Transaction Costs of Blackmailing")
```


<br/>

## Exercise 7 -- Conclusion

This Problem Set enabled us to obtain vulnerable information regarding the Philippine economic condition, the lucrative banana crop, and the challenges associated with this agricultural product in relation to armed insurgent groups and their potential for conflict. Therefore, we investigated the effect of the **global market price on provincial conflict and assessed the role of initial rebel strength on violence**. In addition, we proposed some **plausible mechanisms that attempt the explanation for the observed results**. We have achieved this by exploring the statistical analysis language **R** and its applications from the beginning!

**Task 61:** This task is a preparation for the final one. Over the entire process of this Problem Set, *you have gained some awards*. At maximum, you could have earned **11 trophies**. Please display your trophy cabinet with the `awards()` function.

```{r "17_1"}
#Use the right function to display your achieved awards
```

**Task 62:** You have reached the final task. **Now you can form the word that is made of the letters that you earned as a reward for the exercises. Review the awards in the chunk above if necessary!** Fill in the solution word in *CAPITALS*.

```{r "17_2"}
#Fill in the solution word in capital letters. The solution context, in which the solution word should fit in, is below
SOLUTION_WORD <- c("___")

display("YOU WORKED YOUR WAY THROUGH THE ENTIRE PROBLEM SET AND SUCCESSFULLY MASTERED ALL THE TASKS AND OBJECTIVES! YOU ARE THE CURRENT", SOLUTION_WORD, "OF THIS PROBLEM SET!", sep = " ")

```

**CONGRATULATIONS!** 

As an ultimate step, we will summarize the main results of our analyses and draw a conclusion:

Described by Crost and Felter (2020, p. 1511), the *prevalent belief that conflict can be mitigated by the cultivation of high-value export crops*, which generates jobs, opportunities for legal income sources and increase the opportunity costs of participating in violent organizations, is common in politics and the economic literature. Hence, the cultivation of these lucrative commodities is a major priority for many countries that suffer from instability and violence. Therefore, our analyses aimed to examine *how the variation in the value of crops for export and domestic consumption influence the frequency of violent events in the Philippines*. However, based on data from the Philippines from 2001 to 2009, our **findings are not entirely consistent with the hypothesis of economic literature**. Regarding our analytical findings, both the **crop species and the environmental as well as social circumstances in a province**, have a considerable influence on the outcome of the relationship between variations in crop values and armed disputes. On the one hand, we are **unable to find empirical support** from our analyses regarding a positive relationship between the variation in rice, Saba, or Lacatan banana values and provincial violence. These usually in minor landholdings cultivated goods, *do not influence the frequency of violent disputes!* On the other hand, our analyses reveal a **positive and significant association between the escalation of provincial armed disputes and the rise of Cavendish banana and sugar values**, which are the main commodities of the Philippine export sector. Furthermore, the analyses showed that the regions with *weak initial rebel presence are in the primary focus of the escalation of conflict*. This is due to the occurring predation effect of the rebels, who seek to establish their dominance over the territory. As the CSF outlined, our analyses revealed that a **decline in the number of violent incidents was only observed in regions where rebel organizations, especially the NPA, had an elevated level of initial territorial control**, as the government lack the military resources to regain authority. Lastly, we have demonstrated that the opportunity cost mechanism played a crucial role in determining the impact of increasing Cavendish banana value. Specifically, we found that *regions with large-scale banana farms experienced the highest escalation of violence!*

<br/>

The relevance of the debate on the effectiveness of high-value crop exports as a means of restoring stability and economic growth, or as a potential source of support for rebel groups in developing countries, is irrelevant. Both positive and negative outcomes are associated with this strategy.

<br/>

Crost and Felter (2020, p. 1512) argue that a comprehensive understanding of the effects of economic situations on conflict momentum requires *expanding the scope of the analyses with other indicators, not just violence alone*. The impact of rising crop values on increasing armed disputes can be justified by predation and the opportunity cost mechanism. However, the relative strength of each mechanism varies according to the *provincial circumstances*. This fact poses a challenge to effectively differentiate them just using violence information. Nonetheless, the regression findings indicate that in some scenarios, including for agricultural products that require extensive work input, the predation effect may dominate the opportunity cost effect. To address the question of which several aspects of the organization of violent disputes and the agricultural crop cultivation network, shape the impact of crop values on armed incidents, can therefore be **explored by forthcoming studies**. In conclusion, the findings of this study indicate that when **devising and executing agricultural government interventions in nations facing fragmentation, economic downtime, or social disturbances, it is crucial to consider the unique contextual elements that impact their efficiency, the long-term viability, and the potential drawbacks**. These potentionally unintentional side effects of intensifying export-oriented agriculture, such as *increasing extortion attempts, empowering rebel factions, and the lack of governmental power to challenge the insurgent provincial dominance*, need to be carefully reconsidered with the addition of empirical analyses, when adjusting national guidelines!

<br/>

## Exercise Bibliography

## References:

* Abadie, A., Athey, S., Imbens, G., Wooldridge, J., (2017): *When should you adjust standard errors for clustering?* NBER Working Paper 24003, National Bureau of Economic Research, page 3-4.

* Amgalan, A., Parodi-Mujica, LR., Skiena, S., (2022): *Fast spatial autocorrelation.* Knowledge and Information Systems, 64(4), page 920.

* Bayer Global (2023): *What is a banana?*, accessed 15 April 2024, https://www.bayer.com/en/agriculture/article/history-modern-banana

* Berman, E., Felter, J., Kapstein, E., Troland, E. (2012): *Predation, economic activity and violence: Evidence from the Philippines.* NBER Working Paper 18375, National Bureau of Economic Research, page 1-2.

* Collischon, M., Eberl, A. (2020): *Let’s Talk About Fixed Effects: Let’s Talk About All the Good Things and the Bad Things.* KZfSS Kölner Zeitschrift für Soziologie und Sozialpsychologie, 72(2), page 291-292.

* Conley, T. (2010): *Spatial Econometrics.* Microeconometrics, Chapter 33, London: Palgrave Macmillan, page 303.

* Crost, B., Felter, J. (2020): *Export Crops and Civil Conflict.* Journal of the European Economic Association, 18(3), page 1484-1520.

* DevelopmentAid (2023): *Top 10 biggest banana-producing countries in the world*, accessed 15 April 2024, https://www.developmentaid.org/news-stream/post/165656/top-10-banana-producing-countries

* Federal Reserve Bank of St. Louis (2024): *Global Price of Bananas*, accessed 15 April 2024, https://fred.stlouisfed.org/series/PBANSOPUSDM

* Food and Agriculture Organization of the United Nations (2022): *FAOSTAT Analytical Brief 44: Trade of agricultural commodities 2000-2020*, page 5-6.

* Food and Agriculture Organization of the United Nations (2023): *Banana Market Review 2022*, page 1-2.

* Fredriksson, A., Magalhães de Oliveira, G. (2019): *Impact evaluation using Difference-in-Differences.* RAUSP Management Journal, 54(4), page 519-523.

* Greene, W. H. (2012): *Econometric Analysis.* Seventh Edition - International Edition, Harlow: Pearson Education Limited, page 259.

* Institute for Economics & Peace (2020): *Global Terrorism Index 2020: Measuring the Impact of Terrorism*, page 8-29.

* Kranz, S. (2021): *Visually assessing the Parallel Trends Assumption for the DiD estimation with Control Variables.* Economics and R Blog from Sebastian Kranz of the Ulm University, accessed 15 April 2024, https://skranz.github.io/r/2021/10/20/ParallelTrendsPlot.html

* Miguel, E. (2007): *Poverty and Violence: An Overview of Recent Research and Implications for Foreign Aid.* Too Poor for Peace?: Global Poverty, Conflict, and Security in the 21st Century, page 51-52.

* OEC Bananas in Philippines (2022): *Bananas in Philippines*, accessed 15 April 2024, https://oec.world/en/profile/bilateral-product/bananas/reporter/phl

* OEC Philippines (2022): *Philippines*, accessed 15 April 2024, https://oec.world/en/profile/country/phl

* Pokropek, A. (2016): *Introduction to instrumental variables and their application to large‑scale assessment data.* Large-scale Assess Education 4:4, page 3-5.

* Skaperdas, S. (1996): *Contest success functions.* Economic Theory, 7(2), page 283-290.

* Stanford University (2022): *Abu Sayyaf Group*, accessed 15 April 2024, https://cisac.fsi.stanford.edu/mappingmilitants/profiles/abu-sayyaf-group#text_block_11914

* The World Bank (2024): *Philippines – Overview*, accessed 15 April 2024, https://data.worldbank.org/?locations=PH

* The World Factbook (2024): *Explore All Countries – Philippines*, accessed 15 April 2024, https://www.cia.gov/the-world-factbook/countries/philippines/

* The World Factbook (2024): *References – Terrorist Organizations*, accessed 15 April 2024, https://www.cia.gov/the-world-factbook/references/terrorist-organizations/

* University of Edinburgh - Peace Agreements Database (2023): *The Comprehensive Agreement on the Bangsamoro*, accessed 15 April 2024, https://www.peaceagreements.org/view/881

* Weinberger, K., Lumpkin, T. (2005): *Horticulture for Poverty Alleviation: The Unfunded Revolution.* AVRDC Publication 05-613, Working Paper No. 15, Asian Vegetable Research and Development Center, page 1-2.

* World Bank Group (2023): *Poverty & Equity Brief East Asia & Pacific: Philippines April 2023*, page 1-2.

<br/>

## R Packages:

* Arel-Bundock, V. (2024): *modelsummary: Summary Tables and Plots for Statistical Models and Data: Beautiful, Customizable, and Publication-Ready.* R Package version 1.4.2, accessed 15 April 2024, https://cran.r-project.org/web/packages/modelsummary/index.html

* Berge, L. (2023): *fixest: Fast Fixed-Effects Estimations.* R Package version 0.11.1, accessed 15 April 2024, https://cran.r-project.org/web/packages/fixest/index.html

* Düben, C. (2022): *conleyreg: Estimations using Conley Standard Errors.* R Package version 0.1.7, accessed 15 April 2024, https://cran.r-project.org/web/packages/conleyreg/index.html

* Kassambara, A. (2023): *ggpubr: 'ggplot2' Based Publication Ready Plots.* R Package version 0.6.0, accessed 15 April 2024, https://cran.r-project.org/web/packages/ggpubr/index.html

* Kranz, S. (2020): *RTutor: Interactive R problem sets with automatic testing of solutions and automatic hints.* R Package version 2020.11.25.

* R (2024): *The R Project for Statistical Computing.* R Base Package version 4.3.1, accessed 15 April 2024, https://www.r-project.org/

* R Core Team (2023): *foreign: Read Data Stored by 'Minitab', 'S', 'SAS', 'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ....* R Package version 0.8-86, accessed 15 April 2024, https://cran.r-project.org/web/packages/foreign/index.html

* Wickham, H. (2023): *dplyr: A Grammar of Data Manipulation.* R Package version 1.1.3, accessed 15 April 2024, https://cran.r-project.org/web/packages/dplyr/index.html

* Wickham, H. (2023): *ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics.* R Package version 3.4.4, accessed 15 April 2024, https://cran.r-project.org/web/packages/ggplot2/index.html

* Wickham, H. (2023): *haven: Import and Export 'SPSS', 'Stata' and 'SAS' Files.* R Package version 2.5.3, accessed 15 April 2024, https://cran.r-project.org/web/packages/haven/index.html

* Wickham, H. (2024): *tidyr: Tidy Messy Data*. R Package version 1.3.0, accessed 15 April 2024, https://cran.r-project.org/web/packages/tidyr/index.html

* Zhu, H. (2024): *kableExtra: Construct Complex Table with 'kable' and Pipe Syntax.* R Package version 1.3.4.9000, accessed 15 April 2024, https://cran.r-project.org/web/packages/kableExtra/index.html

<br/>

## Exercise List of illustrations 

The subsequent catalog denotes illustrations that have been used independently from the R generated graphics:

* FIGURE 1: **Value of global fruit and vegetables exports by commodity**, Food and Agriculture Organization of the United Nations (2022): *FAOSTAT Analytical Brief 44: Trade of agricultural commodities 2000-2020*, page 6.

* FIGURE 2: **Production volume of bananas worldwide from 2010 to 2022 (in million metric tons)**, Statista (2024) (1), accessed 15 April 2024, https://www.statista.com/statistics/716037/global-banana-market-volume/#:~:text=In%202021%2C%20the%20volume%20of,been%20generally%20increasing%20since%202010

* FIGURE 3: **Leading producers of bananas worldwide in 2022 by country (in thousand metric tons)**, Statista (2024) (2), accessed 15 April 2024, https://www.statista.com/statistics/811243/leading-banana-producing-countries/

* FIGURE 4: **Global trade of main fruit and vegetables, main importers and exporters (2020)**, Food and Agriculture Organization of the United Nations (2022): *FAOSTAT Analytical Brief 44: Trade of agricultural commodities 2000-2020*, page 6.

* FIGURE 5: **Geographical position of the Philippines**, Own Illustration based on The World Factbook (2024): *Philippines – Details*, accessed 15 April 2024, https://www.cia.gov/the-world-factbook/countries/philippines/locator-map and Wikipedia (2024), accessed 15 April 2024, https://upload.wikimedia.org/wikipedia/commons/f/f6/Labelled_map_of_the_Philippines_-_Provinces_and_Regions.png

* FIGURE 6: **Philippines: Distribution of employment by economic sector from 2011 to 2021**, Statista (2024) (3), accessed 15 April 2024, https://www.statista.com/statistics/578788/employment-by-economic-sector-in-philippines/#:~:text=Employment%20by%20economic%20sector%20in%20the%20Philippines%202021&text=In%202021%2C%2024.27%20percent%20of,percent%20in%20the%20services%20sector

* FIGURE 7: **Share of families with income less than poverty ceiling in the Philippines in 2021, by region**, Statista (2024) (4), accessed 15 April 2024, https://www.statista.com/statistics/1321332/philippines-poverty-incidence-of-families-by-region/

* FIGURE 8: **Mean banana production by province during 2001 to 2009**, Crost, B., Felter, J. (2020): *Export Crops and Civil Conflict.* Journal of the European Economic Association, 18(3), page 1503.

* FIGURE 9: **Terrorism impact of the Philippines**, Institute for Economics & Peace (2020): *Global Terrorism Index 2020: Measuring the Impact of Terrorism*, page 28.

* FIGURE 10: **Predictions from the Contest-Success-Function**, Crost, B., Felter, J. (2020): *Export Crops and Civil Conflict.* Journal of the European Economic Association, 18(3), page 1495.

* FIGURE 11: **Visualization of two-group DiD Approach**, Own illustration based on Fredriksson, A., Magalhães de Oliveira, G. (2019): *Impact evaluation using Difference-in-Differences.* RAUSP Management Journal, 54(4), page 522.

* FIGURE 12: **Examples of situations where Z is valid and invalid**, Pokropek, A. (2016): *Introduction to instrumental variables and their application to large‑scale assessment data*. Large-scale Assess Education 4:4, page 5.

<br/>

## Exercise Appendix 

The subsequent Appendix section is *divided into dual segments*. *Part one* outlines a **robustness verification of the results derived from our analyses**, addressing a potential concern as indicated by the authors. The *second part* of this disclosure will illustrate the **derivation of the graphically employed data frames** `df_figure_rep.dta` and `merged_data.dta` from the foundation data set `replication_data.dta`, as already been indicated in certain tasks of this Problem Set.

<br/>

## A1: Robustness Verification

We begin with an **examination of the robustness check**. Crost and Felter (2020, p. 1512) acknowledge that *prior to the year 2002*, the Philippines Department of Agriculture *did not supply decomposed banana manufacturing data by species*, which could be a potential threat to the conducted analyses. Consequently, the utilization of Cavendish banana cultivation prior to the beginning of the monitoring interval in 2001 as an indicator of agricultural intensity in the empirical analyses, is unfeasible. Therefore, the **issue of reverse causality** also presents itself as a matter for consideration. This may be attributable to the potentiality that *during the preceding years of 2001 and 2002*, fluctuations in pricing structures or resulting national violent disputes occurred, that *may have influenced the quantification of Cavendish banana cultivation in 2002*. To mitigate this issue, the authors reanalyze Table 2 through 10, which were initially examined in this Problem Set, **but within a condensed observational time frame spanning from 2003 to 2009!**

In R, the modification of the data set for the correct annual time frame can be achieved similarly to the creation of the `data_table` data set before. Following adjustment needs to be made:

```{r eval=FALSE}
# Run for additional info in the Viewer pane
info("Adjustment of the correct time frame for the appendix data set")
```

Upon juxtaposing the outcomes of the *preliminary empirical investigations*, that we have studied, with those *derived from the condensed temporal analyses*, it is recognized by the authors that the **findings exhibit a high degree of similarity!** This implies that it is **unlikely that the issue of reverse causality had an influence on the outcomes of the initial conducted analyses**, see Crost and Felter (2020, p. 1512-1516) in their Appendix section for more details. 

<br/>

## A2: Derivation of the Data Frames for the Graphical Representations

Now, the following chunks *illustrate the derivation of the graphically employed data frames* `df_figure_rep.dta` and `merged_data.dta` from the foundation data set `replication_data.dta` step by step. **Additional information about what have been done and why it is done can be reviewed in the comment section of the blocks and above them!** Your can verify the steps of the data preparation process by examining the code segments. *You are not required to produce any original writing or complete any missing parts!* You only need to ensure that the code segments accurately reflect the data preparation process by clicking on the `check` buttons!

<br/>

At first, it is necessary to load the needed packages for the data preparation process and read in the central data frame `replication_data.dta` which is the base of everything:

```{r "20_2",eval=FALSE}

library("haven") #Load the necessary package for the data read in
library("dplyr") #Load the necessary package for the Pipe Operator
library("fixest") #Load the necessary package for the Regression
library("tidyr") #Load the necessary package for the "pivot_longer()" function

#Assign the central data set "replication_data.dta" to the variable "data"

data <- read_dta("replication_data.dta") 

```

The next step is to create a specific variable for the `years` and a set of empty lists for the following `For-Loop`:

```{r "20_3",eval=FALSE}

#Creation of the variable "years" as integer values, which is necessary for the For-Loop

years <- 2001:2009 

#Creation of six new empty lists, which will be replenished and added as columns to the central data set, after the For-Loop

new_column_1 <- list()
new_column_2 <- list()
new_column_3 <- list()
new_column_4 <- list()
new_column_5 <- list()
new_column_6 <- list()

```

Afterwards, we make use of a `For-Loop` to replenish the generated lists. This performs the following: 

The `For-Loop` should go from 1 to the end of the variable `years`, so from 1 to 9. This can be done by pointing at the `length` of the `years` variable. 

We save the entry of iteration i in `years` as a temporary variable called `temp`. The entries i are therefore 2001 to 2009.

After that, in the first part of the loop, we create the new names of the new columns. The column names should contain the terms `year`, `yearint`, `yearintsugar`, `yearintrice`, `yearintlacatan`, and `yearintsaba` in connection with the temporary variable `temp`. For example, in the first iteration of the `For-Loop` we create the new column names: `year2001`, `yearint2001`, `yearintsugar2001`, `yearintrice2001`, `yearintlacatan2001`, and `yearintsaba2001`. 

Then we move on to the second part of the loop. Since we now generated the column names, we need to fill the created empty lists with values. To do so, we need an `ifelse()` condition. Per iteration step of the `For-Loop`, we check, if the `year` of that specific entry in the central data frame `data` is equal to the temporal variable `temp`, which contains the years from 2001 to 2009 as mentioned before. If this is not the case, we add the value 0 for this row in the specific new list. If the condition is met, we add the value 1 or the entry in the column `cavendish_z`, `sugar_z`, `rice_z`, `lacatan_z`, or `saba_z` of the central data frame, for this row in the specific new list. Furthermore, we assign the new column names to the lists.

```{r "20_4",eval=FALSE}

for (i in 1:length(years)) { 
  temp <- years[i] 
  
  new_column_name_1 <- paste0("year", temp) 
  new_column_name_2 <- paste0("yearint", temp)
  new_column_name_3 <- paste0("yearintsugar", temp)
  new_column_name_4 <- paste0("yearintrice", temp)
  new_column_name_5 <- paste0("yearintlacatan", temp)
  new_column_name_6 <- paste0("yearintsaba", temp)
  
  
  new_column_1[[new_column_name_1]] <- ifelse(data$year == temp, 1, 0)
  new_column_2[[new_column_name_2]] <- ifelse(data$year == temp, 1 * data$cavendish_z, 0)
  new_column_3[[new_column_name_3]] <- ifelse(data$year == temp, 1 * data$sugar_z, 0) 
  new_column_4[[new_column_name_4]] <- ifelse(data$year == temp, 1 * data$rice_z, 0)
  new_column_5[[new_column_name_5]] <- ifelse(data$year == temp, 1 * data$lacatan_z, 0) 
  new_column_6[[new_column_name_6]] <- ifelse(data$year == temp, 1 * data$saba_z, 0)
  
}

```

Since we now created the new columns, we need to add them to our central data frame `data`. Furthermore, we need to adjust the data set according to the given time span, that no yearly NA values occur:

```{r "20_5",eval=FALSE}

#Since we now created the new columns, we need to add them to our central data frame. To do so we use the function "cbind()" and create the new data set "data_figures_1"

data_figures_1 <- cbind(data, new_column_1, new_column_2, new_column_3, new_column_4, new_column_5, new_column_6)

#The data set should only contain the years from 2001 to 2009 and no yearly NA values

data_figures_2 <- data_figures_1 %>%
  filter(., year >= 2001 & year <= 2009) 

```

We are left with the data set `data_figures_2`, which contain 691 observations for 116 variables. 

Our primary objective is to compute the described ${\theta}_{j}$ coefficients for the commodities, which enables us to record the gradient of the association of annual armed disputes and the regional power of plant cultivation. We exclude the year 2005 from the analysis and thus ${\theta}_{j}$ represents the slope in year j compared to the gradient of the omitted year 2005.

To compute the ${\theta}_{j}$ coefficients and the variances for the graphical representation, we firstly need to run a linear regression. We do so with the `feols()` function. `vinc` is the dependent variable as the number of provincial violent incidents. Independent variables are all newly created variables, except the ones including the year 2005. Additionally, `zrain`, `wetrain`, `temperature`, `wettemp`, and `typhoon` are included as Control Variables. `pcode` is the only FE variable. The data on which the regression is based on is `data_figures_2`. The observations are weighted with the province population in 2000 (`pop2000`). Furthermore, standard errors are clustered at provincial level with the `pcode` variable. We save the regression results in the variable `figures_reg`:

```{r "20_6",eval=FALSE}

figures_reg <- feols(vinc ~ yearint2001 + yearint2002 + yearint2003 + yearint2004 + yearint2006 + yearint2007 + yearint2008 + yearint2009 + yearintsugar2001 + yearintsugar2002 + yearintsugar2003 + yearintsugar2004 + yearintsugar2006 + yearintsugar2007 + yearintsugar2008 + yearintsugar2009 + yearintrice2001 + yearintrice2002 + yearintrice2003 + yearintrice2004 + yearintrice2006 + yearintrice2007 + yearintrice2008 + yearintrice2009 + yearintlacatan2001 + yearintlacatan2002 + yearintlacatan2003 + yearintlacatan2004 + yearintlacatan2006 + yearintlacatan2007 + yearintlacatan2008 + yearintlacatan2009 + yearintsaba2001 + yearintsaba2002 + yearintsaba2003 + yearintsaba2004 + yearintsaba2006 + yearintsaba2007 + yearintsaba2008 + yearintsaba2009 + year2001 + year2002 + year2003 + year2004 + year2006 + year2007 + year2008 + year2009 + zrain + wetrain + temperature + wettemp + typhoon | pcode, data = data_figures_2, weights =  data_figures_2$pop2000, cluster = data_figures_2$pcode)

```

We need the regression coefficients and the variance-covariance-matrix from `figures_reg`. This can be achieved with the `coefficients()` and `vcov()` functions:

```{r "20_7",eval=FALSE}

#With the "coefficients()" function, we get the necessary regression coefficients theta and save them in the variable "b"

b <- coefficients(figures_reg) 

#With the "vcov()" function, we get the necessary variance-covariance-matrix from the regression and save them in the variable "V". It is a 53x53 symmetric matrix with the variances on the diagonal and the covariances above and below

V <- vcov(figures_reg)

```

The next 10 `For-Loops` are all similar to each other. The goal is to create new columns for the `data_figures_2` data frame to graphically illustrate ${\theta}_{j}$, called `beta` in the code chunks, and the variances later. We create the new columns `beta'i'`, `variance'i'`, `betasugar'i'`, `variancesugar'i'`, `betarice'i'`, `variancerice'i'`, `betalacatan'i'`, `variancelacatan'i'`, `betasaba'i'`, and `variancesaba'i'`. The i in the name corresponds to the specific iteration step in the `For-Loops`. The steps are from 1 to 4 and from 6 to 9, because we effectively exclude the year 2005, so there is no need for the 5. We fill in these columns with the appropriate coefficient from the `b` vector and the appropriate value from the variance-covariance-matrix `V`. To get a better visual idea, for example, after the `For-Loops` we get a new column `beta3` in the `data_figures_2` data frame, which consists of the third entry in `b` (b[3] = -1.056463) for all rows in that new column:

```{r "20_8",eval=FALSE}

for (i in 1:4) {
  data_figures_2[paste("beta", i, sep = "")] <- b[i]
  data_figures_2[paste("variance", i, sep = "")] <- V[i, i]
}

for (i in 6:9) {
  data_figures_2[paste("beta", i, sep = "")] <- b[i-1]
  data_figures_2[paste("variance", i, sep = "")] <- V[i-1, i-1]
}

for (i in 1:4) {
  data_figures_2[paste("betasugar", i, sep = "")] <- b[i+8]
  data_figures_2[paste("variancesugar", i, sep = "")] <- V[i+8, i+8]
}

for (i in 6:9) {
  data_figures_2[paste("betasugar", i, sep = "")] <- b[i+7]
  data_figures_2[paste("variancesugar", i, sep = "")] <- V[i+7, i+7]
}

for (i in 1:4) {
  data_figures_2[paste("betarice", i, sep = "")] <- b[i+16]
  data_figures_2[paste("variancerice", i, sep = "")] <- V[i+16, i+16]
}

for (i in 6:9) {
  data_figures_2[paste("betarice", i, sep = "")] <- b[i+15]
  data_figures_2[paste("variancerice", i, sep = "")] <- V[i+15, i+15]
}

for (i in 1:4) {
  data_figures_2[paste("betalacatan", i, sep = "")] <- b[i+24]
  data_figures_2[paste("variancelacatan", i, sep = "")] <- V[i+24, i+24]
}

for (i in 6:9) {
  data_figures_2[paste("betalacatan", i, sep = "")] <- b[i+23]
  data_figures_2[paste("variancelacatan", i, sep = "")] <- V[i+23, i+23]
}

for (i in 1:4) {
  data_figures_2[paste("betasaba", i, sep = "")] <- b[i+32]
  data_figures_2[paste("variancesaba", i, sep = "")] <- V[i+32, i+32]
}

for (i in 6:9) {
  data_figures_2[paste("betasaba", i, sep = "")] <- b[i+31]
  data_figures_2[paste("variancesaba", i, sep = "")] <- V[i+31, i+31]
}

```

We are left with the data set `data_figures_2`, which contains of 691 observations for 196 variables. **That is too much!** We need to aggregate it such that we have just one observation for our necessary variables / columns `beta` and `variance`. To do so, the `summarise_at()` function is used to summarize the entries for the columns, which start with `beta` or `variance`. We take the mean for our summarize measure. Since we excluded the year 2005 and the 5 in the `For-Loops`, we create the new columns `beta5` and `variance5` with values of zero. We do this, because the ${\theta}_{j}$ coefficient represents the slope in year j compared to the gradient of the omitted year 2005, which is equal to a slope coefficient in year 2005 of zero. We later need an identifier in this data frame, therefore we also create a new column `one` just with entries of 1. We add them to the data set via the `mutate()` function:

```{r "20_9",eval=FALSE}

data_figures_aggregated <- data_figures_2 %>%
  summarise_at(vars(starts_with("beta") | starts_with("variance")), mean) %>% 
  mutate(., one = 1, beta5 = 0, variance5 = 0) 

```

Now the `data_figures_aggregated` data set is much more compact than before. We have one observation, with the mean value, for every column that starts with `beta` or `variance`. That are 83 columns in total with the manually added columns.

Unfortunately, now we have a hole in our sequence. For example, we have the columns `betasugar` 1 to 4 and 6 to 9. So `betasugar5` is still missing. This also applies to the other crops for the `betas` and the `variances`. With this `For-Loop`, the missing columns are added to the `data_figures_aggregated` data frame, with zero values each:

```{r "20_10",eval=FALSE}

for (i in c("sugar", "rice", "lacatan", "saba")) {
  data_figures_aggregated[paste("beta", i, "5", sep = "")] <- 0
  data_figures_aggregated[paste("variance", i, "5", sep = "")] <- 0
}

```

We have now created the new data set `data_figures_aggregated` with one observation for all 91 necessary variables, great!

Since we obtain that the newly created data frame `data_figures_aggregated` is in a wider format, we need to transform it into a longer format with the `pivot_longer()` function. This function converts all columns into two variables starting with either `beta` or `variance` with its `cols` argument. Moreover, the variable `one` is the identifier and the variable `year` the sub-identifier for each observation. The `names_pattern` argument specifies how the column names should be split into multiple variables. First variable should contain one or more word character, second should contain one or more digits. We save the longer format in the variable `diffgraphdata`:

```{r "20_11",eval=FALSE}

diffgraphdata <- pivot_longer(data_figures_aggregated, 
                       cols = starts_with(c("beta", "variance")), 
                       names_to = c(".value", "year"), 
                       names_pattern = "(\\w+)(\\d+)")

```

To get a better idea of how the transformation went, we look for example at the `beta` column. We now have just one column `beta` instead of `beta1`, `beta2`, `beta3`, `beta4`, `beta5`, and so on. For example, the entry for `beta3` from the data frame before the longer transformation, is now in the row with `year = 3` and the column `beta`. The following `head()` function provides a small snapshot of the `diffgraphdata` data frame: 

```{r "20_12",eval=FALSE}

head(diffgraphdata)

```

Some specifications and additional columns are still missing, that is why we compute the following modifications and save the modified data frame in `diffgraphdata_spec`: 

```{r "20_13",eval=FALSE}

#Assigns the data frame "diffgraphdata" to the data frame "diffgraphdata_spec". It is a copy, because issues could occur if we overwrite "diffgraphdata" several times again.

diffgraphdata_spec <- diffgraphdata

#We add 2000 to the column "year" such that we now have real years again

diffgraphdata_spec$year <- as.numeric(diffgraphdata$year) + 2000 

#Moreover, still missing are the values for the 95% confidence interval for the theta coefficients of each commodity. That is why we firstly need values for the standard deviations. At first, we compute it for the Cavendish banana commodity as the square root of the variance value and add it as the column "se"

diffgraphdata_spec$se <- sqrt(diffgraphdata$variance) 

```

We need to compute the bounds of the 95% confidence interval for the `beta` column (Cavendish banana variety), which reflects the ${\theta}_{j}$ coefficient, and add both bounds to our data frame. `cihigh` is the upper bound of the 95% confidence interval which is calculated as `(beta value + 1.96 * standard deviation value)`. `cilow` is the lower bound of the 95% confidence interval which is calculated as `(beta value - 1.96 * standard deviation value)`:

```{r "20_14",eval=FALSE}

diffgraphdata_spec <- diffgraphdata_spec %>%
  mutate(., cihigh = .$beta + 1.96 * .$se, 
            cilow = .$beta - 1.96 * .$se)

```

Moreover, we need the 95% confidence interval for the rest of our commodities, not just for the ${\theta}_{j}$ coefficient and variance of the Cavendish banana variety. With the next `For-Loop` we do the same as previously described with the `beta` column. We calculate the standard error, the upper and lower bound of the 95% confidence interval for all other crops. For example, for the rice commodity, we first calculate the standard deviation of the column `variancerice` and save it in the new column `se_rice`. Afterwards, we use these values and the column `betarice` to calculate the upper and lower bounds of the 95% confidence interval. We save the bound values in the columns `cihigh_rice` and `cilow_rice`:

```{r "20_15",eval=FALSE}

for (i in c("sugar", "rice", "lacatan", "saba")) {
  diffgraphdata_spec[paste0("se_", i)] <- sqrt(diffgraphdata_spec[paste0("variance", i)])
  
  diffgraphdata_spec[paste0("cihigh_", i)] <- diffgraphdata_spec[paste0("beta", i)] + 1.96 * diffgraphdata_spec[paste0("se_", i)]
  
  diffgraphdata_spec[paste0("cilow_", i)] <- diffgraphdata_spec[paste0("beta", i)] - 1.96 * diffgraphdata_spec[paste0("se_", i)]
}

```

Finally, we sort the data frame by `year` and save it in the final data frame `diffgraphdata_final` as the first part of the data preparation process. We obtain nine rows of observation, which reflect the yearly time span of 2001 to 2009, for 27 variables about the ${\theta}_{j}$ coefficients, the variances, and the confidence interval for the different crop varieties:

```{r "20_16",eval=FALSE}

diffgraphdata_final <- arrange(diffgraphdata_spec, year) 

head(diffgraphdata_final)

```

<br/>

*The first part of the data preparation is done, great!*

The created data set `diffgraphdata_final` **is one necessary constituent of the final** `merged_data.dta` **data frame**. Although this represents noteworthy progress, our work is not yet complete! 

<br/>

The objective is to finalize the central data sets for graphical illustrations `df_figure_rep.dta` and `merged_data.dta`. Therefore, we continue with the *second part of the data preparation process:* 

In this part, the goal is to compute the data frame `df_figure_rep`.

To do so, we firstly use the standard `data` data frame from the beginning and compress it a little bit. At start, we group by the `year` column and afterwards we summarize the values across the columns `bananaprice`, `sugarprice`, `riceprice`, `lacatanprice_farmgate`, `sabaprice_farmgate`, and `usd_php_xrate"` with the `mean` as our measure. We save that shortened data frame as `rep_data`:

```{r "20_17",eval=FALSE}

rep_data <- data %>% 
  group_by(year) %>% 
  summarise(across(c(bananaprice, sugarprice, riceprice, lacatanprice_farmgate, sabaprice_farmgate, usd_php_xrate), mean))

```

*Since we report just data for the domestic Lacatan and Saba price, we need to calculate the* `lacatanprice` *and* `sabaprice` *in 2010 US Dollars separately*. To convert these domestic prices into 2010 US Dollars, we **divide the prices with the column** `usd_php_xrate` **which represents the exchange rate USD - Philippine peso**. Moreover, we add these two columns to the data set `rep_data`:

```{r "20_18",eval=FALSE}

rep_data <- rep_data %>%
  mutate(., lacatanprice = .$lacatanprice_farmgate / .$usd_php_xrate, 
            sabaprice = .$sabaprice_farmgate / .$usd_php_xrate)

```

Lastly, we have *one whole row with NA values*. To get rid of these NA values, we use the `na.omit()` function because we only obtain NA values in this one particular row and nowhere else:

```{r "20_19",eval=FALSE}

df_figure_rep <- na.omit(rep_data) 

head(df_figure_rep)

```

<br/>

**Great, the first central data frame for graphical illustration is created!** 

This data set is used in *Exercise 2.2 of this Problem Set, so you should be familiar with it!* Moreover, this data frame **is the second necessary constituent of the final** `merged_data.dta` **data set!**

<br/>

Since the *second part of the data preparation* is done, **let us finalize the process and create the last central data set** `merged_data.dta` for graphical representation purposes:

For the graphical illustration of the huge **five facet figure**, that *we examined in Exercise 6 of this Problem Set*, we need a merged data frame that consists of the data set `df_figure_rep` and `diffgraphdata_final`. To do so, the `merge()` function is used, which merges these data frames by the key variable `year`. With the `all = FALSE` argument, **only rows with data from both data sets are included in the output**. It is therefore a *one-to-one merge*. We save this data frame as `merged_data`: 

```{r "20_20",eval=FALSE}

merged_data <- merge(df_figure_rep, diffgraphdata_final, by = "year", all = FALSE) 

```

However, we are not done yet and still have one `For-Loop` left!

For all commodities, we need to calculate their standard deviations and their `prize_z's` which omits the 2005 category. These columns should be added to the `merged_data` data frame. In the `For-Loop` over the five crops, we calculate the standard deviations from their prices. Afterwards, we create a temporary variable `temp` with the price of the commodity in this loop, if the year is equal to 2005. Else the value is zero. Then we create a new column called `price_2005` for each crop which consists of the maximum value of the `temp` variable. Then the loop adds the `prize_z` column to the data frame for each commodity, which can be calculated as `[(price of the good - price_2005 of the good) / price_sd of the good]`. As a last step, we drop the `temp` variable from the data frame:

```{r "20_21",eval=FALSE}

for (i in c("banana", "rice", "sugar", "lacatan", "saba")) { 
  
  merged_data[[paste0(i, "price_sd")]] <- sd(merged_data[[paste0(i, "price")]])
  
  temp <- merged_data[[paste0(i, "price")]] * (merged_data$year == 2005)
  
  merged_data[[paste0(i, "price_2005")]] <- max(temp) 
  
  merged_data[[paste0(i, "price_z")]] <- (merged_data[[paste0(i, "price")]] - merged_data[[paste0(i, "price_2005")]]) / merged_data[[paste0(i, "price_sd")]]
  
  merged_data$temp <- NULL 
}

head(merged_data)

```

<br/>

We are left with the central `merged_data` data frame that is **primary used to graphically illustrate the crop prices and conflict intensity** (throughout the ${\theta}_{j}$ coefficient) over the observation period of 2001 to 2009!

<br/>

```{r eval=FALSE}
# Run for additional info in the Viewer pane
info("Save the created R data frame in a separate .dta file")
```

**Congratulations! You have successfully completed the data preparation process of the data frames for the graphical illustrations in this Problem Set. You have demonstrated your understanding of the steps and techniques involved in this procedure. Well done!**

<br/>
